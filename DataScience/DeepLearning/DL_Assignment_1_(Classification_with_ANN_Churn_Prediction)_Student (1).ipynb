{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqND1TW4Xr_9"
      },
      "source": [
        "___\n",
        "\n",
        "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkbf0wqiXsAC"
      },
      "source": [
        "<h1 style=\"text-align: center;\">Deep Learning<br><br>Assignment-1 (ANN)<br><br>Churn Prediction for Bank Customer<br><h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4YlSELlXsAC"
      },
      "source": [
        "## Dataset Info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L3uViYdXsAD"
      },
      "source": [
        "We have a dataset in which there are details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed his account) or he continues to be a customer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elnJjbDOXsAD"
      },
      "source": [
        "## Improt Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0HanVzNXsAE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.warn(\"this will not show\")\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "\n",
        "# Set it None to display all rows in the dataframe\n",
        "# pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Set it to None to display all columns in the dataframe\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjAlq_KPXsAG"
      },
      "source": [
        "## Indest Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9h_X0GqXsAH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Churn_Modelling.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtjAG-pyXsAH"
      },
      "outputs": [],
      "source": [
        "df1 = df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzM-tnJCXsAI"
      },
      "source": [
        "## Exploratory Data Analysis and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qjn5vtDXsAI"
      },
      "source": [
        "1. Implement basic steps to see how is your data looks like\n",
        "2. Check for missing values\n",
        "3. Drop the features that not suitable for modelling\n",
        "4. Implement basic visualization steps such as histogram, countplot, heatmap\n",
        "5. Convert categorical variables to dummy variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0lWEEJ9_XsAJ",
        "outputId": "0cd5e43d-5ae4-46cd-e835-b2e3bb694356"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2      0.000              1          1               1   \n",
              "1       1  83807.860              1          0               1   \n",
              "2       8 159660.800              3          1               0   \n",
              "3       1      0.000              2          0               0   \n",
              "4       2 125510.820              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0       101348.880       1  \n",
              "1       112542.580       0  \n",
              "2       113931.570       1  \n",
              "3        93826.630       0  \n",
              "4        79084.100       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-009d8687-c836-496c-afbc-61fd1e094273\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.880</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.860</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.800</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.630</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.820</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-009d8687-c836-496c-afbc-61fd1e094273')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-009d8687-c836-496c-afbc-61fd1e094273 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-009d8687-c836-496c-afbc-61fd1e094273');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfd40DSXsAK",
        "outputId": "cf3e4958-2dac-48db-f577-71d200a26026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   RowNumber        10000 non-null  int64  \n",
            " 1   CustomerId       10000 non-null  int64  \n",
            " 2   Surname          10000 non-null  object \n",
            " 3   CreditScore      10000 non-null  int64  \n",
            " 4   Geography        10000 non-null  object \n",
            " 5   Gender           10000 non-null  object \n",
            " 6   Age              10000 non-null  int64  \n",
            " 7   Tenure           10000 non-null  int64  \n",
            " 8   Balance          10000 non-null  float64\n",
            " 9   NumOfProducts    10000 non-null  int64  \n",
            " 10  HasCrCard        10000 non-null  int64  \n",
            " 11  IsActiveMember   10000 non-null  int64  \n",
            " 12  EstimatedSalary  10000 non-null  float64\n",
            " 13  Exited           10000 non-null  int64  \n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PROeNe2HXsAK",
        "outputId": "8be794df-f317-4c9d-a7c7-39ca9358010f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.isnull().sum().any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "CSAFhOVCXsAK",
        "outputId": "383bc3ea-7339-4814-d195-1bd1235ba0a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    count         mean       std          min          25%  \\\n",
              "RowNumber       10000.000     5000.500  2886.896        1.000     2500.750   \n",
              "CustomerId      10000.000 15690940.569 71936.186 15565701.000 15628528.250   \n",
              "CreditScore     10000.000      650.529    96.653      350.000      584.000   \n",
              "Age             10000.000       38.922    10.488       18.000       32.000   \n",
              "Tenure          10000.000        5.013     2.892        0.000        3.000   \n",
              "Balance         10000.000    76485.889 62397.405        0.000        0.000   \n",
              "NumOfProducts   10000.000        1.530     0.582        1.000        1.000   \n",
              "HasCrCard       10000.000        0.706     0.456        0.000        0.000   \n",
              "IsActiveMember  10000.000        0.515     0.500        0.000        0.000   \n",
              "EstimatedSalary 10000.000   100090.240 57510.493       11.580    51002.110   \n",
              "Exited          10000.000        0.204     0.403        0.000        0.000   \n",
              "\n",
              "                         50%          75%          max  \n",
              "RowNumber           5000.500     7500.250    10000.000  \n",
              "CustomerId      15690738.000 15753233.750 15815690.000  \n",
              "CreditScore          652.000      718.000      850.000  \n",
              "Age                   37.000       44.000       92.000  \n",
              "Tenure                 5.000        7.000       10.000  \n",
              "Balance            97198.540   127644.240   250898.090  \n",
              "NumOfProducts          1.000        2.000        4.000  \n",
              "HasCrCard              1.000        1.000        1.000  \n",
              "IsActiveMember         1.000        1.000        1.000  \n",
              "EstimatedSalary   100193.915   149388.247   199992.480  \n",
              "Exited                 0.000        0.000        1.000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59569cfb-4973-4f6e-a596-e69a9887f7b6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>RowNumber</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>5000.500</td>\n",
              "      <td>2886.896</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2500.750</td>\n",
              "      <td>5000.500</td>\n",
              "      <td>7500.250</td>\n",
              "      <td>10000.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>15690940.569</td>\n",
              "      <td>71936.186</td>\n",
              "      <td>15565701.000</td>\n",
              "      <td>15628528.250</td>\n",
              "      <td>15690738.000</td>\n",
              "      <td>15753233.750</td>\n",
              "      <td>15815690.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>650.529</td>\n",
              "      <td>96.653</td>\n",
              "      <td>350.000</td>\n",
              "      <td>584.000</td>\n",
              "      <td>652.000</td>\n",
              "      <td>718.000</td>\n",
              "      <td>850.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>38.922</td>\n",
              "      <td>10.488</td>\n",
              "      <td>18.000</td>\n",
              "      <td>32.000</td>\n",
              "      <td>37.000</td>\n",
              "      <td>44.000</td>\n",
              "      <td>92.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>5.013</td>\n",
              "      <td>2.892</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>5.000</td>\n",
              "      <td>7.000</td>\n",
              "      <td>10.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>76485.889</td>\n",
              "      <td>62397.405</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>97198.540</td>\n",
              "      <td>127644.240</td>\n",
              "      <td>250898.090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>1.530</td>\n",
              "      <td>0.582</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>4.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>0.706</td>\n",
              "      <td>0.456</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>0.515</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>100090.240</td>\n",
              "      <td>57510.493</td>\n",
              "      <td>11.580</td>\n",
              "      <td>51002.110</td>\n",
              "      <td>100193.915</td>\n",
              "      <td>149388.247</td>\n",
              "      <td>199992.480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>10000.000</td>\n",
              "      <td>0.204</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59569cfb-4973-4f6e-a596-e69a9887f7b6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59569cfb-4973-4f6e-a596-e69a9887f7b6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59569cfb-4973-4f6e-a596-e69a9887f7b6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vej7RFzvXsAL",
        "outputId": "18a95746-ce9e-43b5-dfb9-35afb0cb4e99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "France     5014\n",
              "Germany    2509\n",
              "Spain      2477\n",
              "Name: Geography, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.Geography.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy64lL4HXsAL",
        "outputId": "32275ae1-df77-4f16-921b-e3deab9b5dc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.Exited.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "tgenp1BjXsAM",
        "outputId": "a768a7e8-bd47-40f1-ab86-f69b32214a64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f56a062ba10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x=\"Exited\",hue='Gender', data=df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "j2SBKttrXsAM",
        "outputId": "072b6456-7125-410d-c199-8216466ce124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f569fd0d710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(df[\"Exited\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "uF2z1OF8XsAM",
        "outputId": "80f675e2-41c0-48dd-e52b-2713531c7b16"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df.corr(), annot=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQqoETnyXsAN"
      },
      "outputs": [],
      "source": [
        "drop_list = [\"RowNumber\", \"Surname\", \"Geography\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rasEIpUXsAN"
      },
      "outputs": [],
      "source": [
        "df=df.drop(drop_list, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6gfqNHTXsAN"
      },
      "outputs": [],
      "source": [
        "df=df.drop(\"Gender\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgPEn88UXsAO"
      },
      "outputs": [],
      "source": [
        "df=df.drop(\"CustomerId\", axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbSfjyNGXsAO",
        "outputId": "d9c26f41-c8e1-4647-d258-872c85511697"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "vC9hM3HIXsAO",
        "outputId": "b97d2f9b-9abf-4bf2-fe45-84471ece88f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize = (8,10))\n",
        "df.corr()['Exited'].sort_values().drop(\"Exited\").plot(kind = \"barh\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePvv2zbKXsAO",
        "outputId": "ace0d653-9f1e-41df-8878-86f45c07a64b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5151\n",
              "0    4849\n",
              "Name: IsActiveMember, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.IsActiveMember.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWR3yNB5XsAP",
        "outputId": "8884253d-b7c3-4847-9aeb-aa96da91993a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2     1048\n",
              "1     1035\n",
              "7     1028\n",
              "8     1025\n",
              "5     1012\n",
              "3     1009\n",
              "4      989\n",
              "9      984\n",
              "6      967\n",
              "10     490\n",
              "0      413\n",
              "Name: Tenure, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.Tenure.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IJjHv7uUXsAP",
        "outputId": "f2198f0c-7a39-4f1b-f34b-47a13551bd2c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          619   42       2      0.000              1          1   \n",
              "1          608   41       1  83807.860              1          0   \n",
              "2          502   42       8 159660.800              3          1   \n",
              "3          699   39       1      0.000              2          0   \n",
              "4          850   43       2 125510.820              1          1   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  \n",
              "0               1       101348.880       1  \n",
              "1               1       112542.580       0  \n",
              "2               0       113931.570       1  \n",
              "3               0        93826.630       0  \n",
              "4               1        79084.100       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2258b68-b300-4ae5-977c-37a8bab12109\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.880</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.860</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.580</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.800</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.630</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.820</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.100</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2258b68-b300-4ae5-977c-37a8bab12109')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2258b68-b300-4ae5-977c-37a8bab12109 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2258b68-b300-4ae5-977c-37a8bab12109');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "-4rdg1hPXsAP",
        "outputId": "107bf376-a543-41c0-f444-84b40b526e61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x864 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "r = len(df.columns[1:])//2+ 1*(len(df.columns[1:])%2==1)\n",
        "c = 2\n",
        "r,c\n",
        "\n",
        "fig, ax = plt.subplots(nrows=r,ncols=c, figsize=(16,12))\n",
        "fig.subplots_adjust(left=None,    bottom=None,    right=None,    top=None,    wspace=0.5,    hspace=0.5)\n",
        "\n",
        "for i,col in enumerate(df.columns[1:]):\n",
        "    ax[i//2,i%2].hist(df[col])\n",
        "    ax[i//2,i%2].set_title(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8fQ7lqsXsAQ"
      },
      "source": [
        "## Preprocessing of Data\n",
        "- Train | Test Split, Scalling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98OUVoGVXsAQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HwKLplRXsAQ"
      },
      "outputs": [],
      "source": [
        "X = df.drop('Exited', axis=1)\n",
        "y = df['Exited'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzmUGIcRXsAQ"
      },
      "outputs": [],
      "source": [
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AclAhi0gbBQN"
      },
      "source": [
        "-- Data imbalanced degilse de stratify kullanilabilir --"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2G3cqi6XsAR"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.35, random_state = seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsf3I6PjXsAR"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIX4c9wKXsAR"
      },
      "outputs": [],
      "source": [
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha9hDt_AoGaE"
      },
      "source": [
        "## Modelling & Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX_-iiOlXsAS"
      },
      "source": [
        "### Import related libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPw6b5xyXsAS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from sklearn.metrics import classification_report, confusion_matrix   # classification metricleri\n",
        "from sklearn.metrics import plot_roc_curve, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7n5jTQDXsAS"
      },
      "source": [
        "### Creating Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PVT2gl9XsAS"
      },
      "source": [
        "### without class_weigth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oj6VsaCoXsAT",
        "outputId": "e4a048ed-5c7c-4be8-9a3f-a5920658dbf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "tf.__version__      # tensorflow version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyX2cU27XsAT",
        "outputId": "1b1fabaf-aa4b-4d5a-e5aa-fe46d9862f0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6500, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETuNpdwSXsAT",
        "outputId": "ffc21ebe-fa18-4527-f2e6-1ed8e904a5f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3500, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYzSz478XsAT"
      },
      "source": [
        "Ilk giriste modele 9 feature (input) gelecek. Ilk hidden layer' da 14 nron ile basladik. Nron sayisi icin kesin bir sayi yok ama arastirmalara gore feature sayisinin 1.5 kati ile baslanabilir. Biz 30 ile baslayip yariya indirerek gittik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V74MpDDqXsAT"
      },
      "source": [
        "ANN' de hidden layer' larda aktivasyon fonksiyonu olarak __relu__ secmek, Tanh ve sigmoid' e gore daha hizli sonuca ulasmayi sagliyor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsISBfwOXsAU"
      },
      "source": [
        "Output layer' da aktivasyon fonksiyonu __sigmoid__ cunku binary bir classification yapacagiz. (Regression datasinda outputtaki aktivasyon fonksiyonuna bir sey yazmamistik bu yuzden default deger olan __linear__ secilmisti.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SdftW7vXsAU"
      },
      "source": [
        "Datamiz binary classification oldugu icin model.compile kisminda __binary_crossentropy__ sectik ve gormek istedigimiz skor metriklerini yazdik. (Virgul ile diger metrikleri de ekleyebiliriz (recall, f1 score gibi))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsPagn-2XsAU"
      },
      "source": [
        "__input_dim__ ilk satira yazildigi icin agirlik atamasi bu asamada yapildi. Yazilmasa da olurdu fakat o zaman agirlik atamasi fit islemi esnasinda olurdu :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuHd1loNXsAU"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(14, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(7, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "# Yukarida structure kurduk. Asagida ise modelin egitim esnasinda kullanacagi sistemi belirledik :\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xfNLNQjXsAU"
      },
      "source": [
        "model.fit' in icinde shuffle diye bir parametre var ve bunun default degeri 'True'. Bunun anlami; 'Her epoch isleminden sonra datayi yeniden kar.' (RNN' de shuffle' i False yapacagiz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh_0z_5IXsAV"
      },
      "source": [
        "__validation_split__ ile train datasinin __son__ kisminin 0.14'  alindi. Bunun haricinde kalan data her epoch' tan sonra datayi yeniden karlacak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAH3OcmrXsAV"
      },
      "source": [
        "batch_size = 260, datadaki sample sayisi = 6500 __--->__ Yani her epoch' ta 6500 / 260 = 25 islem olacak."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv7OoqfAXsAV"
      },
      "source": [
        "__Asagida yapilan islem__ Bir epoch icin ---> Her batch_size' da bir (260 satirda bir) backpropagation yapacak sekilde tum datayi 25 islem ile egitime soktu, loss ve accuracy skorlarini aldi. __(Buradaki loss ve accuracy skorlari her epoch' taki 25. islemin sonuclari)__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsMdAnrZXsAV"
      },
      "source": [
        "val_los ve val_accuracy skorlarini ise bir epoch' taki 25 islemin hepsi bittikten sonra buluyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRqSgETOXsAW"
      },
      "source": [
        "__val_loss :__ Cost function' in sonucudur, azalmasi gerekir. Validation datasi ile alinan skorlari verir. Train datasi ile bir epoch' taki egitim biter, bulunan agirlik degerleri ile validation datasi egitime girer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctqA6DwQXsAW"
      },
      "source": [
        "__val_accuracy :__ Validation datasina ait accuracy skordur. val_los yani hata azaldikca accuracy skoru artar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdbtEGujXsAW"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-FN8TngXsAW",
        "outputId": "dc235714-3d97-4dd5-ec00-3cb777625792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.5964 - accuracy: 0.7959 - val_loss: 0.5709 - val_accuracy: 0.7956\n",
            "Epoch 2/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7964 - val_loss: 0.5372 - val_accuracy: 0.7956\n",
            "Epoch 3/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7964 - val_loss: 0.5229 - val_accuracy: 0.7956\n",
            "Epoch 4/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.7964 - val_loss: 0.5122 - val_accuracy: 0.7956\n",
            "Epoch 5/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7964 - val_loss: 0.5044 - val_accuracy: 0.7956\n",
            "Epoch 6/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7964 - val_loss: 0.4981 - val_accuracy: 0.7956\n",
            "Epoch 7/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7964 - val_loss: 0.4932 - val_accuracy: 0.7956\n",
            "Epoch 8/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7964 - val_loss: 0.4893 - val_accuracy: 0.7956\n",
            "Epoch 9/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7964 - val_loss: 0.4857 - val_accuracy: 0.7956\n",
            "Epoch 10/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7964 - val_loss: 0.4819 - val_accuracy: 0.7956\n",
            "Epoch 11/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7964 - val_loss: 0.4787 - val_accuracy: 0.7956\n",
            "Epoch 12/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7964 - val_loss: 0.4753 - val_accuracy: 0.7956\n",
            "Epoch 13/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7964 - val_loss: 0.4716 - val_accuracy: 0.7956\n",
            "Epoch 14/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7964 - val_loss: 0.4675 - val_accuracy: 0.7956\n",
            "Epoch 15/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7964 - val_loss: 0.4641 - val_accuracy: 0.7967\n",
            "Epoch 16/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7979 - val_loss: 0.4615 - val_accuracy: 0.7967\n",
            "Epoch 17/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7989 - val_loss: 0.4585 - val_accuracy: 0.7989\n",
            "Epoch 18/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8038 - val_loss: 0.4565 - val_accuracy: 0.7989\n",
            "Epoch 19/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8050 - val_loss: 0.4541 - val_accuracy: 0.8011\n",
            "Epoch 20/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8059 - val_loss: 0.4530 - val_accuracy: 0.8022\n",
            "Epoch 21/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8061 - val_loss: 0.4511 - val_accuracy: 0.8044\n",
            "Epoch 22/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4354 - accuracy: 0.8091 - val_loss: 0.4491 - val_accuracy: 0.8066\n",
            "Epoch 23/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8091 - val_loss: 0.4477 - val_accuracy: 0.8099\n",
            "Epoch 24/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8104 - val_loss: 0.4454 - val_accuracy: 0.8055\n",
            "Epoch 25/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8102 - val_loss: 0.4443 - val_accuracy: 0.8055\n",
            "Epoch 26/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4254 - accuracy: 0.8109 - val_loss: 0.4421 - val_accuracy: 0.8011\n",
            "Epoch 27/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8154 - val_loss: 0.4414 - val_accuracy: 0.8022\n",
            "Epoch 28/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8148 - val_loss: 0.4380 - val_accuracy: 0.8055\n",
            "Epoch 29/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4184 - accuracy: 0.8166 - val_loss: 0.4354 - val_accuracy: 0.8055\n",
            "Epoch 30/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8188 - val_loss: 0.4361 - val_accuracy: 0.8066\n",
            "Epoch 31/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8191 - val_loss: 0.4325 - val_accuracy: 0.8099\n",
            "Epoch 32/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4114 - accuracy: 0.8218 - val_loss: 0.4334 - val_accuracy: 0.8110\n",
            "Epoch 33/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8229 - val_loss: 0.4270 - val_accuracy: 0.8154\n",
            "Epoch 34/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8249 - val_loss: 0.4257 - val_accuracy: 0.8187\n",
            "Epoch 35/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8263 - val_loss: 0.4235 - val_accuracy: 0.8242\n",
            "Epoch 36/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8293 - val_loss: 0.4217 - val_accuracy: 0.8264\n",
            "Epoch 37/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8304 - val_loss: 0.4195 - val_accuracy: 0.8275\n",
            "Epoch 38/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3977 - accuracy: 0.8324 - val_loss: 0.4178 - val_accuracy: 0.8253\n",
            "Epoch 39/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.4164 - val_accuracy: 0.8275\n",
            "Epoch 40/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8367 - val_loss: 0.4148 - val_accuracy: 0.8264\n",
            "Epoch 41/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8381 - val_loss: 0.4139 - val_accuracy: 0.8275\n",
            "Epoch 42/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8376 - val_loss: 0.4126 - val_accuracy: 0.8286\n",
            "Epoch 43/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8397 - val_loss: 0.4099 - val_accuracy: 0.8275\n",
            "Epoch 44/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3861 - accuracy: 0.8413 - val_loss: 0.4107 - val_accuracy: 0.8297\n",
            "Epoch 45/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8408 - val_loss: 0.4098 - val_accuracy: 0.8275\n",
            "Epoch 46/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8408 - val_loss: 0.4063 - val_accuracy: 0.8330\n",
            "Epoch 47/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8438 - val_loss: 0.4057 - val_accuracy: 0.8341\n",
            "Epoch 48/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3810 - accuracy: 0.8440 - val_loss: 0.4049 - val_accuracy: 0.8319\n",
            "Epoch 49/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3793 - accuracy: 0.8469 - val_loss: 0.4061 - val_accuracy: 0.8275\n",
            "Epoch 50/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8463 - val_loss: 0.4026 - val_accuracy: 0.8374\n",
            "Epoch 51/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8492 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
            "Epoch 52/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.8453 - val_loss: 0.4040 - val_accuracy: 0.8253\n",
            "Epoch 53/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3757 - accuracy: 0.8487 - val_loss: 0.4000 - val_accuracy: 0.8352\n",
            "Epoch 54/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8524 - val_loss: 0.4021 - val_accuracy: 0.8297\n",
            "Epoch 55/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8535 - val_loss: 0.3975 - val_accuracy: 0.8363\n",
            "Epoch 56/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8526 - val_loss: 0.3973 - val_accuracy: 0.8363\n",
            "Epoch 57/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8508 - val_loss: 0.3961 - val_accuracy: 0.8363\n",
            "Epoch 58/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8537 - val_loss: 0.3965 - val_accuracy: 0.8363\n",
            "Epoch 59/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3695 - accuracy: 0.8540 - val_loss: 0.3947 - val_accuracy: 0.8385\n",
            "Epoch 60/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8540 - val_loss: 0.3958 - val_accuracy: 0.8352\n",
            "Epoch 61/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8540 - val_loss: 0.3957 - val_accuracy: 0.8341\n",
            "Epoch 62/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8546 - val_loss: 0.3936 - val_accuracy: 0.8396\n",
            "Epoch 63/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3665 - accuracy: 0.8558 - val_loss: 0.3946 - val_accuracy: 0.8330\n",
            "Epoch 64/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8544 - val_loss: 0.3937 - val_accuracy: 0.8352\n",
            "Epoch 65/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8546 - val_loss: 0.3965 - val_accuracy: 0.8363\n",
            "Epoch 66/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3645 - accuracy: 0.8542 - val_loss: 0.3913 - val_accuracy: 0.8363\n",
            "Epoch 67/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8558 - val_loss: 0.3912 - val_accuracy: 0.8407\n",
            "Epoch 68/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3646 - accuracy: 0.8560 - val_loss: 0.3906 - val_accuracy: 0.8363\n",
            "Epoch 69/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8565 - val_loss: 0.3905 - val_accuracy: 0.8396\n",
            "Epoch 70/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8544 - val_loss: 0.3907 - val_accuracy: 0.8385\n",
            "Epoch 71/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8572 - val_loss: 0.3911 - val_accuracy: 0.8396\n",
            "Epoch 72/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3619 - accuracy: 0.8560 - val_loss: 0.3916 - val_accuracy: 0.8385\n",
            "Epoch 73/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.8569 - val_loss: 0.3905 - val_accuracy: 0.8407\n",
            "Epoch 74/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8564 - val_loss: 0.3899 - val_accuracy: 0.8385\n",
            "Epoch 75/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3612 - accuracy: 0.8558 - val_loss: 0.3892 - val_accuracy: 0.8407\n",
            "Epoch 76/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8565 - val_loss: 0.3905 - val_accuracy: 0.8407\n",
            "Epoch 77/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8571 - val_loss: 0.3908 - val_accuracy: 0.8418\n",
            "Epoch 78/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8564 - val_loss: 0.3894 - val_accuracy: 0.8396\n",
            "Epoch 79/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8572 - val_loss: 0.3896 - val_accuracy: 0.8418\n",
            "Epoch 80/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3592 - accuracy: 0.8574 - val_loss: 0.3883 - val_accuracy: 0.8418\n",
            "Epoch 81/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8560 - val_loss: 0.3885 - val_accuracy: 0.8374\n",
            "Epoch 82/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3602 - accuracy: 0.8562 - val_loss: 0.3887 - val_accuracy: 0.8407\n",
            "Epoch 83/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8407\n",
            "Epoch 84/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8572 - val_loss: 0.3879 - val_accuracy: 0.8385\n",
            "Epoch 85/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8553 - val_loss: 0.3876 - val_accuracy: 0.8396\n",
            "Epoch 86/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8540 - val_loss: 0.3884 - val_accuracy: 0.8418\n",
            "Epoch 87/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8572 - val_loss: 0.3887 - val_accuracy: 0.8418\n",
            "Epoch 88/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8583 - val_loss: 0.3899 - val_accuracy: 0.8418\n",
            "Epoch 89/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.8581 - val_loss: 0.3880 - val_accuracy: 0.8396\n",
            "Epoch 90/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.8565 - val_loss: 0.3872 - val_accuracy: 0.8396\n",
            "Epoch 91/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8585 - val_loss: 0.3892 - val_accuracy: 0.8407\n",
            "Epoch 92/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8576 - val_loss: 0.3876 - val_accuracy: 0.8396\n",
            "Epoch 93/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8580 - val_loss: 0.3881 - val_accuracy: 0.8429\n",
            "Epoch 94/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8576 - val_loss: 0.3868 - val_accuracy: 0.8385\n",
            "Epoch 95/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8565 - val_loss: 0.3894 - val_accuracy: 0.8396\n",
            "Epoch 96/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8572 - val_loss: 0.3870 - val_accuracy: 0.8396\n",
            "Epoch 97/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8585 - val_loss: 0.3885 - val_accuracy: 0.8407\n",
            "Epoch 98/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8571 - val_loss: 0.3885 - val_accuracy: 0.8418\n",
            "Epoch 99/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8585 - val_loss: 0.3861 - val_accuracy: 0.8385\n",
            "Epoch 100/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3553 - accuracy: 0.8589 - val_loss: 0.3878 - val_accuracy: 0.8429\n",
            "Epoch 101/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3556 - accuracy: 0.8580 - val_loss: 0.3879 - val_accuracy: 0.8429\n",
            "Epoch 102/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8578 - val_loss: 0.3882 - val_accuracy: 0.8440\n",
            "Epoch 103/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8565 - val_loss: 0.3885 - val_accuracy: 0.8418\n",
            "Epoch 104/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3550 - accuracy: 0.8583 - val_loss: 0.3858 - val_accuracy: 0.8385\n",
            "Epoch 105/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8580 - val_loss: 0.3885 - val_accuracy: 0.8429\n",
            "Epoch 106/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8546 - val_loss: 0.3895 - val_accuracy: 0.8396\n",
            "Epoch 107/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3545 - accuracy: 0.8567 - val_loss: 0.3861 - val_accuracy: 0.8418\n",
            "Epoch 108/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3544 - accuracy: 0.8572 - val_loss: 0.3867 - val_accuracy: 0.8418\n",
            "Epoch 109/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8580 - val_loss: 0.3858 - val_accuracy: 0.8385\n",
            "Epoch 110/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8574 - val_loss: 0.3863 - val_accuracy: 0.8440\n",
            "Epoch 111/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8578 - val_loss: 0.3898 - val_accuracy: 0.8407\n",
            "Epoch 112/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.3882 - val_accuracy: 0.8418\n",
            "Epoch 113/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8578 - val_loss: 0.3894 - val_accuracy: 0.8407\n",
            "Epoch 114/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8565 - val_loss: 0.3875 - val_accuracy: 0.8440\n",
            "Epoch 115/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8571 - val_loss: 0.3870 - val_accuracy: 0.8429\n",
            "Epoch 116/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8569 - val_loss: 0.3884 - val_accuracy: 0.8418\n",
            "Epoch 117/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3538 - accuracy: 0.8578 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
            "Epoch 118/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3543 - accuracy: 0.8581 - val_loss: 0.3852 - val_accuracy: 0.8385\n",
            "Epoch 119/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8569 - val_loss: 0.3859 - val_accuracy: 0.8407\n",
            "Epoch 120/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8571 - val_loss: 0.3887 - val_accuracy: 0.8407\n",
            "Epoch 121/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8576 - val_loss: 0.3848 - val_accuracy: 0.8385\n",
            "Epoch 122/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8565 - val_loss: 0.3894 - val_accuracy: 0.8407\n",
            "Epoch 123/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8572 - val_loss: 0.3845 - val_accuracy: 0.8418\n",
            "Epoch 124/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8567 - val_loss: 0.3849 - val_accuracy: 0.8363\n",
            "Epoch 125/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8581 - val_loss: 0.3874 - val_accuracy: 0.8440\n",
            "Epoch 126/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3527 - accuracy: 0.8571 - val_loss: 0.3848 - val_accuracy: 0.8407\n",
            "Epoch 127/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8572 - val_loss: 0.3855 - val_accuracy: 0.8418\n",
            "Epoch 128/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3529 - accuracy: 0.8574 - val_loss: 0.3846 - val_accuracy: 0.8385\n",
            "Epoch 129/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3523 - accuracy: 0.8581 - val_loss: 0.3864 - val_accuracy: 0.8429\n",
            "Epoch 130/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8571 - val_loss: 0.3866 - val_accuracy: 0.8429\n",
            "Epoch 131/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8576 - val_loss: 0.3859 - val_accuracy: 0.8418\n",
            "Epoch 132/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8572 - val_loss: 0.3888 - val_accuracy: 0.8396\n",
            "Epoch 133/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8544 - val_loss: 0.3889 - val_accuracy: 0.8407\n",
            "Epoch 134/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8562 - val_loss: 0.3847 - val_accuracy: 0.8385\n",
            "Epoch 135/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3517 - accuracy: 0.8578 - val_loss: 0.3855 - val_accuracy: 0.8418\n",
            "Epoch 136/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3518 - accuracy: 0.8580 - val_loss: 0.3844 - val_accuracy: 0.8407\n",
            "Epoch 137/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8560 - val_loss: 0.3842 - val_accuracy: 0.8374\n",
            "Epoch 138/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8583 - val_loss: 0.3842 - val_accuracy: 0.8396\n",
            "Epoch 139/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8564 - val_loss: 0.3841 - val_accuracy: 0.8374\n",
            "Epoch 140/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3520 - accuracy: 0.8578 - val_loss: 0.3857 - val_accuracy: 0.8440\n",
            "Epoch 141/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8574 - val_loss: 0.3839 - val_accuracy: 0.8385\n",
            "Epoch 142/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8567 - val_loss: 0.3851 - val_accuracy: 0.8418\n",
            "Epoch 143/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8572 - val_loss: 0.3868 - val_accuracy: 0.8418\n",
            "Epoch 144/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8581 - val_loss: 0.3837 - val_accuracy: 0.8385\n",
            "Epoch 145/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8580 - val_loss: 0.3837 - val_accuracy: 0.8396\n",
            "Epoch 146/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8569 - val_loss: 0.3844 - val_accuracy: 0.8407\n",
            "Epoch 147/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8576 - val_loss: 0.3858 - val_accuracy: 0.8429\n",
            "Epoch 148/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8571 - val_loss: 0.3851 - val_accuracy: 0.8429\n",
            "Epoch 149/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8572 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 150/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8581 - val_loss: 0.3834 - val_accuracy: 0.8374\n",
            "Epoch 151/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8578 - val_loss: 0.3839 - val_accuracy: 0.8385\n",
            "Epoch 152/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3505 - accuracy: 0.8574 - val_loss: 0.3846 - val_accuracy: 0.8440\n",
            "Epoch 153/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8569 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 154/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.8574 - val_loss: 0.3847 - val_accuracy: 0.8440\n",
            "Epoch 155/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8572 - val_loss: 0.3849 - val_accuracy: 0.8440\n",
            "Epoch 156/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8572 - val_loss: 0.3852 - val_accuracy: 0.8440\n",
            "Epoch 157/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3503 - accuracy: 0.8574 - val_loss: 0.3849 - val_accuracy: 0.8429\n",
            "Epoch 158/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8574 - val_loss: 0.3861 - val_accuracy: 0.8396\n",
            "Epoch 159/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8565 - val_loss: 0.3861 - val_accuracy: 0.8407\n",
            "Epoch 160/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8574 - val_loss: 0.3836 - val_accuracy: 0.8407\n",
            "Epoch 161/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8574 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 162/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3495 - accuracy: 0.8567 - val_loss: 0.3846 - val_accuracy: 0.8418\n",
            "Epoch 163/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8565 - val_loss: 0.3870 - val_accuracy: 0.8407\n",
            "Epoch 164/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8572 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 165/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8578 - val_loss: 0.3837 - val_accuracy: 0.8418\n",
            "Epoch 166/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8581 - val_loss: 0.3851 - val_accuracy: 0.8418\n",
            "Epoch 167/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8587 - val_loss: 0.3878 - val_accuracy: 0.8418\n",
            "Epoch 168/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8572 - val_loss: 0.3839 - val_accuracy: 0.8407\n",
            "Epoch 169/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8578 - val_loss: 0.3827 - val_accuracy: 0.8374\n",
            "Epoch 170/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8567 - val_loss: 0.3835 - val_accuracy: 0.8418\n",
            "Epoch 171/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8572 - val_loss: 0.3839 - val_accuracy: 0.8396\n",
            "Epoch 172/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8572 - val_loss: 0.3831 - val_accuracy: 0.8374\n",
            "Epoch 173/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8567 - val_loss: 0.3828 - val_accuracy: 0.8385\n",
            "Epoch 174/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8571 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 175/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8583 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
            "Epoch 176/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8572 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 177/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8576 - val_loss: 0.3829 - val_accuracy: 0.8385\n",
            "Epoch 178/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8580 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
            "Epoch 179/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8572 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
            "Epoch 180/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8583 - val_loss: 0.3847 - val_accuracy: 0.8418\n",
            "Epoch 181/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8576 - val_loss: 0.3831 - val_accuracy: 0.8385\n",
            "Epoch 182/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8581 - val_loss: 0.3824 - val_accuracy: 0.8374\n",
            "Epoch 183/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8569 - val_loss: 0.3825 - val_accuracy: 0.8396\n",
            "Epoch 184/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8589 - val_loss: 0.3895 - val_accuracy: 0.8385\n",
            "Epoch 185/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8583 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 186/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8549 - val_loss: 0.3824 - val_accuracy: 0.8396\n",
            "Epoch 187/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8574 - val_loss: 0.3820 - val_accuracy: 0.8385\n",
            "Epoch 188/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8585 - val_loss: 0.3826 - val_accuracy: 0.8374\n",
            "Epoch 189/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8571 - val_loss: 0.3843 - val_accuracy: 0.8396\n",
            "Epoch 190/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3487 - accuracy: 0.8576 - val_loss: 0.3874 - val_accuracy: 0.8407\n",
            "Epoch 191/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8572 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 192/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8564 - val_loss: 0.3817 - val_accuracy: 0.8385\n",
            "Epoch 193/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8574 - val_loss: 0.3835 - val_accuracy: 0.8396\n",
            "Epoch 194/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8572 - val_loss: 0.3831 - val_accuracy: 0.8407\n",
            "Epoch 195/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3475 - accuracy: 0.8578 - val_loss: 0.3833 - val_accuracy: 0.8407\n",
            "Epoch 196/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8576 - val_loss: 0.3832 - val_accuracy: 0.8385\n",
            "Epoch 197/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8562 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 198/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8556 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 199/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8576 - val_loss: 0.3832 - val_accuracy: 0.8374\n",
            "Epoch 200/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8574 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 201/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8572 - val_loss: 0.3815 - val_accuracy: 0.8374\n",
            "Epoch 202/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8572 - val_loss: 0.3832 - val_accuracy: 0.8385\n",
            "Epoch 203/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8560 - val_loss: 0.3848 - val_accuracy: 0.8396\n",
            "Epoch 204/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8569 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 205/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8385\n",
            "Epoch 206/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8572 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 207/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8574 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 208/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 209/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8574 - val_loss: 0.3817 - val_accuracy: 0.8374\n",
            "Epoch 210/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8569 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 211/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8572 - val_loss: 0.3849 - val_accuracy: 0.8396\n",
            "Epoch 212/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 213/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8585 - val_loss: 0.3845 - val_accuracy: 0.8396\n",
            "Epoch 214/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8567 - val_loss: 0.3831 - val_accuracy: 0.8385\n",
            "Epoch 215/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8580 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 216/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8578 - val_loss: 0.3814 - val_accuracy: 0.8374\n",
            "Epoch 217/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8583 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 218/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8576 - val_loss: 0.3886 - val_accuracy: 0.8396\n",
            "Epoch 219/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8567 - val_loss: 0.3820 - val_accuracy: 0.8396\n",
            "Epoch 220/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8578 - val_loss: 0.3810 - val_accuracy: 0.8374\n",
            "Epoch 221/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3465 - accuracy: 0.8589 - val_loss: 0.3821 - val_accuracy: 0.8396\n",
            "Epoch 222/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8571 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 223/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8565 - val_loss: 0.3834 - val_accuracy: 0.8407\n",
            "Epoch 224/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 225/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8578 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 226/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8592 - val_loss: 0.3826 - val_accuracy: 0.8429\n",
            "Epoch 227/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8581 - val_loss: 0.3865 - val_accuracy: 0.8396\n",
            "Epoch 228/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8580 - val_loss: 0.3834 - val_accuracy: 0.8418\n",
            "Epoch 229/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8587 - val_loss: 0.3820 - val_accuracy: 0.8407\n",
            "Epoch 230/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8592 - val_loss: 0.3821 - val_accuracy: 0.8396\n",
            "Epoch 231/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8583 - val_loss: 0.3842 - val_accuracy: 0.8407\n",
            "Epoch 232/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8581 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 233/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8587 - val_loss: 0.3809 - val_accuracy: 0.8374\n",
            "Epoch 234/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8578 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 235/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.8587 - val_loss: 0.3825 - val_accuracy: 0.8396\n",
            "Epoch 236/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 237/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8587 - val_loss: 0.3827 - val_accuracy: 0.8418\n",
            "Epoch 238/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8590 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 239/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8585 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 240/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8587 - val_loss: 0.3854 - val_accuracy: 0.8407\n",
            "Epoch 241/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8587 - val_loss: 0.3842 - val_accuracy: 0.8418\n",
            "Epoch 242/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8574 - val_loss: 0.3871 - val_accuracy: 0.8407\n",
            "Epoch 243/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8576 - val_loss: 0.3848 - val_accuracy: 0.8385\n",
            "Epoch 244/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8589 - val_loss: 0.3810 - val_accuracy: 0.8396\n",
            "Epoch 245/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8590 - val_loss: 0.3809 - val_accuracy: 0.8374\n",
            "Epoch 246/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8594 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 247/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8594 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 248/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8590 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 249/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8576 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 250/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8587 - val_loss: 0.3841 - val_accuracy: 0.8407\n",
            "Epoch 251/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8581 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 252/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8592 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 253/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8581 - val_loss: 0.3812 - val_accuracy: 0.8407\n",
            "Epoch 254/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8589 - val_loss: 0.3847 - val_accuracy: 0.8385\n",
            "Epoch 255/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8587 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 256/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8592 - val_loss: 0.3837 - val_accuracy: 0.8396\n",
            "Epoch 257/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8603 - val_loss: 0.3857 - val_accuracy: 0.8396\n",
            "Epoch 258/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8587 - val_loss: 0.3828 - val_accuracy: 0.8407\n",
            "Epoch 259/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8583 - val_loss: 0.3822 - val_accuracy: 0.8385\n",
            "Epoch 260/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8596 - val_loss: 0.3845 - val_accuracy: 0.8407\n",
            "Epoch 261/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8587 - val_loss: 0.3813 - val_accuracy: 0.8374\n",
            "Epoch 262/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8601 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 263/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8590 - val_loss: 0.3807 - val_accuracy: 0.8396\n",
            "Epoch 264/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8580 - val_loss: 0.3813 - val_accuracy: 0.8396\n",
            "Epoch 265/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8592 - val_loss: 0.3819 - val_accuracy: 0.8396\n",
            "Epoch 266/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8592 - val_loss: 0.3811 - val_accuracy: 0.8363\n",
            "Epoch 267/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8585 - val_loss: 0.3818 - val_accuracy: 0.8396\n",
            "Epoch 268/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8592 - val_loss: 0.3833 - val_accuracy: 0.8407\n",
            "Epoch 269/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8596 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 270/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8571 - val_loss: 0.3830 - val_accuracy: 0.8396\n",
            "Epoch 271/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8608 - val_loss: 0.3807 - val_accuracy: 0.8396\n",
            "Epoch 272/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8587 - val_loss: 0.3813 - val_accuracy: 0.8385\n",
            "Epoch 273/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8594 - val_loss: 0.3807 - val_accuracy: 0.8374\n",
            "Epoch 274/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8599 - val_loss: 0.3830 - val_accuracy: 0.8407\n",
            "Epoch 275/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8592 - val_loss: 0.3819 - val_accuracy: 0.8385\n",
            "Epoch 276/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8594 - val_loss: 0.3826 - val_accuracy: 0.8407\n",
            "Epoch 277/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8592 - val_loss: 0.3813 - val_accuracy: 0.8385\n",
            "Epoch 278/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8589 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 279/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8592 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 280/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8578 - val_loss: 0.3810 - val_accuracy: 0.8374\n",
            "Epoch 281/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8589 - val_loss: 0.3807 - val_accuracy: 0.8385\n",
            "Epoch 282/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8606 - val_loss: 0.3810 - val_accuracy: 0.8385\n",
            "Epoch 283/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8592 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 284/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8601 - val_loss: 0.3801 - val_accuracy: 0.8363\n",
            "Epoch 285/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8599 - val_loss: 0.3804 - val_accuracy: 0.8352\n",
            "Epoch 286/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8585 - val_loss: 0.3809 - val_accuracy: 0.8396\n",
            "Epoch 287/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8594 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 288/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8592 - val_loss: 0.3810 - val_accuracy: 0.8418\n",
            "Epoch 289/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8592 - val_loss: 0.3804 - val_accuracy: 0.8385\n",
            "Epoch 290/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8594 - val_loss: 0.3814 - val_accuracy: 0.8385\n",
            "Epoch 291/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.8603 - val_loss: 0.3808 - val_accuracy: 0.8385\n",
            "Epoch 292/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8603 - val_loss: 0.3817 - val_accuracy: 0.8385\n",
            "Epoch 293/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8594 - val_loss: 0.3817 - val_accuracy: 0.8418\n",
            "Epoch 294/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8603 - val_loss: 0.3855 - val_accuracy: 0.8385\n",
            "Epoch 295/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8589 - val_loss: 0.3813 - val_accuracy: 0.8418\n",
            "Epoch 296/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8590 - val_loss: 0.3817 - val_accuracy: 0.8374\n",
            "Epoch 297/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8574 - val_loss: 0.3806 - val_accuracy: 0.8363\n",
            "Epoch 298/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8590 - val_loss: 0.3805 - val_accuracy: 0.8396\n",
            "Epoch 299/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8596 - val_loss: 0.3811 - val_accuracy: 0.8407\n",
            "Epoch 300/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8601 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 301/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8594 - val_loss: 0.3805 - val_accuracy: 0.8385\n",
            "Epoch 302/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8587 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 303/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8603 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 304/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8589 - val_loss: 0.3812 - val_accuracy: 0.8363\n",
            "Epoch 305/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8597 - val_loss: 0.3810 - val_accuracy: 0.8396\n",
            "Epoch 306/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8590 - val_loss: 0.3805 - val_accuracy: 0.8385\n",
            "Epoch 307/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8599 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 308/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8589 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 309/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8590 - val_loss: 0.3806 - val_accuracy: 0.8374\n",
            "Epoch 310/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8603 - val_loss: 0.3813 - val_accuracy: 0.8374\n",
            "Epoch 311/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8590 - val_loss: 0.3818 - val_accuracy: 0.8407\n",
            "Epoch 312/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8594 - val_loss: 0.3821 - val_accuracy: 0.8407\n",
            "Epoch 313/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8578 - val_loss: 0.3806 - val_accuracy: 0.8407\n",
            "Epoch 314/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8597 - val_loss: 0.3834 - val_accuracy: 0.8396\n",
            "Epoch 315/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8592 - val_loss: 0.3839 - val_accuracy: 0.8418\n",
            "Epoch 316/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8606 - val_loss: 0.3825 - val_accuracy: 0.8429\n",
            "Epoch 317/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8594 - val_loss: 0.3801 - val_accuracy: 0.8385\n",
            "Epoch 318/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8596 - val_loss: 0.3803 - val_accuracy: 0.8385\n",
            "Epoch 319/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8590 - val_loss: 0.3807 - val_accuracy: 0.8385\n",
            "Epoch 320/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8585 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 321/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.8596 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 322/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8599 - val_loss: 0.3813 - val_accuracy: 0.8407\n",
            "Epoch 323/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8580 - val_loss: 0.3814 - val_accuracy: 0.8396\n",
            "Epoch 324/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8599 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 325/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8587 - val_loss: 0.3797 - val_accuracy: 0.8363\n",
            "Epoch 326/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8592 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 327/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8594 - val_loss: 0.3803 - val_accuracy: 0.8407\n",
            "Epoch 328/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8601 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 329/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8581 - val_loss: 0.3807 - val_accuracy: 0.8385\n",
            "Epoch 330/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8596 - val_loss: 0.3807 - val_accuracy: 0.8407\n",
            "Epoch 331/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8603 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 332/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8596 - val_loss: 0.3838 - val_accuracy: 0.8429\n",
            "Epoch 333/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8587 - val_loss: 0.3810 - val_accuracy: 0.8363\n",
            "Epoch 334/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8578 - val_loss: 0.3804 - val_accuracy: 0.8385\n",
            "Epoch 335/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8605 - val_loss: 0.3813 - val_accuracy: 0.8385\n",
            "Epoch 336/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3435 - accuracy: 0.8605 - val_loss: 0.3819 - val_accuracy: 0.8407\n",
            "Epoch 337/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8590 - val_loss: 0.3808 - val_accuracy: 0.8396\n",
            "Epoch 338/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8601 - val_loss: 0.3811 - val_accuracy: 0.8385\n",
            "Epoch 339/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8605 - val_loss: 0.3831 - val_accuracy: 0.8429\n",
            "Epoch 340/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8589 - val_loss: 0.3852 - val_accuracy: 0.8374\n",
            "Epoch 341/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8608 - val_loss: 0.3843 - val_accuracy: 0.8396\n",
            "Epoch 342/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3431 - accuracy: 0.8597 - val_loss: 0.3801 - val_accuracy: 0.8385\n",
            "Epoch 343/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8592 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 344/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8592 - val_loss: 0.3829 - val_accuracy: 0.8418\n",
            "Epoch 345/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8590 - val_loss: 0.3813 - val_accuracy: 0.8418\n",
            "Epoch 346/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3429 - accuracy: 0.8601 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 347/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3425 - accuracy: 0.8599 - val_loss: 0.3807 - val_accuracy: 0.8396\n",
            "Epoch 348/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8592 - val_loss: 0.3836 - val_accuracy: 0.8418\n",
            "Epoch 349/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8596 - val_loss: 0.3808 - val_accuracy: 0.8396\n",
            "Epoch 350/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8605 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 351/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8592 - val_loss: 0.3818 - val_accuracy: 0.8385\n",
            "Epoch 352/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8615 - val_loss: 0.3828 - val_accuracy: 0.8429\n",
            "Epoch 353/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8599 - val_loss: 0.3853 - val_accuracy: 0.8374\n",
            "Epoch 354/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8605 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 355/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8594 - val_loss: 0.3820 - val_accuracy: 0.8418\n",
            "Epoch 356/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8592 - val_loss: 0.3813 - val_accuracy: 0.8374\n",
            "Epoch 357/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8603 - val_loss: 0.3834 - val_accuracy: 0.8429\n",
            "Epoch 358/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8589 - val_loss: 0.3851 - val_accuracy: 0.8396\n",
            "Epoch 359/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3433 - accuracy: 0.8592 - val_loss: 0.3840 - val_accuracy: 0.8396\n",
            "Epoch 360/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3419 - accuracy: 0.8597 - val_loss: 0.3806 - val_accuracy: 0.8385\n",
            "Epoch 361/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8603 - val_loss: 0.3799 - val_accuracy: 0.8385\n",
            "Epoch 362/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3430 - accuracy: 0.8587 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 363/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8590 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 364/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3424 - accuracy: 0.8592 - val_loss: 0.3805 - val_accuracy: 0.8407\n",
            "Epoch 365/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8594 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 366/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8590 - val_loss: 0.3796 - val_accuracy: 0.8352\n",
            "Epoch 367/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3424 - accuracy: 0.8585 - val_loss: 0.3799 - val_accuracy: 0.8374\n",
            "Epoch 368/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8578 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 369/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3427 - accuracy: 0.8581 - val_loss: 0.3831 - val_accuracy: 0.8407\n",
            "Epoch 370/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3425 - accuracy: 0.8583 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 371/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8596 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 372/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8589 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 373/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8589 - val_loss: 0.3809 - val_accuracy: 0.8385\n",
            "Epoch 374/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8599 - val_loss: 0.3799 - val_accuracy: 0.8385\n",
            "Epoch 375/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8596 - val_loss: 0.3814 - val_accuracy: 0.8407\n",
            "Epoch 376/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8418\n",
            "Epoch 377/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8606 - val_loss: 0.3821 - val_accuracy: 0.8407\n",
            "Epoch 378/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8581 - val_loss: 0.3843 - val_accuracy: 0.8418\n",
            "Epoch 379/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8594 - val_loss: 0.3807 - val_accuracy: 0.8363\n",
            "Epoch 380/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3434 - accuracy: 0.8580 - val_loss: 0.3812 - val_accuracy: 0.8407\n",
            "Epoch 381/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8589 - val_loss: 0.3803 - val_accuracy: 0.8374\n",
            "Epoch 382/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8583 - val_loss: 0.3838 - val_accuracy: 0.8407\n",
            "Epoch 383/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8583 - val_loss: 0.3808 - val_accuracy: 0.8385\n",
            "Epoch 384/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8587 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 385/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8594 - val_loss: 0.3817 - val_accuracy: 0.8385\n",
            "Epoch 386/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3421 - accuracy: 0.8589 - val_loss: 0.3836 - val_accuracy: 0.8385\n",
            "Epoch 387/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8587 - val_loss: 0.3819 - val_accuracy: 0.8407\n",
            "Epoch 388/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8585 - val_loss: 0.3796 - val_accuracy: 0.8385\n",
            "Epoch 389/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8594 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 390/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8596 - val_loss: 0.3806 - val_accuracy: 0.8407\n",
            "Epoch 391/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8585 - val_loss: 0.3806 - val_accuracy: 0.8418\n",
            "Epoch 392/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8599 - val_loss: 0.3816 - val_accuracy: 0.8374\n",
            "Epoch 393/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8594 - val_loss: 0.3807 - val_accuracy: 0.8407\n",
            "Epoch 394/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8576 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
            "Epoch 395/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8585 - val_loss: 0.3824 - val_accuracy: 0.8385\n",
            "Epoch 396/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8580 - val_loss: 0.3804 - val_accuracy: 0.8374\n",
            "Epoch 397/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8578 - val_loss: 0.3794 - val_accuracy: 0.8385\n",
            "Epoch 398/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8585 - val_loss: 0.3812 - val_accuracy: 0.8418\n",
            "Epoch 399/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8597 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 400/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8581 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 401/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8603 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 402/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8597 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 403/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8581 - val_loss: 0.3812 - val_accuracy: 0.8374\n",
            "Epoch 404/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8601 - val_loss: 0.3803 - val_accuracy: 0.8418\n",
            "Epoch 405/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8583 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 406/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8606 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 407/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8590 - val_loss: 0.3805 - val_accuracy: 0.8374\n",
            "Epoch 408/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8603 - val_loss: 0.3829 - val_accuracy: 0.8418\n",
            "Epoch 409/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8599 - val_loss: 0.3799 - val_accuracy: 0.8396\n",
            "Epoch 410/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8608 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 411/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8601 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 412/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8603 - val_loss: 0.3800 - val_accuracy: 0.8396\n",
            "Epoch 413/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8603 - val_loss: 0.3842 - val_accuracy: 0.8418\n",
            "Epoch 414/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3418 - accuracy: 0.8592 - val_loss: 0.3811 - val_accuracy: 0.8385\n",
            "Epoch 415/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8612 - val_loss: 0.3848 - val_accuracy: 0.8429\n",
            "Epoch 416/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8418\n",
            "Epoch 417/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8578 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 418/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8590 - val_loss: 0.3806 - val_accuracy: 0.8385\n",
            "Epoch 419/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8597 - val_loss: 0.3810 - val_accuracy: 0.8418\n",
            "Epoch 420/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8603 - val_loss: 0.3799 - val_accuracy: 0.8385\n",
            "Epoch 421/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8589 - val_loss: 0.3805 - val_accuracy: 0.8396\n",
            "Epoch 422/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8590 - val_loss: 0.3795 - val_accuracy: 0.8374\n",
            "Epoch 423/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8587 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 424/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8601 - val_loss: 0.3842 - val_accuracy: 0.8407\n",
            "Epoch 425/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8601 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 426/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3417 - accuracy: 0.8592 - val_loss: 0.3835 - val_accuracy: 0.8385\n",
            "Epoch 427/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8610 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 428/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8594 - val_loss: 0.3804 - val_accuracy: 0.8396\n",
            "Epoch 429/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3415 - accuracy: 0.8597 - val_loss: 0.3801 - val_accuracy: 0.8396\n",
            "Epoch 430/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8603 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 431/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8596 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 432/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8597 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 433/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.8597 - val_loss: 0.3805 - val_accuracy: 0.8407\n",
            "Epoch 434/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.8587 - val_loss: 0.3803 - val_accuracy: 0.8418\n",
            "Epoch 435/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8581 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 436/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3420 - accuracy: 0.8589 - val_loss: 0.3798 - val_accuracy: 0.8385\n",
            "Epoch 437/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8596 - val_loss: 0.3802 - val_accuracy: 0.8396\n",
            "Epoch 438/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8601 - val_loss: 0.3825 - val_accuracy: 0.8385\n",
            "Epoch 439/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8594 - val_loss: 0.3806 - val_accuracy: 0.8418\n",
            "Epoch 440/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8594 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 441/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8590 - val_loss: 0.3795 - val_accuracy: 0.8374\n",
            "Epoch 442/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8599 - val_loss: 0.3800 - val_accuracy: 0.8385\n",
            "Epoch 443/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8614 - val_loss: 0.3807 - val_accuracy: 0.8418\n",
            "Epoch 444/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.8619 - val_loss: 0.3793 - val_accuracy: 0.8429\n",
            "Epoch 445/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8614 - val_loss: 0.3805 - val_accuracy: 0.8418\n",
            "Epoch 446/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8583 - val_loss: 0.3814 - val_accuracy: 0.8396\n",
            "Epoch 447/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8606 - val_loss: 0.3858 - val_accuracy: 0.8407\n",
            "Epoch 448/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8592 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 449/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8576 - val_loss: 0.3815 - val_accuracy: 0.8407\n",
            "Epoch 450/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8596 - val_loss: 0.3825 - val_accuracy: 0.8385\n",
            "Epoch 451/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8592 - val_loss: 0.3805 - val_accuracy: 0.8407\n",
            "Epoch 452/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8597 - val_loss: 0.3877 - val_accuracy: 0.8429\n",
            "Epoch 453/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8580 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 454/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8599 - val_loss: 0.3791 - val_accuracy: 0.8407\n",
            "Epoch 455/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8608 - val_loss: 0.3803 - val_accuracy: 0.8407\n",
            "Epoch 456/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8605 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 457/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8601 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 458/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8596 - val_loss: 0.3814 - val_accuracy: 0.8407\n",
            "Epoch 459/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8590 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 460/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8603 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 461/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3411 - accuracy: 0.8606 - val_loss: 0.3809 - val_accuracy: 0.8407\n",
            "Epoch 462/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8594 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 463/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8587 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 464/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8599 - val_loss: 0.3794 - val_accuracy: 0.8418\n",
            "Epoch 465/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8597 - val_loss: 0.3802 - val_accuracy: 0.8385\n",
            "Epoch 466/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8596 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 467/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8590 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 468/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8601 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 469/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8592 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 470/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8597 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 471/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8587 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 472/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8592 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 473/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8606 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 474/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8610 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 475/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8606 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 476/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8606 - val_loss: 0.3814 - val_accuracy: 0.8407\n",
            "Epoch 477/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8599 - val_loss: 0.3814 - val_accuracy: 0.8396\n",
            "Epoch 478/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8597 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 479/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8597 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 480/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8614 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 481/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3422 - accuracy: 0.8594 - val_loss: 0.3794 - val_accuracy: 0.8374\n",
            "Epoch 482/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8608 - val_loss: 0.3792 - val_accuracy: 0.8396\n",
            "Epoch 483/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8594 - val_loss: 0.3808 - val_accuracy: 0.8407\n",
            "Epoch 484/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8610 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 485/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.8597 - val_loss: 0.3791 - val_accuracy: 0.8396\n",
            "Epoch 486/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8603 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 487/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8605 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 488/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3417 - accuracy: 0.8580 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 489/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3415 - accuracy: 0.8601 - val_loss: 0.3814 - val_accuracy: 0.8385\n",
            "Epoch 490/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8601 - val_loss: 0.3793 - val_accuracy: 0.8396\n",
            "Epoch 491/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8599 - val_loss: 0.3788 - val_accuracy: 0.8385\n",
            "Epoch 492/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3419 - accuracy: 0.8590 - val_loss: 0.3795 - val_accuracy: 0.8385\n",
            "Epoch 493/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8606 - val_loss: 0.3849 - val_accuracy: 0.8385\n",
            "Epoch 494/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8605 - val_loss: 0.3810 - val_accuracy: 0.8407\n",
            "Epoch 495/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.8596 - val_loss: 0.3808 - val_accuracy: 0.8396\n",
            "Epoch 496/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.8597 - val_loss: 0.3812 - val_accuracy: 0.8418\n",
            "Epoch 497/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8612 - val_loss: 0.3802 - val_accuracy: 0.8396\n",
            "Epoch 498/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8596 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 499/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8615 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 500/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8587 - val_loss: 0.3805 - val_accuracy: 0.8440\n",
            "Epoch 501/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8589 - val_loss: 0.3808 - val_accuracy: 0.8429\n",
            "Epoch 502/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8614 - val_loss: 0.3809 - val_accuracy: 0.8418\n",
            "Epoch 503/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8596 - val_loss: 0.3808 - val_accuracy: 0.8418\n",
            "Epoch 504/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8597 - val_loss: 0.3813 - val_accuracy: 0.8418\n",
            "Epoch 505/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8594 - val_loss: 0.3842 - val_accuracy: 0.8396\n",
            "Epoch 506/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8596 - val_loss: 0.3822 - val_accuracy: 0.8385\n",
            "Epoch 507/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8585 - val_loss: 0.3793 - val_accuracy: 0.8418\n",
            "Epoch 508/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8615 - val_loss: 0.3807 - val_accuracy: 0.8407\n",
            "Epoch 509/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8610 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 510/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8594 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 511/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8596 - val_loss: 0.3801 - val_accuracy: 0.8363\n",
            "Epoch 512/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3422 - accuracy: 0.8608 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 513/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8610 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 514/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8610 - val_loss: 0.3816 - val_accuracy: 0.8418\n",
            "Epoch 515/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8601 - val_loss: 0.3804 - val_accuracy: 0.8418\n",
            "Epoch 516/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8603 - val_loss: 0.3797 - val_accuracy: 0.8440\n",
            "Epoch 517/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8601 - val_loss: 0.3815 - val_accuracy: 0.8429\n",
            "Epoch 518/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8599 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 519/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8619 - val_loss: 0.3796 - val_accuracy: 0.8385\n",
            "Epoch 520/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8603 - val_loss: 0.3792 - val_accuracy: 0.8385\n",
            "Epoch 521/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8594 - val_loss: 0.3791 - val_accuracy: 0.8407\n",
            "Epoch 522/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8610 - val_loss: 0.3793 - val_accuracy: 0.8385\n",
            "Epoch 523/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8617 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 524/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8606 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
            "Epoch 525/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8610 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 526/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8608 - val_loss: 0.3836 - val_accuracy: 0.8396\n",
            "Epoch 527/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8608 - val_loss: 0.3790 - val_accuracy: 0.8352\n",
            "Epoch 528/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8615 - val_loss: 0.3811 - val_accuracy: 0.8385\n",
            "Epoch 529/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8606 - val_loss: 0.3808 - val_accuracy: 0.8418\n",
            "Epoch 530/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8612 - val_loss: 0.3871 - val_accuracy: 0.8429\n",
            "Epoch 531/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3413 - accuracy: 0.8594 - val_loss: 0.3807 - val_accuracy: 0.8418\n",
            "Epoch 532/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8621 - val_loss: 0.3817 - val_accuracy: 0.8374\n",
            "Epoch 533/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.8601 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 534/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3399 - accuracy: 0.8612 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 535/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8610 - val_loss: 0.3793 - val_accuracy: 0.8407\n",
            "Epoch 536/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.8599 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 537/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3404 - accuracy: 0.8610 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 538/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8619 - val_loss: 0.3796 - val_accuracy: 0.8407\n",
            "Epoch 539/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8596 - val_loss: 0.3791 - val_accuracy: 0.8385\n",
            "Epoch 540/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8581 - val_loss: 0.3810 - val_accuracy: 0.8385\n",
            "Epoch 541/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3398 - accuracy: 0.8615 - val_loss: 0.3825 - val_accuracy: 0.8418\n",
            "Epoch 542/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8608 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 543/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8614 - val_loss: 0.3811 - val_accuracy: 0.8407\n",
            "Epoch 544/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8617 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 545/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8612 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 546/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8614 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 547/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8603 - val_loss: 0.3801 - val_accuracy: 0.8385\n",
            "Epoch 548/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8615 - val_loss: 0.3814 - val_accuracy: 0.8418\n",
            "Epoch 549/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8606 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 550/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8603 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 551/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8612 - val_loss: 0.3841 - val_accuracy: 0.8396\n",
            "Epoch 552/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8608 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 553/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8592 - val_loss: 0.3796 - val_accuracy: 0.8385\n",
            "Epoch 554/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8605 - val_loss: 0.3808 - val_accuracy: 0.8407\n",
            "Epoch 555/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8608 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 556/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8606 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 557/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8612 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
            "Epoch 558/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8606 - val_loss: 0.3827 - val_accuracy: 0.8440\n",
            "Epoch 559/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8608 - val_loss: 0.3818 - val_accuracy: 0.8440\n",
            "Epoch 560/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8619 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 561/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8592 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 562/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8610 - val_loss: 0.3830 - val_accuracy: 0.8418\n",
            "Epoch 563/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8580 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 564/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8610 - val_loss: 0.3837 - val_accuracy: 0.8418\n",
            "Epoch 565/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8589 - val_loss: 0.3800 - val_accuracy: 0.8440\n",
            "Epoch 566/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8592 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 567/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3401 - accuracy: 0.8612 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 568/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8606 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 569/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8603 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 570/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8619 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 571/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8610 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 572/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3398 - accuracy: 0.8592 - val_loss: 0.3885 - val_accuracy: 0.8396\n",
            "Epoch 573/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8585 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 574/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3418 - accuracy: 0.8610 - val_loss: 0.3796 - val_accuracy: 0.8385\n",
            "Epoch 575/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8601 - val_loss: 0.3792 - val_accuracy: 0.8341\n",
            "Epoch 576/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8597 - val_loss: 0.3807 - val_accuracy: 0.8418\n",
            "Epoch 577/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8608 - val_loss: 0.3841 - val_accuracy: 0.8418\n",
            "Epoch 578/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8612 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 579/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8597 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 580/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8606 - val_loss: 0.3794 - val_accuracy: 0.8418\n",
            "Epoch 581/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8606 - val_loss: 0.3817 - val_accuracy: 0.8429\n",
            "Epoch 582/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3401 - accuracy: 0.8599 - val_loss: 0.3811 - val_accuracy: 0.8418\n",
            "Epoch 583/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3404 - accuracy: 0.8612 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 584/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8603 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 585/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8614 - val_loss: 0.3792 - val_accuracy: 0.8407\n",
            "Epoch 586/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8617 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 587/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3404 - accuracy: 0.8612 - val_loss: 0.3822 - val_accuracy: 0.8429\n",
            "Epoch 588/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8614 - val_loss: 0.3840 - val_accuracy: 0.8418\n",
            "Epoch 589/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8614 - val_loss: 0.3790 - val_accuracy: 0.8396\n",
            "Epoch 590/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8603 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 591/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8615 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 592/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8608 - val_loss: 0.3808 - val_accuracy: 0.8396\n",
            "Epoch 593/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8608 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 594/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8615 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 595/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8610 - val_loss: 0.3804 - val_accuracy: 0.8396\n",
            "Epoch 596/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3400 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 597/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8603 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 598/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8592 - val_loss: 0.3790 - val_accuracy: 0.8396\n",
            "Epoch 599/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8603 - val_loss: 0.3788 - val_accuracy: 0.8407\n",
            "Epoch 600/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8605 - val_loss: 0.3818 - val_accuracy: 0.8407\n",
            "Epoch 601/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8615 - val_loss: 0.3806 - val_accuracy: 0.8451\n",
            "Epoch 602/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8615 - val_loss: 0.3820 - val_accuracy: 0.8451\n",
            "Epoch 603/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8610 - val_loss: 0.3796 - val_accuracy: 0.8407\n",
            "Epoch 604/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8612 - val_loss: 0.3816 - val_accuracy: 0.8418\n",
            "Epoch 605/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8610 - val_loss: 0.3805 - val_accuracy: 0.8407\n",
            "Epoch 606/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8606 - val_loss: 0.3804 - val_accuracy: 0.8418\n",
            "Epoch 607/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8624 - val_loss: 0.3796 - val_accuracy: 0.8407\n",
            "Epoch 608/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8614 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 609/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8610 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 610/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8612 - val_loss: 0.3793 - val_accuracy: 0.8396\n",
            "Epoch 611/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8617 - val_loss: 0.3796 - val_accuracy: 0.8352\n",
            "Epoch 612/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8610 - val_loss: 0.3812 - val_accuracy: 0.8352\n",
            "Epoch 613/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8590 - val_loss: 0.3793 - val_accuracy: 0.8352\n",
            "Epoch 614/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8599 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 615/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8605 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 616/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8601 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 617/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8603 - val_loss: 0.3818 - val_accuracy: 0.8407\n",
            "Epoch 618/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8624 - val_loss: 0.3821 - val_accuracy: 0.8429\n",
            "Epoch 619/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8596 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 620/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8612 - val_loss: 0.3807 - val_accuracy: 0.8418\n",
            "Epoch 621/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8608 - val_loss: 0.3875 - val_accuracy: 0.8418\n",
            "Epoch 622/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8606 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 623/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8623 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 624/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8628 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 625/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8617 - val_loss: 0.3850 - val_accuracy: 0.8429\n",
            "Epoch 626/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8624 - val_loss: 0.3823 - val_accuracy: 0.8440\n",
            "Epoch 627/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8592 - val_loss: 0.3792 - val_accuracy: 0.8396\n",
            "Epoch 628/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8608 - val_loss: 0.3790 - val_accuracy: 0.8363\n",
            "Epoch 629/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8581 - val_loss: 0.3792 - val_accuracy: 0.8418\n",
            "Epoch 630/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8621 - val_loss: 0.3826 - val_accuracy: 0.8418\n",
            "Epoch 631/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8606 - val_loss: 0.3838 - val_accuracy: 0.8418\n",
            "Epoch 632/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8615 - val_loss: 0.3817 - val_accuracy: 0.8462\n",
            "Epoch 633/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8617 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 634/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8590 - val_loss: 0.3799 - val_accuracy: 0.8352\n",
            "Epoch 635/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8617 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 636/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.8596 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 637/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8619 - val_loss: 0.3825 - val_accuracy: 0.8418\n",
            "Epoch 638/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8606 - val_loss: 0.3791 - val_accuracy: 0.8396\n",
            "Epoch 639/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.8614 - val_loss: 0.3795 - val_accuracy: 0.8352\n",
            "Epoch 640/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3397 - accuracy: 0.8601 - val_loss: 0.3801 - val_accuracy: 0.8462\n",
            "Epoch 641/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8606 - val_loss: 0.3794 - val_accuracy: 0.8418\n",
            "Epoch 642/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8623 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
            "Epoch 643/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8612 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 644/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8599 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 645/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8606 - val_loss: 0.3789 - val_accuracy: 0.8396\n",
            "Epoch 646/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3404 - accuracy: 0.8612 - val_loss: 0.3830 - val_accuracy: 0.8418\n",
            "Epoch 647/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8610 - val_loss: 0.3831 - val_accuracy: 0.8429\n",
            "Epoch 648/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8608 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 649/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8606 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 650/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8597 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 651/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8612 - val_loss: 0.3812 - val_accuracy: 0.8462\n",
            "Epoch 652/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8608 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 653/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8626 - val_loss: 0.3806 - val_accuracy: 0.8429\n",
            "Epoch 654/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8596 - val_loss: 0.3836 - val_accuracy: 0.8429\n",
            "Epoch 655/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8623 - val_loss: 0.3824 - val_accuracy: 0.8429\n",
            "Epoch 656/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3394 - accuracy: 0.8615 - val_loss: 0.3837 - val_accuracy: 0.8429\n",
            "Epoch 657/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8605 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 658/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3388 - accuracy: 0.8619 - val_loss: 0.3813 - val_accuracy: 0.8473\n",
            "Epoch 659/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8614 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 660/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8608 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 661/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3394 - accuracy: 0.8605 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 662/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8599 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 663/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8606 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 664/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8614 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 665/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3391 - accuracy: 0.8610 - val_loss: 0.3790 - val_accuracy: 0.8396\n",
            "Epoch 666/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8612 - val_loss: 0.3790 - val_accuracy: 0.8341\n",
            "Epoch 667/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8589 - val_loss: 0.3813 - val_accuracy: 0.8473\n",
            "Epoch 668/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8626 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
            "Epoch 669/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8623 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 670/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8619 - val_loss: 0.3806 - val_accuracy: 0.8352\n",
            "Epoch 671/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8615 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 672/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8614 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 673/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3387 - accuracy: 0.8610 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
            "Epoch 674/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8601 - val_loss: 0.3793 - val_accuracy: 0.8363\n",
            "Epoch 675/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8612 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 676/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8603 - val_loss: 0.3803 - val_accuracy: 0.8418\n",
            "Epoch 677/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3400 - accuracy: 0.8605 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 678/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8610 - val_loss: 0.3792 - val_accuracy: 0.8385\n",
            "Epoch 679/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8606 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 680/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3386 - accuracy: 0.8617 - val_loss: 0.3829 - val_accuracy: 0.8418\n",
            "Epoch 681/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8619 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 682/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8615 - val_loss: 0.3824 - val_accuracy: 0.8429\n",
            "Epoch 683/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8612 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 684/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8612 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 685/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8617 - val_loss: 0.3794 - val_accuracy: 0.8429\n",
            "Epoch 686/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8610 - val_loss: 0.3792 - val_accuracy: 0.8407\n",
            "Epoch 687/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8606 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 688/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8605 - val_loss: 0.3792 - val_accuracy: 0.8363\n",
            "Epoch 689/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8610 - val_loss: 0.3791 - val_accuracy: 0.8396\n",
            "Epoch 690/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8619 - val_loss: 0.3836 - val_accuracy: 0.8418\n",
            "Epoch 691/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8621 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 692/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8628 - val_loss: 0.3796 - val_accuracy: 0.8429\n",
            "Epoch 693/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8614 - val_loss: 0.3799 - val_accuracy: 0.8429\n",
            "Epoch 694/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8621 - val_loss: 0.3804 - val_accuracy: 0.8451\n",
            "Epoch 695/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8599 - val_loss: 0.3793 - val_accuracy: 0.8407\n",
            "Epoch 696/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8624 - val_loss: 0.3789 - val_accuracy: 0.8407\n",
            "Epoch 697/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8614 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 698/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8612 - val_loss: 0.3791 - val_accuracy: 0.8407\n",
            "Epoch 699/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8628 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
            "Epoch 700/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8608 - val_loss: 0.3795 - val_accuracy: 0.8429\n",
            "Epoch 701/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8619 - val_loss: 0.3812 - val_accuracy: 0.8473\n",
            "Epoch 702/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3794 - val_accuracy: 0.8374\n",
            "Epoch 703/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8619 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 704/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8630 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 705/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8617 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 706/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3383 - accuracy: 0.8619 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 707/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8623 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 708/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8606 - val_loss: 0.3789 - val_accuracy: 0.8407\n",
            "Epoch 709/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8596 - val_loss: 0.3791 - val_accuracy: 0.8374\n",
            "Epoch 710/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8606 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 711/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8610 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 712/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8614 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 713/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8592 - val_loss: 0.3791 - val_accuracy: 0.8418\n",
            "Epoch 714/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8624 - val_loss: 0.3792 - val_accuracy: 0.8429\n",
            "Epoch 715/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8619 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 716/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3388 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 717/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8605 - val_loss: 0.3808 - val_accuracy: 0.8451\n",
            "Epoch 718/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8592 - val_loss: 0.3790 - val_accuracy: 0.8363\n",
            "Epoch 719/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8617 - val_loss: 0.3790 - val_accuracy: 0.8341\n",
            "Epoch 720/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8603 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 721/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8601 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 722/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8621 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 723/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8615 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 724/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8635 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
            "Epoch 725/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8619 - val_loss: 0.3803 - val_accuracy: 0.8429\n",
            "Epoch 726/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8614 - val_loss: 0.3792 - val_accuracy: 0.8407\n",
            "Epoch 727/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8624 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 728/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8612 - val_loss: 0.3794 - val_accuracy: 0.8407\n",
            "Epoch 729/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3395 - accuracy: 0.8581 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 730/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8614 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 731/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8612 - val_loss: 0.3884 - val_accuracy: 0.8451\n",
            "Epoch 732/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8585 - val_loss: 0.3830 - val_accuracy: 0.8440\n",
            "Epoch 733/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8624 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 734/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8617 - val_loss: 0.3804 - val_accuracy: 0.8429\n",
            "Epoch 735/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8630 - val_loss: 0.3809 - val_accuracy: 0.8440\n",
            "Epoch 736/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8615 - val_loss: 0.3804 - val_accuracy: 0.8429\n",
            "Epoch 737/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8621 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 738/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8615 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 739/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 740/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8614 - val_loss: 0.3843 - val_accuracy: 0.8418\n",
            "Epoch 741/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8635 - val_loss: 0.3791 - val_accuracy: 0.8407\n",
            "Epoch 742/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8615 - val_loss: 0.3813 - val_accuracy: 0.8451\n",
            "Epoch 743/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8621 - val_loss: 0.3813 - val_accuracy: 0.8473\n",
            "Epoch 744/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3379 - accuracy: 0.8624 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 745/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8621 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 746/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8623 - val_loss: 0.3795 - val_accuracy: 0.8352\n",
            "Epoch 747/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3399 - accuracy: 0.8605 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 748/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8624 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 749/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3390 - accuracy: 0.8619 - val_loss: 0.3825 - val_accuracy: 0.8462\n",
            "Epoch 750/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8605 - val_loss: 0.3816 - val_accuracy: 0.8429\n",
            "Epoch 751/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8623 - val_loss: 0.3798 - val_accuracy: 0.8429\n",
            "Epoch 752/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8623 - val_loss: 0.3836 - val_accuracy: 0.8451\n",
            "Epoch 753/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8606 - val_loss: 0.3839 - val_accuracy: 0.8429\n",
            "Epoch 754/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3382 - accuracy: 0.8612 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 755/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8610 - val_loss: 0.3849 - val_accuracy: 0.8418\n",
            "Epoch 756/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8606 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 757/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8610 - val_loss: 0.3813 - val_accuracy: 0.8451\n",
            "Epoch 758/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8637 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 759/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3388 - accuracy: 0.8605 - val_loss: 0.3808 - val_accuracy: 0.8484\n",
            "Epoch 760/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3403 - accuracy: 0.8601 - val_loss: 0.3865 - val_accuracy: 0.8407\n",
            "Epoch 761/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8605 - val_loss: 0.3804 - val_accuracy: 0.8451\n",
            "Epoch 762/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3388 - accuracy: 0.8597 - val_loss: 0.3795 - val_accuracy: 0.8418\n",
            "Epoch 763/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8451\n",
            "Epoch 764/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8619 - val_loss: 0.3794 - val_accuracy: 0.8418\n",
            "Epoch 765/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8623 - val_loss: 0.3798 - val_accuracy: 0.8429\n",
            "Epoch 766/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8621 - val_loss: 0.3811 - val_accuracy: 0.8462\n",
            "Epoch 767/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8624 - val_loss: 0.3805 - val_accuracy: 0.8440\n",
            "Epoch 768/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8617 - val_loss: 0.3795 - val_accuracy: 0.8440\n",
            "Epoch 769/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8617 - val_loss: 0.3790 - val_accuracy: 0.8407\n",
            "Epoch 770/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8592 - val_loss: 0.3812 - val_accuracy: 0.8451\n",
            "Epoch 771/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8628 - val_loss: 0.3825 - val_accuracy: 0.8462\n",
            "Epoch 772/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8626 - val_loss: 0.3817 - val_accuracy: 0.8462\n",
            "Epoch 773/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8624 - val_loss: 0.3818 - val_accuracy: 0.8473\n",
            "Epoch 774/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8590 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 775/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8603 - val_loss: 0.3803 - val_accuracy: 0.8341\n",
            "Epoch 776/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8624 - val_loss: 0.3822 - val_accuracy: 0.8451\n",
            "Epoch 777/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 778/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8626 - val_loss: 0.3824 - val_accuracy: 0.8473\n",
            "Epoch 779/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8623 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 780/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8623 - val_loss: 0.3811 - val_accuracy: 0.8429\n",
            "Epoch 781/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8628 - val_loss: 0.3797 - val_accuracy: 0.8429\n",
            "Epoch 782/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8623 - val_loss: 0.3834 - val_accuracy: 0.8451\n",
            "Epoch 783/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8640 - val_loss: 0.3816 - val_accuracy: 0.8473\n",
            "Epoch 784/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3384 - accuracy: 0.8615 - val_loss: 0.3822 - val_accuracy: 0.8451\n",
            "Epoch 785/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8621 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
            "Epoch 786/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8624 - val_loss: 0.3799 - val_accuracy: 0.8451\n",
            "Epoch 787/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8637 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 788/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8615 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 789/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8631 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 790/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8617 - val_loss: 0.3809 - val_accuracy: 0.8440\n",
            "Epoch 791/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8626 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 792/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3389 - accuracy: 0.8592 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 793/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.8617 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 794/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8621 - val_loss: 0.3799 - val_accuracy: 0.8429\n",
            "Epoch 795/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8617 - val_loss: 0.3807 - val_accuracy: 0.8440\n",
            "Epoch 796/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8623 - val_loss: 0.3844 - val_accuracy: 0.8440\n",
            "Epoch 797/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8612 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 798/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8633 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 799/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8619 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 800/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8621 - val_loss: 0.3837 - val_accuracy: 0.8451\n",
            "Epoch 801/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8612 - val_loss: 0.3804 - val_accuracy: 0.8451\n",
            "Epoch 802/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8615 - val_loss: 0.3796 - val_accuracy: 0.8440\n",
            "Epoch 803/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8640 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 804/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8633 - val_loss: 0.3834 - val_accuracy: 0.8451\n",
            "Epoch 805/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3795 - val_accuracy: 0.8462\n",
            "Epoch 806/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8631 - val_loss: 0.3808 - val_accuracy: 0.8440\n",
            "Epoch 807/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8640 - val_loss: 0.3864 - val_accuracy: 0.8440\n",
            "Epoch 808/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8603 - val_loss: 0.3794 - val_accuracy: 0.8341\n",
            "Epoch 809/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8623 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 810/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8628 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 811/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 812/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8630 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 813/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8606 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 814/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 815/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8621 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 816/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8628 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
            "Epoch 817/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8628 - val_loss: 0.3803 - val_accuracy: 0.8429\n",
            "Epoch 818/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8630 - val_loss: 0.3801 - val_accuracy: 0.8440\n",
            "Epoch 819/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8615 - val_loss: 0.3824 - val_accuracy: 0.8462\n",
            "Epoch 820/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8648 - val_loss: 0.3829 - val_accuracy: 0.8462\n",
            "Epoch 821/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8612 - val_loss: 0.3810 - val_accuracy: 0.8440\n",
            "Epoch 822/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8615 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 823/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8630 - val_loss: 0.3821 - val_accuracy: 0.8451\n",
            "Epoch 824/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8612 - val_loss: 0.3801 - val_accuracy: 0.8440\n",
            "Epoch 825/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8606 - val_loss: 0.3801 - val_accuracy: 0.8440\n",
            "Epoch 826/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8624 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
            "Epoch 827/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8642 - val_loss: 0.3846 - val_accuracy: 0.8418\n",
            "Epoch 828/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8617 - val_loss: 0.3799 - val_accuracy: 0.8451\n",
            "Epoch 829/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3840 - val_accuracy: 0.8429\n",
            "Epoch 830/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8610 - val_loss: 0.3798 - val_accuracy: 0.8363\n",
            "Epoch 831/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8626 - val_loss: 0.3808 - val_accuracy: 0.8440\n",
            "Epoch 832/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8610 - val_loss: 0.3810 - val_accuracy: 0.8440\n",
            "Epoch 833/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8610 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 834/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8612 - val_loss: 0.3839 - val_accuracy: 0.8440\n",
            "Epoch 835/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8615 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 836/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8623 - val_loss: 0.3812 - val_accuracy: 0.8429\n",
            "Epoch 837/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8619 - val_loss: 0.3830 - val_accuracy: 0.8440\n",
            "Epoch 838/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3368 - accuracy: 0.8628 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 839/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8628 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 840/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8615 - val_loss: 0.3798 - val_accuracy: 0.8451\n",
            "Epoch 841/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 842/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8610 - val_loss: 0.3848 - val_accuracy: 0.8429\n",
            "Epoch 843/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8624 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 844/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8583 - val_loss: 0.3808 - val_accuracy: 0.8374\n",
            "Epoch 845/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8606 - val_loss: 0.3798 - val_accuracy: 0.8440\n",
            "Epoch 846/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8621 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 847/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8610 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 848/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8624 - val_loss: 0.3827 - val_accuracy: 0.8440\n",
            "Epoch 849/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8597 - val_loss: 0.3876 - val_accuracy: 0.8440\n",
            "Epoch 850/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8608 - val_loss: 0.3803 - val_accuracy: 0.8440\n",
            "Epoch 851/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8628 - val_loss: 0.3851 - val_accuracy: 0.8440\n",
            "Epoch 852/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 853/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8623 - val_loss: 0.3814 - val_accuracy: 0.8440\n",
            "Epoch 854/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8621 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 855/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8614 - val_loss: 0.3794 - val_accuracy: 0.8440\n",
            "Epoch 856/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8626 - val_loss: 0.3841 - val_accuracy: 0.8418\n",
            "Epoch 857/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8621 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
            "Epoch 858/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3378 - accuracy: 0.8621 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 859/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8628 - val_loss: 0.3799 - val_accuracy: 0.8396\n",
            "Epoch 860/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3368 - accuracy: 0.8619 - val_loss: 0.3793 - val_accuracy: 0.8374\n",
            "Epoch 861/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3370 - accuracy: 0.8601 - val_loss: 0.3802 - val_accuracy: 0.8451\n",
            "Epoch 862/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8633 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 863/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8631 - val_loss: 0.3805 - val_accuracy: 0.8462\n",
            "Epoch 864/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3366 - accuracy: 0.8614 - val_loss: 0.3850 - val_accuracy: 0.8451\n",
            "Epoch 865/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3371 - accuracy: 0.8624 - val_loss: 0.3845 - val_accuracy: 0.8418\n",
            "Epoch 866/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3381 - accuracy: 0.8623 - val_loss: 0.3849 - val_accuracy: 0.8418\n",
            "Epoch 867/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8612 - val_loss: 0.3823 - val_accuracy: 0.8429\n",
            "Epoch 868/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8623 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 869/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8621 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 870/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8623 - val_loss: 0.3818 - val_accuracy: 0.8429\n",
            "Epoch 871/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8623 - val_loss: 0.3797 - val_accuracy: 0.8352\n",
            "Epoch 872/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8614 - val_loss: 0.3798 - val_accuracy: 0.8385\n",
            "Epoch 873/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3371 - accuracy: 0.8619 - val_loss: 0.3806 - val_accuracy: 0.8451\n",
            "Epoch 874/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8626 - val_loss: 0.3808 - val_accuracy: 0.8462\n",
            "Epoch 875/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8608 - val_loss: 0.3841 - val_accuracy: 0.8429\n",
            "Epoch 876/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8628 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 877/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8623 - val_loss: 0.3808 - val_accuracy: 0.8451\n",
            "Epoch 878/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8624 - val_loss: 0.3797 - val_accuracy: 0.8440\n",
            "Epoch 879/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8630 - val_loss: 0.3812 - val_accuracy: 0.8451\n",
            "Epoch 880/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3365 - accuracy: 0.8610 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 881/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8619 - val_loss: 0.3813 - val_accuracy: 0.8462\n",
            "Epoch 882/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8623 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 883/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8635 - val_loss: 0.3842 - val_accuracy: 0.8418\n",
            "Epoch 884/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8610 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 885/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8623 - val_loss: 0.3809 - val_accuracy: 0.8451\n",
            "Epoch 886/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8614 - val_loss: 0.3799 - val_accuracy: 0.8440\n",
            "Epoch 887/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8617 - val_loss: 0.3801 - val_accuracy: 0.8396\n",
            "Epoch 888/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8605 - val_loss: 0.3819 - val_accuracy: 0.8451\n",
            "Epoch 889/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.8633 - val_loss: 0.3816 - val_accuracy: 0.8440\n",
            "Epoch 890/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8626 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 891/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8440\n",
            "Epoch 892/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8621 - val_loss: 0.3870 - val_accuracy: 0.8451\n",
            "Epoch 893/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8619 - val_loss: 0.3866 - val_accuracy: 0.8396\n",
            "Epoch 894/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8628 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 895/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8624 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 896/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8630 - val_loss: 0.3834 - val_accuracy: 0.8396\n",
            "Epoch 897/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8630 - val_loss: 0.3798 - val_accuracy: 0.8440\n",
            "Epoch 898/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8610 - val_loss: 0.3804 - val_accuracy: 0.8385\n",
            "Epoch 899/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8628 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
            "Epoch 900/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8619 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
            "Epoch 901/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8624 - val_loss: 0.3841 - val_accuracy: 0.8440\n",
            "Epoch 902/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8628 - val_loss: 0.3821 - val_accuracy: 0.8451\n",
            "Epoch 903/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8612 - val_loss: 0.3799 - val_accuracy: 0.8451\n",
            "Epoch 904/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8621 - val_loss: 0.3828 - val_accuracy: 0.8429\n",
            "Epoch 905/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8614 - val_loss: 0.3830 - val_accuracy: 0.8429\n",
            "Epoch 906/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8610 - val_loss: 0.3811 - val_accuracy: 0.8451\n",
            "Epoch 907/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8628 - val_loss: 0.3794 - val_accuracy: 0.8429\n",
            "Epoch 908/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8639 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 909/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8608 - val_loss: 0.3793 - val_accuracy: 0.8440\n",
            "Epoch 910/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8623 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 911/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8633 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 912/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8623 - val_loss: 0.3808 - val_accuracy: 0.8451\n",
            "Epoch 913/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8621 - val_loss: 0.3793 - val_accuracy: 0.8429\n",
            "Epoch 914/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.8589 - val_loss: 0.3803 - val_accuracy: 0.8374\n",
            "Epoch 915/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8633 - val_loss: 0.3800 - val_accuracy: 0.8451\n",
            "Epoch 916/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8628 - val_loss: 0.3797 - val_accuracy: 0.8440\n",
            "Epoch 917/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8615 - val_loss: 0.3805 - val_accuracy: 0.8462\n",
            "Epoch 918/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8612 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 919/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8624 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 920/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8623 - val_loss: 0.3841 - val_accuracy: 0.8407\n",
            "Epoch 921/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8624 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 922/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8621 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 923/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8621 - val_loss: 0.3805 - val_accuracy: 0.8462\n",
            "Epoch 924/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8621 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 925/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8617 - val_loss: 0.3832 - val_accuracy: 0.8429\n",
            "Epoch 926/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8617 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 927/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8623 - val_loss: 0.3796 - val_accuracy: 0.8440\n",
            "Epoch 928/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8630 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 929/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8585 - val_loss: 0.3793 - val_accuracy: 0.8396\n",
            "Epoch 930/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3377 - accuracy: 0.8608 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 931/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8624 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 932/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8612 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 933/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8633 - val_loss: 0.3815 - val_accuracy: 0.8440\n",
            "Epoch 934/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8623 - val_loss: 0.3822 - val_accuracy: 0.8451\n",
            "Epoch 935/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3366 - accuracy: 0.8603 - val_loss: 0.3804 - val_accuracy: 0.8418\n",
            "Epoch 936/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8615 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 937/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8451\n",
            "Epoch 938/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8619 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 939/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8637 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 940/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8624 - val_loss: 0.3828 - val_accuracy: 0.8440\n",
            "Epoch 941/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8617 - val_loss: 0.3799 - val_accuracy: 0.8451\n",
            "Epoch 942/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8640 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 943/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8624 - val_loss: 0.3832 - val_accuracy: 0.8451\n",
            "Epoch 944/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8621 - val_loss: 0.3839 - val_accuracy: 0.8440\n",
            "Epoch 945/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8635 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 946/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8623 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 947/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8614 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 948/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8615 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 949/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8623 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 950/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8619 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 951/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8605 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 952/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8633 - val_loss: 0.3854 - val_accuracy: 0.8440\n",
            "Epoch 953/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8612 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 954/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8623 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 955/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8623 - val_loss: 0.3828 - val_accuracy: 0.8440\n",
            "Epoch 956/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8619 - val_loss: 0.3815 - val_accuracy: 0.8473\n",
            "Epoch 957/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8637 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 958/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8601 - val_loss: 0.3881 - val_accuracy: 0.8429\n",
            "Epoch 959/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8631 - val_loss: 0.3849 - val_accuracy: 0.8429\n",
            "Epoch 960/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8599 - val_loss: 0.3804 - val_accuracy: 0.8451\n",
            "Epoch 961/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8621 - val_loss: 0.3815 - val_accuracy: 0.8451\n",
            "Epoch 962/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8630 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 963/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8614 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 964/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8631 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 965/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8623 - val_loss: 0.3805 - val_accuracy: 0.8451\n",
            "Epoch 966/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8623 - val_loss: 0.3848 - val_accuracy: 0.8418\n",
            "Epoch 967/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8624 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 968/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8633 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 969/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8644 - val_loss: 0.3845 - val_accuracy: 0.8429\n",
            "Epoch 970/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8624 - val_loss: 0.3826 - val_accuracy: 0.8462\n",
            "Epoch 971/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8619 - val_loss: 0.3800 - val_accuracy: 0.8451\n",
            "Epoch 972/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8615 - val_loss: 0.3819 - val_accuracy: 0.8473\n",
            "Epoch 973/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3371 - accuracy: 0.8623 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 974/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8619 - val_loss: 0.3811 - val_accuracy: 0.8451\n",
            "Epoch 975/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8633 - val_loss: 0.3800 - val_accuracy: 0.8440\n",
            "Epoch 976/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8451\n",
            "Epoch 977/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8605 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 978/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8623 - val_loss: 0.3796 - val_accuracy: 0.8407\n",
            "Epoch 979/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8603 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 980/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8619 - val_loss: 0.3798 - val_accuracy: 0.8440\n",
            "Epoch 981/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8617 - val_loss: 0.3836 - val_accuracy: 0.8440\n",
            "Epoch 982/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8631 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 983/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3796 - val_accuracy: 0.8407\n",
            "Epoch 984/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8599 - val_loss: 0.3799 - val_accuracy: 0.8396\n",
            "Epoch 985/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 986/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3370 - accuracy: 0.8589 - val_loss: 0.3800 - val_accuracy: 0.8440\n",
            "Epoch 987/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8633 - val_loss: 0.3838 - val_accuracy: 0.8429\n",
            "Epoch 988/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8615 - val_loss: 0.3864 - val_accuracy: 0.8440\n",
            "Epoch 989/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8628 - val_loss: 0.3825 - val_accuracy: 0.8429\n",
            "Epoch 990/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8617 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 991/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8614 - val_loss: 0.3797 - val_accuracy: 0.8374\n",
            "Epoch 992/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8623 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 993/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8621 - val_loss: 0.3864 - val_accuracy: 0.8429\n",
            "Epoch 994/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.8603 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 995/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.8615 - val_loss: 0.3812 - val_accuracy: 0.8473\n",
            "Epoch 996/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 997/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8621 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 998/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8644 - val_loss: 0.3826 - val_accuracy: 0.8462\n",
            "Epoch 999/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8628 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 1000/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8610 - val_loss: 0.3802 - val_accuracy: 0.8451\n",
            "Epoch 1001/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8617 - val_loss: 0.3858 - val_accuracy: 0.8440\n",
            "Epoch 1002/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8635 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 1003/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3363 - accuracy: 0.8614 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 1004/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8615 - val_loss: 0.3804 - val_accuracy: 0.8451\n",
            "Epoch 1005/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8451\n",
            "Epoch 1006/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8605 - val_loss: 0.3802 - val_accuracy: 0.8451\n",
            "Epoch 1007/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8626 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 1008/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3795 - val_accuracy: 0.8440\n",
            "Epoch 1009/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8642 - val_loss: 0.3871 - val_accuracy: 0.8462\n",
            "Epoch 1010/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8614 - val_loss: 0.3882 - val_accuracy: 0.8418\n",
            "Epoch 1011/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3380 - accuracy: 0.8612 - val_loss: 0.3809 - val_accuracy: 0.8462\n",
            "Epoch 1012/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8631 - val_loss: 0.3802 - val_accuracy: 0.8451\n",
            "Epoch 1013/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8631 - val_loss: 0.3806 - val_accuracy: 0.8462\n",
            "Epoch 1014/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3355 - accuracy: 0.8619 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 1015/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8451\n",
            "Epoch 1016/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8621 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 1017/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8615 - val_loss: 0.3820 - val_accuracy: 0.8473\n",
            "Epoch 1018/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8624 - val_loss: 0.3806 - val_accuracy: 0.8451\n",
            "Epoch 1019/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8626 - val_loss: 0.3821 - val_accuracy: 0.8451\n",
            "Epoch 1020/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8630 - val_loss: 0.3791 - val_accuracy: 0.8396\n",
            "Epoch 1021/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8614 - val_loss: 0.3790 - val_accuracy: 0.8418\n",
            "Epoch 1022/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8630 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 1023/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8626 - val_loss: 0.3799 - val_accuracy: 0.8462\n",
            "Epoch 1024/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8623 - val_loss: 0.3814 - val_accuracy: 0.8462\n",
            "Epoch 1025/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8601 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 1026/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8635 - val_loss: 0.3797 - val_accuracy: 0.8462\n",
            "Epoch 1027/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8612 - val_loss: 0.3814 - val_accuracy: 0.8462\n",
            "Epoch 1028/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8615 - val_loss: 0.3791 - val_accuracy: 0.8440\n",
            "Epoch 1029/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8628 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 1030/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8626 - val_loss: 0.3799 - val_accuracy: 0.8451\n",
            "Epoch 1031/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8617 - val_loss: 0.3841 - val_accuracy: 0.8429\n",
            "Epoch 1032/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8624 - val_loss: 0.3803 - val_accuracy: 0.8451\n",
            "Epoch 1033/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8619 - val_loss: 0.3806 - val_accuracy: 0.8473\n",
            "Epoch 1034/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8630 - val_loss: 0.3837 - val_accuracy: 0.8451\n",
            "Epoch 1035/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8635 - val_loss: 0.3808 - val_accuracy: 0.8462\n",
            "Epoch 1036/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8619 - val_loss: 0.3791 - val_accuracy: 0.8418\n",
            "Epoch 1037/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8630 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 1038/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8628 - val_loss: 0.3814 - val_accuracy: 0.8462\n",
            "Epoch 1039/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 1040/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8631 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 1041/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8614 - val_loss: 0.3828 - val_accuracy: 0.8484\n",
            "Epoch 1042/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8621 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 1043/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8626 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1044/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8621 - val_loss: 0.3817 - val_accuracy: 0.8462\n",
            "Epoch 1045/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8385\n",
            "Epoch 1046/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8617 - val_loss: 0.3789 - val_accuracy: 0.8374\n",
            "Epoch 1047/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8619 - val_loss: 0.3879 - val_accuracy: 0.8429\n",
            "Epoch 1048/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8646 - val_loss: 0.3820 - val_accuracy: 0.8462\n",
            "Epoch 1049/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8619 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 1050/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8617 - val_loss: 0.3789 - val_accuracy: 0.8396\n",
            "Epoch 1051/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8631 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 1052/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8630 - val_loss: 0.3789 - val_accuracy: 0.8418\n",
            "Epoch 1053/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.8626 - val_loss: 0.3790 - val_accuracy: 0.8396\n",
            "Epoch 1054/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8615 - val_loss: 0.3812 - val_accuracy: 0.8451\n",
            "Epoch 1055/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8623 - val_loss: 0.3796 - val_accuracy: 0.8429\n",
            "Epoch 1056/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8612 - val_loss: 0.3808 - val_accuracy: 0.8462\n",
            "Epoch 1057/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3345 - accuracy: 0.8630 - val_loss: 0.3793 - val_accuracy: 0.8385\n",
            "Epoch 1058/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8630 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 1059/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8630 - val_loss: 0.3811 - val_accuracy: 0.8462\n",
            "Epoch 1060/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8614 - val_loss: 0.3865 - val_accuracy: 0.8429\n",
            "Epoch 1061/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8615 - val_loss: 0.3798 - val_accuracy: 0.8429\n",
            "Epoch 1062/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8614 - val_loss: 0.3796 - val_accuracy: 0.8440\n",
            "Epoch 1063/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8621 - val_loss: 0.3790 - val_accuracy: 0.8407\n",
            "Epoch 1064/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8615 - val_loss: 0.3819 - val_accuracy: 0.8473\n",
            "Epoch 1065/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8621 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 1066/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8619 - val_loss: 0.3787 - val_accuracy: 0.8407\n",
            "Epoch 1067/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8619 - val_loss: 0.3809 - val_accuracy: 0.8440\n",
            "Epoch 1068/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8626 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 1069/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8623 - val_loss: 0.3791 - val_accuracy: 0.8396\n",
            "Epoch 1070/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8623 - val_loss: 0.3794 - val_accuracy: 0.8418\n",
            "Epoch 1071/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8621 - val_loss: 0.3814 - val_accuracy: 0.8451\n",
            "Epoch 1072/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8628 - val_loss: 0.3823 - val_accuracy: 0.8451\n",
            "Epoch 1073/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8619 - val_loss: 0.3802 - val_accuracy: 0.8440\n",
            "Epoch 1074/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8633 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 1075/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8623 - val_loss: 0.3804 - val_accuracy: 0.8462\n",
            "Epoch 1076/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8619 - val_loss: 0.3789 - val_accuracy: 0.8407\n",
            "Epoch 1077/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8601 - val_loss: 0.3845 - val_accuracy: 0.8429\n",
            "Epoch 1078/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8619 - val_loss: 0.3802 - val_accuracy: 0.8440\n",
            "Epoch 1079/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8631 - val_loss: 0.3792 - val_accuracy: 0.8418\n",
            "Epoch 1080/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3349 - accuracy: 0.8619 - val_loss: 0.3790 - val_accuracy: 0.8396\n",
            "Epoch 1081/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8615 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 1082/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8628 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 1083/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8626 - val_loss: 0.3792 - val_accuracy: 0.8429\n",
            "Epoch 1084/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8614 - val_loss: 0.3801 - val_accuracy: 0.8440\n",
            "Epoch 1085/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8621 - val_loss: 0.3792 - val_accuracy: 0.8407\n",
            "Epoch 1086/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8619 - val_loss: 0.3793 - val_accuracy: 0.8407\n",
            "Epoch 1087/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8615 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 1088/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8624 - val_loss: 0.3808 - val_accuracy: 0.8462\n",
            "Epoch 1089/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8628 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 1090/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8624 - val_loss: 0.3815 - val_accuracy: 0.8473\n",
            "Epoch 1091/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8623 - val_loss: 0.3799 - val_accuracy: 0.8429\n",
            "Epoch 1092/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8601 - val_loss: 0.3791 - val_accuracy: 0.8429\n",
            "Epoch 1093/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8610 - val_loss: 0.3806 - val_accuracy: 0.8473\n",
            "Epoch 1094/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8429\n",
            "Epoch 1095/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8635 - val_loss: 0.3830 - val_accuracy: 0.8462\n",
            "Epoch 1096/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.8614 - val_loss: 0.3855 - val_accuracy: 0.8451\n",
            "Epoch 1097/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8631 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 1098/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8619 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
            "Epoch 1099/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8597 - val_loss: 0.3815 - val_accuracy: 0.8484\n",
            "Epoch 1100/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8597 - val_loss: 0.3810 - val_accuracy: 0.8440\n",
            "Epoch 1101/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3798 - val_accuracy: 0.8440\n",
            "Epoch 1102/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8606 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
            "Epoch 1103/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3342 - accuracy: 0.8639 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 1104/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8630 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 1105/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8621 - val_loss: 0.3867 - val_accuracy: 0.8462\n",
            "Epoch 1106/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8630 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 1107/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8628 - val_loss: 0.3799 - val_accuracy: 0.8429\n",
            "Epoch 1108/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3795 - val_accuracy: 0.8396\n",
            "Epoch 1109/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8617 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 1110/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8614 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 1111/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8624 - val_loss: 0.3823 - val_accuracy: 0.8462\n",
            "Epoch 1112/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8626 - val_loss: 0.3792 - val_accuracy: 0.8407\n",
            "Epoch 1113/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3355 - accuracy: 0.8617 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 1114/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8624 - val_loss: 0.3851 - val_accuracy: 0.8451\n",
            "Epoch 1115/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3795 - val_accuracy: 0.8429\n",
            "Epoch 1116/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8626 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 1117/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8628 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1118/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8614 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 1119/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8623 - val_loss: 0.3850 - val_accuracy: 0.8429\n",
            "Epoch 1120/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8644 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 1121/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8623 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 1122/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8623 - val_loss: 0.3814 - val_accuracy: 0.8440\n",
            "Epoch 1123/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8617 - val_loss: 0.3818 - val_accuracy: 0.8484\n",
            "Epoch 1124/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8615 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 1125/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8623 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 1126/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8628 - val_loss: 0.3807 - val_accuracy: 0.8440\n",
            "Epoch 1127/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8624 - val_loss: 0.3803 - val_accuracy: 0.8462\n",
            "Epoch 1128/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
            "Epoch 1129/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8484\n",
            "Epoch 1130/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8617 - val_loss: 0.3806 - val_accuracy: 0.8495\n",
            "Epoch 1131/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8626 - val_loss: 0.3808 - val_accuracy: 0.8418\n",
            "Epoch 1132/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3347 - accuracy: 0.8630 - val_loss: 0.3808 - val_accuracy: 0.8440\n",
            "Epoch 1133/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8617 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 1134/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3349 - accuracy: 0.8624 - val_loss: 0.3807 - val_accuracy: 0.8440\n",
            "Epoch 1135/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8610 - val_loss: 0.3795 - val_accuracy: 0.8429\n",
            "Epoch 1136/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8601 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 1137/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8633 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 1138/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.8630 - val_loss: 0.3808 - val_accuracy: 0.8462\n",
            "Epoch 1139/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8628 - val_loss: 0.3811 - val_accuracy: 0.8429\n",
            "Epoch 1140/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8633 - val_loss: 0.3820 - val_accuracy: 0.8484\n",
            "Epoch 1141/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8624 - val_loss: 0.3809 - val_accuracy: 0.8473\n",
            "Epoch 1142/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8630 - val_loss: 0.3794 - val_accuracy: 0.8429\n",
            "Epoch 1143/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8617 - val_loss: 0.3792 - val_accuracy: 0.8396\n",
            "Epoch 1144/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8617 - val_loss: 0.3807 - val_accuracy: 0.8462\n",
            "Epoch 1145/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8628 - val_loss: 0.3818 - val_accuracy: 0.8484\n",
            "Epoch 1146/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8630 - val_loss: 0.3874 - val_accuracy: 0.8440\n",
            "Epoch 1147/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8612 - val_loss: 0.3816 - val_accuracy: 0.8484\n",
            "Epoch 1148/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8623 - val_loss: 0.3812 - val_accuracy: 0.8484\n",
            "Epoch 1149/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8603 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 1150/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8610 - val_loss: 0.3809 - val_accuracy: 0.8473\n",
            "Epoch 1151/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8624 - val_loss: 0.3806 - val_accuracy: 0.8473\n",
            "Epoch 1152/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8628 - val_loss: 0.3821 - val_accuracy: 0.8473\n",
            "Epoch 1153/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8605 - val_loss: 0.3812 - val_accuracy: 0.8484\n",
            "Epoch 1154/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8635 - val_loss: 0.3809 - val_accuracy: 0.8440\n",
            "Epoch 1155/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8630 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
            "Epoch 1156/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.3810 - val_accuracy: 0.8429\n",
            "Epoch 1157/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8623 - val_loss: 0.3803 - val_accuracy: 0.8440\n",
            "Epoch 1158/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8642 - val_loss: 0.3838 - val_accuracy: 0.8429\n",
            "Epoch 1159/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3358 - accuracy: 0.8610 - val_loss: 0.3843 - val_accuracy: 0.8451\n",
            "Epoch 1160/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3360 - accuracy: 0.8624 - val_loss: 0.3823 - val_accuracy: 0.8462\n",
            "Epoch 1161/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8630 - val_loss: 0.3798 - val_accuracy: 0.8440\n",
            "Epoch 1162/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8617 - val_loss: 0.3797 - val_accuracy: 0.8418\n",
            "Epoch 1163/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8639 - val_loss: 0.3798 - val_accuracy: 0.8429\n",
            "Epoch 1164/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8440\n",
            "Epoch 1165/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8624 - val_loss: 0.3832 - val_accuracy: 0.8473\n",
            "Epoch 1166/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3347 - accuracy: 0.8612 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 1167/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8633 - val_loss: 0.3820 - val_accuracy: 0.8462\n",
            "Epoch 1168/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8635 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 1169/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8633 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 1170/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8623 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 1171/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8623 - val_loss: 0.3822 - val_accuracy: 0.8484\n",
            "Epoch 1172/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8628 - val_loss: 0.3849 - val_accuracy: 0.8451\n",
            "Epoch 1173/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8623 - val_loss: 0.3799 - val_accuracy: 0.8396\n",
            "Epoch 1174/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8612 - val_loss: 0.3809 - val_accuracy: 0.8462\n",
            "Epoch 1175/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8630 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 1176/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8610 - val_loss: 0.3791 - val_accuracy: 0.8418\n",
            "Epoch 1177/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8630 - val_loss: 0.3855 - val_accuracy: 0.8429\n",
            "Epoch 1178/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8626 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 1179/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8644 - val_loss: 0.3826 - val_accuracy: 0.8484\n",
            "Epoch 1180/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 1181/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8623 - val_loss: 0.3800 - val_accuracy: 0.8440\n",
            "Epoch 1182/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8630 - val_loss: 0.3812 - val_accuracy: 0.8473\n",
            "Epoch 1183/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8633 - val_loss: 0.3798 - val_accuracy: 0.8451\n",
            "Epoch 1184/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8628 - val_loss: 0.3795 - val_accuracy: 0.8429\n",
            "Epoch 1185/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.8626 - val_loss: 0.3799 - val_accuracy: 0.8418\n",
            "Epoch 1186/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8637 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 1187/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8614 - val_loss: 0.3802 - val_accuracy: 0.8440\n",
            "Epoch 1188/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.3795 - val_accuracy: 0.8407\n",
            "Epoch 1189/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8615 - val_loss: 0.3796 - val_accuracy: 0.8429\n",
            "Epoch 1190/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3363 - accuracy: 0.8608 - val_loss: 0.3795 - val_accuracy: 0.8429\n",
            "Epoch 1191/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8633 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1192/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8631 - val_loss: 0.3814 - val_accuracy: 0.8484\n",
            "Epoch 1193/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8628 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 1194/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8614 - val_loss: 0.3824 - val_accuracy: 0.8484\n",
            "Epoch 1195/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8644 - val_loss: 0.3815 - val_accuracy: 0.8429\n",
            "Epoch 1196/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8628 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 1197/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8407\n",
            "Epoch 1198/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8635 - val_loss: 0.3810 - val_accuracy: 0.8440\n",
            "Epoch 1199/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8623 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 1200/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8617 - val_loss: 0.3807 - val_accuracy: 0.8451\n",
            "Epoch 1201/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8631 - val_loss: 0.3804 - val_accuracy: 0.8429\n",
            "Epoch 1202/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8624 - val_loss: 0.3790 - val_accuracy: 0.8385\n",
            "Epoch 1203/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8624 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 1204/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8624 - val_loss: 0.3796 - val_accuracy: 0.8418\n",
            "Epoch 1205/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8617 - val_loss: 0.3815 - val_accuracy: 0.8484\n",
            "Epoch 1206/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8637 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 1207/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8626 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1208/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8621 - val_loss: 0.3822 - val_accuracy: 0.8473\n",
            "Epoch 1209/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8614 - val_loss: 0.3827 - val_accuracy: 0.8484\n",
            "Epoch 1210/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8615 - val_loss: 0.3852 - val_accuracy: 0.8440\n",
            "Epoch 1211/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8623 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 1212/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8624 - val_loss: 0.3803 - val_accuracy: 0.8407\n",
            "Epoch 1213/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8635 - val_loss: 0.3804 - val_accuracy: 0.8418\n",
            "Epoch 1214/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.3795 - val_accuracy: 0.8440\n",
            "Epoch 1215/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8630 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 1216/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8615 - val_loss: 0.3841 - val_accuracy: 0.8495\n",
            "Epoch 1217/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8617 - val_loss: 0.3830 - val_accuracy: 0.8451\n",
            "Epoch 1218/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8630 - val_loss: 0.3827 - val_accuracy: 0.8495\n",
            "Epoch 1219/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8635 - val_loss: 0.3829 - val_accuracy: 0.8484\n",
            "Epoch 1220/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8628 - val_loss: 0.3803 - val_accuracy: 0.8429\n",
            "Epoch 1221/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8626 - val_loss: 0.3796 - val_accuracy: 0.8396\n",
            "Epoch 1222/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3349 - accuracy: 0.8615 - val_loss: 0.3798 - val_accuracy: 0.8407\n",
            "Epoch 1223/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8624 - val_loss: 0.3794 - val_accuracy: 0.8396\n",
            "Epoch 1224/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8621 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 1225/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8628 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 1226/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3339 - accuracy: 0.8619 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 1227/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8608 - val_loss: 0.3829 - val_accuracy: 0.8462\n",
            "Epoch 1228/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3866 - val_accuracy: 0.8462\n",
            "Epoch 1229/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8633 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 1230/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8633 - val_loss: 0.3819 - val_accuracy: 0.8473\n",
            "Epoch 1231/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3796 - val_accuracy: 0.8374\n",
            "Epoch 1232/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8624 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 1233/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8619 - val_loss: 0.3801 - val_accuracy: 0.8418\n",
            "Epoch 1234/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8628 - val_loss: 0.3817 - val_accuracy: 0.8484\n",
            "Epoch 1235/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8631 - val_loss: 0.3815 - val_accuracy: 0.8473\n",
            "Epoch 1236/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8630 - val_loss: 0.3812 - val_accuracy: 0.8462\n",
            "Epoch 1237/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8623 - val_loss: 0.3823 - val_accuracy: 0.8473\n",
            "Epoch 1238/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8617 - val_loss: 0.3799 - val_accuracy: 0.8407\n",
            "Epoch 1239/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8615 - val_loss: 0.3832 - val_accuracy: 0.8484\n",
            "Epoch 1240/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8628 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 1241/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8597 - val_loss: 0.3864 - val_accuracy: 0.8440\n",
            "Epoch 1242/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8623 - val_loss: 0.3816 - val_accuracy: 0.8473\n",
            "Epoch 1243/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8631 - val_loss: 0.3816 - val_accuracy: 0.8473\n",
            "Epoch 1244/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8637 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 1245/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8628 - val_loss: 0.3827 - val_accuracy: 0.8462\n",
            "Epoch 1246/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8626 - val_loss: 0.3856 - val_accuracy: 0.8440\n",
            "Epoch 1247/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8612 - val_loss: 0.3798 - val_accuracy: 0.8418\n",
            "Epoch 1248/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8396\n",
            "Epoch 1249/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8624 - val_loss: 0.3823 - val_accuracy: 0.8484\n",
            "Epoch 1250/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8640 - val_loss: 0.3818 - val_accuracy: 0.8473\n",
            "Epoch 1251/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8633 - val_loss: 0.3810 - val_accuracy: 0.8473\n",
            "Epoch 1252/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8626 - val_loss: 0.3818 - val_accuracy: 0.8473\n",
            "Epoch 1253/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3835 - val_accuracy: 0.8473\n",
            "Epoch 1254/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8630 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1255/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8610 - val_loss: 0.3817 - val_accuracy: 0.8451\n",
            "Epoch 1256/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3352 - accuracy: 0.8633 - val_loss: 0.3798 - val_accuracy: 0.8396\n",
            "Epoch 1257/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8631 - val_loss: 0.3797 - val_accuracy: 0.8396\n",
            "Epoch 1258/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8624 - val_loss: 0.3831 - val_accuracy: 0.8451\n",
            "Epoch 1259/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8635 - val_loss: 0.3810 - val_accuracy: 0.8473\n",
            "Epoch 1260/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.3816 - val_accuracy: 0.8473\n",
            "Epoch 1261/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8628 - val_loss: 0.3807 - val_accuracy: 0.8429\n",
            "Epoch 1262/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8631 - val_loss: 0.3872 - val_accuracy: 0.8462\n",
            "Epoch 1263/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8603 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 1264/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8635 - val_loss: 0.3813 - val_accuracy: 0.8451\n",
            "Epoch 1265/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8635 - val_loss: 0.3831 - val_accuracy: 0.8473\n",
            "Epoch 1266/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8648 - val_loss: 0.3800 - val_accuracy: 0.8396\n",
            "Epoch 1267/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.3845 - val_accuracy: 0.8451\n",
            "Epoch 1268/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8631 - val_loss: 0.3827 - val_accuracy: 0.8484\n",
            "Epoch 1269/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8601 - val_loss: 0.3805 - val_accuracy: 0.8429\n",
            "Epoch 1270/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8624 - val_loss: 0.3832 - val_accuracy: 0.8473\n",
            "Epoch 1271/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8626 - val_loss: 0.3816 - val_accuracy: 0.8484\n",
            "Epoch 1272/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8633 - val_loss: 0.3809 - val_accuracy: 0.8473\n",
            "Epoch 1273/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8615 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 1274/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8635 - val_loss: 0.3816 - val_accuracy: 0.8440\n",
            "Epoch 1275/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8637 - val_loss: 0.3823 - val_accuracy: 0.8484\n",
            "Epoch 1276/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8624 - val_loss: 0.3887 - val_accuracy: 0.8440\n",
            "Epoch 1277/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8606 - val_loss: 0.3797 - val_accuracy: 0.8385\n",
            "Epoch 1278/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8608 - val_loss: 0.3804 - val_accuracy: 0.8418\n",
            "Epoch 1279/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8633 - val_loss: 0.3801 - val_accuracy: 0.8407\n",
            "Epoch 1280/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8628 - val_loss: 0.3802 - val_accuracy: 0.8418\n",
            "Epoch 1281/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8628 - val_loss: 0.3801 - val_accuracy: 0.8385\n",
            "Epoch 1282/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8451\n",
            "Epoch 1283/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8621 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 1284/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8599 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 1285/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8614 - val_loss: 0.3800 - val_accuracy: 0.8418\n",
            "Epoch 1286/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8621 - val_loss: 0.3808 - val_accuracy: 0.8418\n",
            "Epoch 1287/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8608 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 1288/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8626 - val_loss: 0.3837 - val_accuracy: 0.8473\n",
            "Epoch 1289/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8633 - val_loss: 0.3825 - val_accuracy: 0.8473\n",
            "Epoch 1290/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8633 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
            "Epoch 1291/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8633 - val_loss: 0.3812 - val_accuracy: 0.8484\n",
            "Epoch 1292/2000\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3331 - accuracy: 0.8633 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1293/2000\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.3332 - accuracy: 0.8626 - val_loss: 0.3806 - val_accuracy: 0.8363\n",
            "Epoch 1294/2000\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3342 - accuracy: 0.8610 - val_loss: 0.3809 - val_accuracy: 0.8462\n",
            "Epoch 1295/2000\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.3341 - accuracy: 0.8621 - val_loss: 0.3813 - val_accuracy: 0.8429\n",
            "Epoch 1296/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8626 - val_loss: 0.3806 - val_accuracy: 0.8407\n",
            "Epoch 1297/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8619 - val_loss: 0.3879 - val_accuracy: 0.8462\n",
            "Epoch 1298/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8637 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
            "Epoch 1299/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8640 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 1300/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8633 - val_loss: 0.3854 - val_accuracy: 0.8451\n",
            "Epoch 1301/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8615 - val_loss: 0.3813 - val_accuracy: 0.8451\n",
            "Epoch 1302/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8628 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
            "Epoch 1303/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8637 - val_loss: 0.3799 - val_accuracy: 0.8385\n",
            "Epoch 1304/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8626 - val_loss: 0.3804 - val_accuracy: 0.8429\n",
            "Epoch 1305/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8624 - val_loss: 0.3813 - val_accuracy: 0.8429\n",
            "Epoch 1306/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8624 - val_loss: 0.3800 - val_accuracy: 0.8396\n",
            "Epoch 1307/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8630 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1308/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8626 - val_loss: 0.3809 - val_accuracy: 0.8407\n",
            "Epoch 1309/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8630 - val_loss: 0.3800 - val_accuracy: 0.8385\n",
            "Epoch 1310/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8631 - val_loss: 0.3803 - val_accuracy: 0.8418\n",
            "Epoch 1311/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8631 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 1312/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8633 - val_loss: 0.3810 - val_accuracy: 0.8429\n",
            "Epoch 1313/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8628 - val_loss: 0.3802 - val_accuracy: 0.8451\n",
            "Epoch 1314/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8635 - val_loss: 0.3803 - val_accuracy: 0.8385\n",
            "Epoch 1315/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8621 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1316/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8617 - val_loss: 0.3825 - val_accuracy: 0.8462\n",
            "Epoch 1317/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8617 - val_loss: 0.3838 - val_accuracy: 0.8484\n",
            "Epoch 1318/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8623 - val_loss: 0.3811 - val_accuracy: 0.8451\n",
            "Epoch 1319/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8630 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1320/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8596 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1321/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8635 - val_loss: 0.3809 - val_accuracy: 0.8440\n",
            "Epoch 1322/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 1323/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8605 - val_loss: 0.3854 - val_accuracy: 0.8484\n",
            "Epoch 1324/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3350 - accuracy: 0.8605 - val_loss: 0.3841 - val_accuracy: 0.8505\n",
            "Epoch 1325/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8623 - val_loss: 0.3828 - val_accuracy: 0.8484\n",
            "Epoch 1326/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8631 - val_loss: 0.3806 - val_accuracy: 0.8407\n",
            "Epoch 1327/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8603 - val_loss: 0.3860 - val_accuracy: 0.8484\n",
            "Epoch 1328/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8631 - val_loss: 0.3802 - val_accuracy: 0.8396\n",
            "Epoch 1329/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8631 - val_loss: 0.3800 - val_accuracy: 0.8429\n",
            "Epoch 1330/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8606 - val_loss: 0.3858 - val_accuracy: 0.8462\n",
            "Epoch 1331/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8628 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 1332/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8631 - val_loss: 0.3803 - val_accuracy: 0.8396\n",
            "Epoch 1333/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3826 - val_accuracy: 0.8484\n",
            "Epoch 1334/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8624 - val_loss: 0.3813 - val_accuracy: 0.8418\n",
            "Epoch 1335/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8633 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 1336/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8624 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1337/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8599 - val_loss: 0.3806 - val_accuracy: 0.8429\n",
            "Epoch 1338/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8624 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 1339/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8640 - val_loss: 0.3811 - val_accuracy: 0.8429\n",
            "Epoch 1340/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8621 - val_loss: 0.3812 - val_accuracy: 0.8473\n",
            "Epoch 1341/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8626 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1342/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8624 - val_loss: 0.3835 - val_accuracy: 0.8451\n",
            "Epoch 1343/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8628 - val_loss: 0.3818 - val_accuracy: 0.8451\n",
            "Epoch 1344/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 1345/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8623 - val_loss: 0.3807 - val_accuracy: 0.8418\n",
            "Epoch 1346/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8633 - val_loss: 0.3817 - val_accuracy: 0.8462\n",
            "Epoch 1347/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8637 - val_loss: 0.3806 - val_accuracy: 0.8429\n",
            "Epoch 1348/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8639 - val_loss: 0.3854 - val_accuracy: 0.8462\n",
            "Epoch 1349/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8630 - val_loss: 0.3868 - val_accuracy: 0.8462\n",
            "Epoch 1350/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8608 - val_loss: 0.3806 - val_accuracy: 0.8462\n",
            "Epoch 1351/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8639 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
            "Epoch 1352/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8628 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 1353/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8628 - val_loss: 0.3808 - val_accuracy: 0.8451\n",
            "Epoch 1354/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8624 - val_loss: 0.3809 - val_accuracy: 0.8418\n",
            "Epoch 1355/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8628 - val_loss: 0.3831 - val_accuracy: 0.8440\n",
            "Epoch 1356/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8623 - val_loss: 0.3837 - val_accuracy: 0.8484\n",
            "Epoch 1357/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8640 - val_loss: 0.3819 - val_accuracy: 0.8473\n",
            "Epoch 1358/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3823 - val_accuracy: 0.8462\n",
            "Epoch 1359/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8628 - val_loss: 0.3827 - val_accuracy: 0.8473\n",
            "Epoch 1360/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8637 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1361/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8617 - val_loss: 0.3838 - val_accuracy: 0.8473\n",
            "Epoch 1362/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8623 - val_loss: 0.3859 - val_accuracy: 0.8473\n",
            "Epoch 1363/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.3806 - val_accuracy: 0.8396\n",
            "Epoch 1364/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8605 - val_loss: 0.3810 - val_accuracy: 0.8451\n",
            "Epoch 1365/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8628 - val_loss: 0.3801 - val_accuracy: 0.8396\n",
            "Epoch 1366/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8596 - val_loss: 0.3860 - val_accuracy: 0.8462\n",
            "Epoch 1367/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8624 - val_loss: 0.3846 - val_accuracy: 0.8462\n",
            "Epoch 1368/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8623 - val_loss: 0.3826 - val_accuracy: 0.8451\n",
            "Epoch 1369/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3841 - val_accuracy: 0.8484\n",
            "Epoch 1370/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8626 - val_loss: 0.3839 - val_accuracy: 0.8451\n",
            "Epoch 1371/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8621 - val_loss: 0.3830 - val_accuracy: 0.8484\n",
            "Epoch 1372/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8633 - val_loss: 0.3829 - val_accuracy: 0.8473\n",
            "Epoch 1373/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3823 - val_accuracy: 0.8451\n",
            "Epoch 1374/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8640 - val_loss: 0.3802 - val_accuracy: 0.8407\n",
            "Epoch 1375/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3332 - accuracy: 0.8631 - val_loss: 0.3813 - val_accuracy: 0.8451\n",
            "Epoch 1376/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8635 - val_loss: 0.3832 - val_accuracy: 0.8451\n",
            "Epoch 1377/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3332 - accuracy: 0.8621 - val_loss: 0.3802 - val_accuracy: 0.8374\n",
            "Epoch 1378/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8610 - val_loss: 0.3800 - val_accuracy: 0.8407\n",
            "Epoch 1379/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8621 - val_loss: 0.3808 - val_accuracy: 0.8440\n",
            "Epoch 1380/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8637 - val_loss: 0.3818 - val_accuracy: 0.8440\n",
            "Epoch 1381/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8635 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 1382/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8626 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1383/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8612 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 1384/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8630 - val_loss: 0.3840 - val_accuracy: 0.8440\n",
            "Epoch 1385/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8621 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 1386/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8642 - val_loss: 0.3824 - val_accuracy: 0.8451\n",
            "Epoch 1387/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8623 - val_loss: 0.3879 - val_accuracy: 0.8451\n",
            "Epoch 1388/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3819 - val_accuracy: 0.8462\n",
            "Epoch 1389/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8639 - val_loss: 0.3843 - val_accuracy: 0.8440\n",
            "Epoch 1390/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.8623 - val_loss: 0.3872 - val_accuracy: 0.8473\n",
            "Epoch 1391/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8626 - val_loss: 0.3804 - val_accuracy: 0.8396\n",
            "Epoch 1392/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8612 - val_loss: 0.3803 - val_accuracy: 0.8407\n",
            "Epoch 1393/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8626 - val_loss: 0.3819 - val_accuracy: 0.8473\n",
            "Epoch 1394/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3807 - val_accuracy: 0.8407\n",
            "Epoch 1395/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8624 - val_loss: 0.3808 - val_accuracy: 0.8385\n",
            "Epoch 1396/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8615 - val_loss: 0.3810 - val_accuracy: 0.8418\n",
            "Epoch 1397/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3816 - val_accuracy: 0.8462\n",
            "Epoch 1398/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.8631 - val_loss: 0.3812 - val_accuracy: 0.8418\n",
            "Epoch 1399/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8631 - val_loss: 0.3805 - val_accuracy: 0.8396\n",
            "Epoch 1400/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8631 - val_loss: 0.3817 - val_accuracy: 0.8473\n",
            "Epoch 1401/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8635 - val_loss: 0.3815 - val_accuracy: 0.8440\n",
            "Epoch 1402/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3805 - val_accuracy: 0.8374\n",
            "Epoch 1403/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8631 - val_loss: 0.3803 - val_accuracy: 0.8385\n",
            "Epoch 1404/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8628 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 1405/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8633 - val_loss: 0.3806 - val_accuracy: 0.8418\n",
            "Epoch 1406/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.8624 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 1407/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8626 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1408/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8624 - val_loss: 0.3831 - val_accuracy: 0.8484\n",
            "Epoch 1409/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8637 - val_loss: 0.3818 - val_accuracy: 0.8451\n",
            "Epoch 1410/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8633 - val_loss: 0.3804 - val_accuracy: 0.8396\n",
            "Epoch 1411/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3332 - accuracy: 0.8626 - val_loss: 0.3812 - val_accuracy: 0.8440\n",
            "Epoch 1412/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3818 - val_accuracy: 0.8462\n",
            "Epoch 1413/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8631 - val_loss: 0.3820 - val_accuracy: 0.8462\n",
            "Epoch 1414/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8631 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1415/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8639 - val_loss: 0.3855 - val_accuracy: 0.8462\n",
            "Epoch 1416/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8630 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 1417/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8651 - val_loss: 0.3844 - val_accuracy: 0.8473\n",
            "Epoch 1418/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8624 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1419/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8631 - val_loss: 0.3803 - val_accuracy: 0.8396\n",
            "Epoch 1420/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8612 - val_loss: 0.3865 - val_accuracy: 0.8451\n",
            "Epoch 1421/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8637 - val_loss: 0.3821 - val_accuracy: 0.8440\n",
            "Epoch 1422/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8606 - val_loss: 0.3806 - val_accuracy: 0.8385\n",
            "Epoch 1423/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8630 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
            "Epoch 1424/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8631 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
            "Epoch 1425/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8624 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 1426/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8619 - val_loss: 0.3808 - val_accuracy: 0.8429\n",
            "Epoch 1427/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8644 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 1428/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8628 - val_loss: 0.3828 - val_accuracy: 0.8440\n",
            "Epoch 1429/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8621 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1430/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8396\n",
            "Epoch 1431/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8610 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1432/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8635 - val_loss: 0.3815 - val_accuracy: 0.8462\n",
            "Epoch 1433/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 1434/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8623 - val_loss: 0.3816 - val_accuracy: 0.8429\n",
            "Epoch 1435/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8429\n",
            "Epoch 1436/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8631 - val_loss: 0.3811 - val_accuracy: 0.8440\n",
            "Epoch 1437/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8637 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 1438/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3338 - accuracy: 0.8617 - val_loss: 0.3810 - val_accuracy: 0.8396\n",
            "Epoch 1439/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3329 - accuracy: 0.8624 - val_loss: 0.3806 - val_accuracy: 0.8440\n",
            "Epoch 1440/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.8619 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1441/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8626 - val_loss: 0.3809 - val_accuracy: 0.8396\n",
            "Epoch 1442/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8623 - val_loss: 0.3810 - val_accuracy: 0.8418\n",
            "Epoch 1443/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8617 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 1444/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8633 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 1445/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8637 - val_loss: 0.3821 - val_accuracy: 0.8440\n",
            "Epoch 1446/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8615 - val_loss: 0.3810 - val_accuracy: 0.8418\n",
            "Epoch 1447/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8626 - val_loss: 0.3813 - val_accuracy: 0.8407\n",
            "Epoch 1448/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8631 - val_loss: 0.3809 - val_accuracy: 0.8407\n",
            "Epoch 1449/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8637 - val_loss: 0.3803 - val_accuracy: 0.8396\n",
            "Epoch 1450/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8614 - val_loss: 0.3813 - val_accuracy: 0.8429\n",
            "Epoch 1451/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8630 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1452/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8640 - val_loss: 0.3843 - val_accuracy: 0.8440\n",
            "Epoch 1453/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8603 - val_loss: 0.3935 - val_accuracy: 0.8374\n",
            "Epoch 1454/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8619 - val_loss: 0.3830 - val_accuracy: 0.8451\n",
            "Epoch 1455/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8623 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1456/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8628 - val_loss: 0.3811 - val_accuracy: 0.8429\n",
            "Epoch 1457/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3823 - val_accuracy: 0.8440\n",
            "Epoch 1458/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8633 - val_loss: 0.3811 - val_accuracy: 0.8418\n",
            "Epoch 1459/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8630 - val_loss: 0.3810 - val_accuracy: 0.8396\n",
            "Epoch 1460/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3821 - val_accuracy: 0.8451\n",
            "Epoch 1461/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8617 - val_loss: 0.3812 - val_accuracy: 0.8429\n",
            "Epoch 1462/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8639 - val_loss: 0.3821 - val_accuracy: 0.8440\n",
            "Epoch 1463/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8646 - val_loss: 0.3842 - val_accuracy: 0.8473\n",
            "Epoch 1464/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8630 - val_loss: 0.3805 - val_accuracy: 0.8385\n",
            "Epoch 1465/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8617 - val_loss: 0.3815 - val_accuracy: 0.8418\n",
            "Epoch 1466/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8619 - val_loss: 0.3808 - val_accuracy: 0.8418\n",
            "Epoch 1467/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8615 - val_loss: 0.3876 - val_accuracy: 0.8462\n",
            "Epoch 1468/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8630 - val_loss: 0.3814 - val_accuracy: 0.8429\n",
            "Epoch 1469/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8623 - val_loss: 0.3815 - val_accuracy: 0.8451\n",
            "Epoch 1470/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3832 - val_accuracy: 0.8451\n",
            "Epoch 1471/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8640 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1472/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8637 - val_loss: 0.3833 - val_accuracy: 0.8462\n",
            "Epoch 1473/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8615 - val_loss: 0.3809 - val_accuracy: 0.8429\n",
            "Epoch 1474/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8626 - val_loss: 0.3812 - val_accuracy: 0.8429\n",
            "Epoch 1475/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8623 - val_loss: 0.3807 - val_accuracy: 0.8429\n",
            "Epoch 1476/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3886 - val_accuracy: 0.8462\n",
            "Epoch 1477/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8587 - val_loss: 0.3884 - val_accuracy: 0.8473\n",
            "Epoch 1478/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8615 - val_loss: 0.3866 - val_accuracy: 0.8462\n",
            "Epoch 1479/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8642 - val_loss: 0.3821 - val_accuracy: 0.8462\n",
            "Epoch 1480/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8628 - val_loss: 0.3816 - val_accuracy: 0.8385\n",
            "Epoch 1481/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8628 - val_loss: 0.3837 - val_accuracy: 0.8451\n",
            "Epoch 1482/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8630 - val_loss: 0.3849 - val_accuracy: 0.8451\n",
            "Epoch 1483/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8617 - val_loss: 0.3818 - val_accuracy: 0.8440\n",
            "Epoch 1484/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8633 - val_loss: 0.3832 - val_accuracy: 0.8484\n",
            "Epoch 1485/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3826 - val_accuracy: 0.8451\n",
            "Epoch 1486/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8628 - val_loss: 0.3818 - val_accuracy: 0.8473\n",
            "Epoch 1487/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8630 - val_loss: 0.3837 - val_accuracy: 0.8473\n",
            "Epoch 1488/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 1489/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8631 - val_loss: 0.3811 - val_accuracy: 0.8407\n",
            "Epoch 1490/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3340 - accuracy: 0.8614 - val_loss: 0.3817 - val_accuracy: 0.8429\n",
            "Epoch 1491/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8612 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 1492/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 1493/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8648 - val_loss: 0.3818 - val_accuracy: 0.8440\n",
            "Epoch 1494/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3334 - accuracy: 0.8621 - val_loss: 0.3871 - val_accuracy: 0.8462\n",
            "Epoch 1495/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3337 - accuracy: 0.8621 - val_loss: 0.3821 - val_accuracy: 0.8440\n",
            "Epoch 1496/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.3810 - val_accuracy: 0.8374\n",
            "Epoch 1497/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8610 - val_loss: 0.3815 - val_accuracy: 0.8429\n",
            "Epoch 1498/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8617 - val_loss: 0.3804 - val_accuracy: 0.8407\n",
            "Epoch 1499/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8617 - val_loss: 0.3834 - val_accuracy: 0.8440\n",
            "Epoch 1500/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8623 - val_loss: 0.3816 - val_accuracy: 0.8451\n",
            "Epoch 1501/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8590 - val_loss: 0.3808 - val_accuracy: 0.8396\n",
            "Epoch 1502/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8615 - val_loss: 0.3822 - val_accuracy: 0.8451\n",
            "Epoch 1503/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8626 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 1504/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8608 - val_loss: 0.3809 - val_accuracy: 0.8407\n",
            "Epoch 1505/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8621 - val_loss: 0.3840 - val_accuracy: 0.8462\n",
            "Epoch 1506/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8614 - val_loss: 0.3838 - val_accuracy: 0.8473\n",
            "Epoch 1507/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8606 - val_loss: 0.3894 - val_accuracy: 0.8451\n",
            "Epoch 1508/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8608 - val_loss: 0.3879 - val_accuracy: 0.8462\n",
            "Epoch 1509/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8608 - val_loss: 0.3871 - val_accuracy: 0.8440\n",
            "Epoch 1510/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8603 - val_loss: 0.3831 - val_accuracy: 0.8462\n",
            "Epoch 1511/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8624 - val_loss: 0.3818 - val_accuracy: 0.8407\n",
            "Epoch 1512/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8642 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1513/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8626 - val_loss: 0.3840 - val_accuracy: 0.8462\n",
            "Epoch 1514/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8626 - val_loss: 0.3886 - val_accuracy: 0.8462\n",
            "Epoch 1515/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8615 - val_loss: 0.3855 - val_accuracy: 0.8473\n",
            "Epoch 1516/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8630 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 1517/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8626 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 1518/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8633 - val_loss: 0.3814 - val_accuracy: 0.8440\n",
            "Epoch 1519/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3889 - val_accuracy: 0.8462\n",
            "Epoch 1520/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8631 - val_loss: 0.3811 - val_accuracy: 0.8396\n",
            "Epoch 1521/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8633 - val_loss: 0.3820 - val_accuracy: 0.8429\n",
            "Epoch 1522/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8615 - val_loss: 0.3829 - val_accuracy: 0.8484\n",
            "Epoch 1523/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 1524/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8619 - val_loss: 0.3842 - val_accuracy: 0.8451\n",
            "Epoch 1525/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8614 - val_loss: 0.3858 - val_accuracy: 0.8462\n",
            "Epoch 1526/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8615 - val_loss: 0.3811 - val_accuracy: 0.8418\n",
            "Epoch 1527/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8624 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1528/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3842 - val_accuracy: 0.8451\n",
            "Epoch 1529/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 1530/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8646 - val_loss: 0.3820 - val_accuracy: 0.8407\n",
            "Epoch 1531/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8630 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1532/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8635 - val_loss: 0.3820 - val_accuracy: 0.8429\n",
            "Epoch 1533/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8630 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1534/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8637 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1535/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3860 - val_accuracy: 0.8429\n",
            "Epoch 1536/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8621 - val_loss: 0.3812 - val_accuracy: 0.8407\n",
            "Epoch 1537/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 1538/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3810 - val_accuracy: 0.8363\n",
            "Epoch 1539/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8640 - val_loss: 0.3846 - val_accuracy: 0.8451\n",
            "Epoch 1540/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8621 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1541/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8635 - val_loss: 0.3818 - val_accuracy: 0.8385\n",
            "Epoch 1542/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8630 - val_loss: 0.3823 - val_accuracy: 0.8462\n",
            "Epoch 1543/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.3809 - val_accuracy: 0.8418\n",
            "Epoch 1544/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8624 - val_loss: 0.3847 - val_accuracy: 0.8451\n",
            "Epoch 1545/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.8637 - val_loss: 0.3814 - val_accuracy: 0.8418\n",
            "Epoch 1546/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8597 - val_loss: 0.3841 - val_accuracy: 0.8451\n",
            "Epoch 1547/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3335 - accuracy: 0.8635 - val_loss: 0.3858 - val_accuracy: 0.8473\n",
            "Epoch 1548/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8619 - val_loss: 0.3819 - val_accuracy: 0.8385\n",
            "Epoch 1549/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8633 - val_loss: 0.3827 - val_accuracy: 0.8462\n",
            "Epoch 1550/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3835 - val_accuracy: 0.8440\n",
            "Epoch 1551/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3332 - accuracy: 0.8630 - val_loss: 0.3817 - val_accuracy: 0.8451\n",
            "Epoch 1552/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1553/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8626 - val_loss: 0.3840 - val_accuracy: 0.8440\n",
            "Epoch 1554/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3817 - val_accuracy: 0.8374\n",
            "Epoch 1555/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1556/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8628 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 1557/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8640 - val_loss: 0.3823 - val_accuracy: 0.8451\n",
            "Epoch 1558/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 1559/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.3826 - val_accuracy: 0.8462\n",
            "Epoch 1560/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8633 - val_loss: 0.3867 - val_accuracy: 0.8418\n",
            "Epoch 1561/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8621 - val_loss: 0.3818 - val_accuracy: 0.8440\n",
            "Epoch 1562/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8614 - val_loss: 0.3874 - val_accuracy: 0.8462\n",
            "Epoch 1563/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8623 - val_loss: 0.3843 - val_accuracy: 0.8440\n",
            "Epoch 1564/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8633 - val_loss: 0.3866 - val_accuracy: 0.8462\n",
            "Epoch 1565/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8628 - val_loss: 0.3843 - val_accuracy: 0.8440\n",
            "Epoch 1566/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8635 - val_loss: 0.3824 - val_accuracy: 0.8451\n",
            "Epoch 1567/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8628 - val_loss: 0.3817 - val_accuracy: 0.8440\n",
            "Epoch 1568/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8631 - val_loss: 0.3815 - val_accuracy: 0.8396\n",
            "Epoch 1569/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8635 - val_loss: 0.3816 - val_accuracy: 0.8429\n",
            "Epoch 1570/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8615 - val_loss: 0.3839 - val_accuracy: 0.8462\n",
            "Epoch 1571/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8615 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 1572/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8626 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 1573/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8623 - val_loss: 0.3817 - val_accuracy: 0.8462\n",
            "Epoch 1574/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8626 - val_loss: 0.3846 - val_accuracy: 0.8440\n",
            "Epoch 1575/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1576/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8630 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1577/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8633 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 1578/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8619 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 1579/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3339 - accuracy: 0.8608 - val_loss: 0.3814 - val_accuracy: 0.8407\n",
            "Epoch 1580/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8630 - val_loss: 0.3811 - val_accuracy: 0.8418\n",
            "Epoch 1581/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8633 - val_loss: 0.3826 - val_accuracy: 0.8462\n",
            "Epoch 1582/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8615 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 1583/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8642 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1584/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8637 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 1585/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8631 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1586/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8642 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 1587/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8617 - val_loss: 0.3815 - val_accuracy: 0.8396\n",
            "Epoch 1588/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8606 - val_loss: 0.3824 - val_accuracy: 0.8462\n",
            "Epoch 1589/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8644 - val_loss: 0.3838 - val_accuracy: 0.8451\n",
            "Epoch 1590/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8623 - val_loss: 0.3853 - val_accuracy: 0.8440\n",
            "Epoch 1591/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8624 - val_loss: 0.3848 - val_accuracy: 0.8440\n",
            "Epoch 1592/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8639 - val_loss: 0.3828 - val_accuracy: 0.8462\n",
            "Epoch 1593/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8642 - val_loss: 0.3821 - val_accuracy: 0.8429\n",
            "Epoch 1594/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8621 - val_loss: 0.3842 - val_accuracy: 0.8451\n",
            "Epoch 1595/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8637 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1596/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8630 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1597/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3840 - val_accuracy: 0.8440\n",
            "Epoch 1598/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8630 - val_loss: 0.3836 - val_accuracy: 0.8462\n",
            "Epoch 1599/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8619 - val_loss: 0.3852 - val_accuracy: 0.8484\n",
            "Epoch 1600/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8633 - val_loss: 0.3819 - val_accuracy: 0.8429\n",
            "Epoch 1601/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8621 - val_loss: 0.3811 - val_accuracy: 0.8385\n",
            "Epoch 1602/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8640 - val_loss: 0.3862 - val_accuracy: 0.8462\n",
            "Epoch 1603/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8642 - val_loss: 0.3819 - val_accuracy: 0.8440\n",
            "Epoch 1604/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8608 - val_loss: 0.3818 - val_accuracy: 0.8407\n",
            "Epoch 1605/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3817 - val_accuracy: 0.8429\n",
            "Epoch 1606/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3875 - val_accuracy: 0.8451\n",
            "Epoch 1607/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8603 - val_loss: 0.3877 - val_accuracy: 0.8462\n",
            "Epoch 1608/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8630 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 1609/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
            "Epoch 1610/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8639 - val_loss: 0.3834 - val_accuracy: 0.8462\n",
            "Epoch 1611/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8621 - val_loss: 0.3817 - val_accuracy: 0.8429\n",
            "Epoch 1612/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8635 - val_loss: 0.3846 - val_accuracy: 0.8451\n",
            "Epoch 1613/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8628 - val_loss: 0.3817 - val_accuracy: 0.8385\n",
            "Epoch 1614/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8642 - val_loss: 0.3810 - val_accuracy: 0.8374\n",
            "Epoch 1615/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8628 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 1616/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8646 - val_loss: 0.3815 - val_accuracy: 0.8407\n",
            "Epoch 1617/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8623 - val_loss: 0.3864 - val_accuracy: 0.8451\n",
            "Epoch 1618/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8637 - val_loss: 0.3864 - val_accuracy: 0.8440\n",
            "Epoch 1619/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8635 - val_loss: 0.3830 - val_accuracy: 0.8462\n",
            "Epoch 1620/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3846 - val_accuracy: 0.8440\n",
            "Epoch 1621/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3832 - val_accuracy: 0.8440\n",
            "Epoch 1622/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8635 - val_loss: 0.3884 - val_accuracy: 0.8451\n",
            "Epoch 1623/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3335 - accuracy: 0.8624 - val_loss: 0.3824 - val_accuracy: 0.8451\n",
            "Epoch 1624/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8621 - val_loss: 0.3821 - val_accuracy: 0.8407\n",
            "Epoch 1625/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8619 - val_loss: 0.3812 - val_accuracy: 0.8418\n",
            "Epoch 1626/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8637 - val_loss: 0.3822 - val_accuracy: 0.8451\n",
            "Epoch 1627/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3842 - val_accuracy: 0.8473\n",
            "Epoch 1628/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8621 - val_loss: 0.3815 - val_accuracy: 0.8407\n",
            "Epoch 1629/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3831 - val_accuracy: 0.8462\n",
            "Epoch 1630/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8623 - val_loss: 0.3827 - val_accuracy: 0.8440\n",
            "Epoch 1631/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8631 - val_loss: 0.3824 - val_accuracy: 0.8451\n",
            "Epoch 1632/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8626 - val_loss: 0.3836 - val_accuracy: 0.8451\n",
            "Epoch 1633/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.8628 - val_loss: 0.3863 - val_accuracy: 0.8451\n",
            "Epoch 1634/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8631 - val_loss: 0.3838 - val_accuracy: 0.8440\n",
            "Epoch 1635/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3817 - val_accuracy: 0.8418\n",
            "Epoch 1636/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8624 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 1637/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8630 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1638/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3816 - val_accuracy: 0.8385\n",
            "Epoch 1639/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8628 - val_loss: 0.3843 - val_accuracy: 0.8473\n",
            "Epoch 1640/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 1641/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3334 - accuracy: 0.8617 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
            "Epoch 1642/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8633 - val_loss: 0.3814 - val_accuracy: 0.8385\n",
            "Epoch 1643/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3331 - accuracy: 0.8628 - val_loss: 0.3826 - val_accuracy: 0.8440\n",
            "Epoch 1644/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8635 - val_loss: 0.3819 - val_accuracy: 0.8407\n",
            "Epoch 1645/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8631 - val_loss: 0.3842 - val_accuracy: 0.8451\n",
            "Epoch 1646/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8637 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1647/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.8642 - val_loss: 0.3871 - val_accuracy: 0.8484\n",
            "Epoch 1648/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8621 - val_loss: 0.3822 - val_accuracy: 0.8429\n",
            "Epoch 1649/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8637 - val_loss: 0.3833 - val_accuracy: 0.8462\n",
            "Epoch 1650/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3840 - val_accuracy: 0.8440\n",
            "Epoch 1651/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8637 - val_loss: 0.3821 - val_accuracy: 0.8418\n",
            "Epoch 1652/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3333 - accuracy: 0.8626 - val_loss: 0.3816 - val_accuracy: 0.8407\n",
            "Epoch 1653/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8631 - val_loss: 0.3815 - val_accuracy: 0.8418\n",
            "Epoch 1654/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8637 - val_loss: 0.3819 - val_accuracy: 0.8418\n",
            "Epoch 1655/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8623 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1656/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8635 - val_loss: 0.3823 - val_accuracy: 0.8451\n",
            "Epoch 1657/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8630 - val_loss: 0.3857 - val_accuracy: 0.8440\n",
            "Epoch 1658/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8637 - val_loss: 0.3862 - val_accuracy: 0.8473\n",
            "Epoch 1659/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8630 - val_loss: 0.3849 - val_accuracy: 0.8451\n",
            "Epoch 1660/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8624 - val_loss: 0.3860 - val_accuracy: 0.8451\n",
            "Epoch 1661/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8635 - val_loss: 0.3918 - val_accuracy: 0.8440\n",
            "Epoch 1662/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8623 - val_loss: 0.3858 - val_accuracy: 0.8462\n",
            "Epoch 1663/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8619 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1664/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8631 - val_loss: 0.3906 - val_accuracy: 0.8440\n",
            "Epoch 1665/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3349 - accuracy: 0.8601 - val_loss: 0.3860 - val_accuracy: 0.8451\n",
            "Epoch 1666/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8637 - val_loss: 0.3840 - val_accuracy: 0.8451\n",
            "Epoch 1667/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8624 - val_loss: 0.3819 - val_accuracy: 0.8385\n",
            "Epoch 1668/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8617 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 1669/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3328 - accuracy: 0.8631 - val_loss: 0.3814 - val_accuracy: 0.8374\n",
            "Epoch 1670/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3828 - val_accuracy: 0.8440\n",
            "Epoch 1671/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.8623 - val_loss: 0.3852 - val_accuracy: 0.8418\n",
            "Epoch 1672/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.8631 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 1673/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8631 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1674/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8624 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 1675/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8623 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 1676/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.8631 - val_loss: 0.3820 - val_accuracy: 0.8440\n",
            "Epoch 1677/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8630 - val_loss: 0.3824 - val_accuracy: 0.8418\n",
            "Epoch 1678/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8630 - val_loss: 0.3834 - val_accuracy: 0.8462\n",
            "Epoch 1679/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8626 - val_loss: 0.3840 - val_accuracy: 0.8473\n",
            "Epoch 1680/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8635 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1681/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8624 - val_loss: 0.3874 - val_accuracy: 0.8462\n",
            "Epoch 1682/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8631 - val_loss: 0.3883 - val_accuracy: 0.8451\n",
            "Epoch 1683/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8614 - val_loss: 0.3842 - val_accuracy: 0.8440\n",
            "Epoch 1684/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8635 - val_loss: 0.3822 - val_accuracy: 0.8429\n",
            "Epoch 1685/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8626 - val_loss: 0.3820 - val_accuracy: 0.8418\n",
            "Epoch 1686/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8644 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1687/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8637 - val_loss: 0.3826 - val_accuracy: 0.8451\n",
            "Epoch 1688/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8615 - val_loss: 0.3849 - val_accuracy: 0.8451\n",
            "Epoch 1689/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8610 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1690/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8635 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 1691/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8649 - val_loss: 0.3840 - val_accuracy: 0.8451\n",
            "Epoch 1692/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8628 - val_loss: 0.3836 - val_accuracy: 0.8462\n",
            "Epoch 1693/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8635 - val_loss: 0.3817 - val_accuracy: 0.8396\n",
            "Epoch 1694/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8639 - val_loss: 0.3818 - val_accuracy: 0.8374\n",
            "Epoch 1695/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8623 - val_loss: 0.3818 - val_accuracy: 0.8385\n",
            "Epoch 1696/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8639 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 1697/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8615 - val_loss: 0.3849 - val_accuracy: 0.8473\n",
            "Epoch 1698/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3870 - val_accuracy: 0.8451\n",
            "Epoch 1699/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8621 - val_loss: 0.3905 - val_accuracy: 0.8451\n",
            "Epoch 1700/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8635 - val_loss: 0.3825 - val_accuracy: 0.8451\n",
            "Epoch 1701/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8630 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 1702/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8639 - val_loss: 0.3831 - val_accuracy: 0.8451\n",
            "Epoch 1703/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 1704/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8617 - val_loss: 0.3816 - val_accuracy: 0.8385\n",
            "Epoch 1705/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8628 - val_loss: 0.3821 - val_accuracy: 0.8418\n",
            "Epoch 1706/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8626 - val_loss: 0.3823 - val_accuracy: 0.8451\n",
            "Epoch 1707/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8649 - val_loss: 0.3848 - val_accuracy: 0.8473\n",
            "Epoch 1708/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 1709/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.8630 - val_loss: 0.3825 - val_accuracy: 0.8429\n",
            "Epoch 1710/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8631 - val_loss: 0.3832 - val_accuracy: 0.8462\n",
            "Epoch 1711/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3830 - val_accuracy: 0.8440\n",
            "Epoch 1712/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8623 - val_loss: 0.3854 - val_accuracy: 0.8462\n",
            "Epoch 1713/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8614 - val_loss: 0.3861 - val_accuracy: 0.8451\n",
            "Epoch 1714/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8630 - val_loss: 0.3862 - val_accuracy: 0.8440\n",
            "Epoch 1715/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8637 - val_loss: 0.3822 - val_accuracy: 0.8440\n",
            "Epoch 1716/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8633 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1717/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8624 - val_loss: 0.3869 - val_accuracy: 0.8462\n",
            "Epoch 1718/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8624 - val_loss: 0.3820 - val_accuracy: 0.8396\n",
            "Epoch 1719/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3830 - val_accuracy: 0.8429\n",
            "Epoch 1720/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3861 - val_accuracy: 0.8440\n",
            "Epoch 1721/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8626 - val_loss: 0.3871 - val_accuracy: 0.8473\n",
            "Epoch 1722/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8603 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1723/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8640 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "Epoch 1724/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3824 - val_accuracy: 0.8440\n",
            "Epoch 1725/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8644 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 1726/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8628 - val_loss: 0.3821 - val_accuracy: 0.8440\n",
            "Epoch 1727/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8633 - val_loss: 0.3863 - val_accuracy: 0.8440\n",
            "Epoch 1728/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8639 - val_loss: 0.3835 - val_accuracy: 0.8451\n",
            "Epoch 1729/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8617 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 1730/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8626 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 1731/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3833 - val_accuracy: 0.8473\n",
            "Epoch 1732/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.8630 - val_loss: 0.3823 - val_accuracy: 0.8407\n",
            "Epoch 1733/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3318 - accuracy: 0.8639 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1734/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8637 - val_loss: 0.3840 - val_accuracy: 0.8462\n",
            "Epoch 1735/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8631 - val_loss: 0.3832 - val_accuracy: 0.8440\n",
            "Epoch 1736/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8637 - val_loss: 0.3857 - val_accuracy: 0.8462\n",
            "Epoch 1737/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8614 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1738/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8630 - val_loss: 0.3873 - val_accuracy: 0.8484\n",
            "Epoch 1739/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8639 - val_loss: 0.3835 - val_accuracy: 0.8451\n",
            "Epoch 1740/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8639 - val_loss: 0.3845 - val_accuracy: 0.8440\n",
            "Epoch 1741/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8631 - val_loss: 0.3857 - val_accuracy: 0.8440\n",
            "Epoch 1742/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8633 - val_loss: 0.3843 - val_accuracy: 0.8484\n",
            "Epoch 1743/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8631 - val_loss: 0.3871 - val_accuracy: 0.8451\n",
            "Epoch 1744/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8623 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
            "Epoch 1745/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3333 - accuracy: 0.8637 - val_loss: 0.3833 - val_accuracy: 0.8451\n",
            "Epoch 1746/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8642 - val_loss: 0.3822 - val_accuracy: 0.8440\n",
            "Epoch 1747/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8624 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
            "Epoch 1748/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8640 - val_loss: 0.3828 - val_accuracy: 0.8429\n",
            "Epoch 1749/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8615 - val_loss: 0.3820 - val_accuracy: 0.8407\n",
            "Epoch 1750/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8635 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1751/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8640 - val_loss: 0.3836 - val_accuracy: 0.8462\n",
            "Epoch 1752/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8626 - val_loss: 0.3825 - val_accuracy: 0.8374\n",
            "Epoch 1753/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8623 - val_loss: 0.3840 - val_accuracy: 0.8473\n",
            "Epoch 1754/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8642 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 1755/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8633 - val_loss: 0.3835 - val_accuracy: 0.8440\n",
            "Epoch 1756/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3823 - val_accuracy: 0.8418\n",
            "Epoch 1757/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8624 - val_loss: 0.3822 - val_accuracy: 0.8385\n",
            "Epoch 1758/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8619 - val_loss: 0.3858 - val_accuracy: 0.8440\n",
            "Epoch 1759/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8639 - val_loss: 0.3870 - val_accuracy: 0.8451\n",
            "Epoch 1760/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8644 - val_loss: 0.3850 - val_accuracy: 0.8429\n",
            "Epoch 1761/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8626 - val_loss: 0.3821 - val_accuracy: 0.8418\n",
            "Epoch 1762/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3861 - val_accuracy: 0.8440\n",
            "Epoch 1763/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8637 - val_loss: 0.3821 - val_accuracy: 0.8407\n",
            "Epoch 1764/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8628 - val_loss: 0.3854 - val_accuracy: 0.8440\n",
            "Epoch 1765/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8628 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1766/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8628 - val_loss: 0.3868 - val_accuracy: 0.8429\n",
            "Epoch 1767/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8648 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
            "Epoch 1768/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8639 - val_loss: 0.3856 - val_accuracy: 0.8462\n",
            "Epoch 1769/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8633 - val_loss: 0.3857 - val_accuracy: 0.8451\n",
            "Epoch 1770/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3320 - accuracy: 0.8635 - val_loss: 0.3859 - val_accuracy: 0.8440\n",
            "Epoch 1771/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8624 - val_loss: 0.3863 - val_accuracy: 0.8462\n",
            "Epoch 1772/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8633 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 1773/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8649 - val_loss: 0.3826 - val_accuracy: 0.8429\n",
            "Epoch 1774/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 1775/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8626 - val_loss: 0.3832 - val_accuracy: 0.8440\n",
            "Epoch 1776/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8624 - val_loss: 0.3851 - val_accuracy: 0.8451\n",
            "Epoch 1777/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8637 - val_loss: 0.3882 - val_accuracy: 0.8462\n",
            "Epoch 1778/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1779/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8639 - val_loss: 0.3859 - val_accuracy: 0.8429\n",
            "Epoch 1780/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8655 - val_loss: 0.3822 - val_accuracy: 0.8407\n",
            "Epoch 1781/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8610 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1782/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8624 - val_loss: 0.3831 - val_accuracy: 0.8418\n",
            "Epoch 1783/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8626 - val_loss: 0.3822 - val_accuracy: 0.8407\n",
            "Epoch 1784/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8617 - val_loss: 0.3853 - val_accuracy: 0.8451\n",
            "Epoch 1785/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1786/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8642 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1787/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8631 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 1788/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8624 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1789/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8621 - val_loss: 0.3827 - val_accuracy: 0.8374\n",
            "Epoch 1790/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8644 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "Epoch 1791/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8642 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 1792/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8623 - val_loss: 0.3828 - val_accuracy: 0.8429\n",
            "Epoch 1793/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8631 - val_loss: 0.3830 - val_accuracy: 0.8407\n",
            "Epoch 1794/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8635 - val_loss: 0.3826 - val_accuracy: 0.8418\n",
            "Epoch 1795/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8642 - val_loss: 0.3826 - val_accuracy: 0.8440\n",
            "Epoch 1796/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8637 - val_loss: 0.3848 - val_accuracy: 0.8462\n",
            "Epoch 1797/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8639 - val_loss: 0.3844 - val_accuracy: 0.8440\n",
            "Epoch 1798/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3319 - accuracy: 0.8623 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1799/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8626 - val_loss: 0.3837 - val_accuracy: 0.8451\n",
            "Epoch 1800/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3844 - val_accuracy: 0.8473\n",
            "Epoch 1801/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8623 - val_loss: 0.3867 - val_accuracy: 0.8462\n",
            "Epoch 1802/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8621 - val_loss: 0.3865 - val_accuracy: 0.8451\n",
            "Epoch 1803/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8640 - val_loss: 0.3887 - val_accuracy: 0.8451\n",
            "Epoch 1804/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3831 - val_accuracy: 0.8451\n",
            "Epoch 1805/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8633 - val_loss: 0.3822 - val_accuracy: 0.8418\n",
            "Epoch 1806/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8623 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 1807/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8633 - val_loss: 0.3833 - val_accuracy: 0.8473\n",
            "Epoch 1808/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8624 - val_loss: 0.3836 - val_accuracy: 0.8462\n",
            "Epoch 1809/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8642 - val_loss: 0.3838 - val_accuracy: 0.8473\n",
            "Epoch 1810/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8635 - val_loss: 0.3892 - val_accuracy: 0.8429\n",
            "Epoch 1811/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8617 - val_loss: 0.3869 - val_accuracy: 0.8462\n",
            "Epoch 1812/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8633 - val_loss: 0.3900 - val_accuracy: 0.8440\n",
            "Epoch 1813/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8610 - val_loss: 0.3902 - val_accuracy: 0.8451\n",
            "Epoch 1814/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8639 - val_loss: 0.3850 - val_accuracy: 0.8462\n",
            "Epoch 1815/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 1816/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8639 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1817/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8633 - val_loss: 0.3826 - val_accuracy: 0.8407\n",
            "Epoch 1818/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3824 - val_accuracy: 0.8429\n",
            "Epoch 1819/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8637 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
            "Epoch 1820/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8619 - val_loss: 0.3849 - val_accuracy: 0.8451\n",
            "Epoch 1821/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8644 - val_loss: 0.3840 - val_accuracy: 0.8473\n",
            "Epoch 1822/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8635 - val_loss: 0.3826 - val_accuracy: 0.8407\n",
            "Epoch 1823/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8633 - val_loss: 0.3845 - val_accuracy: 0.8473\n",
            "Epoch 1824/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8612 - val_loss: 0.3900 - val_accuracy: 0.8418\n",
            "Epoch 1825/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8637 - val_loss: 0.3819 - val_accuracy: 0.8429\n",
            "Epoch 1826/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8630 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 1827/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8601 - val_loss: 0.3821 - val_accuracy: 0.8429\n",
            "Epoch 1828/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8639 - val_loss: 0.3871 - val_accuracy: 0.8440\n",
            "Epoch 1829/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3324 - accuracy: 0.8623 - val_loss: 0.3911 - val_accuracy: 0.8418\n",
            "Epoch 1830/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8617 - val_loss: 0.3879 - val_accuracy: 0.8462\n",
            "Epoch 1831/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8623 - val_loss: 0.3826 - val_accuracy: 0.8418\n",
            "Epoch 1832/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3333 - accuracy: 0.8624 - val_loss: 0.3826 - val_accuracy: 0.8440\n",
            "Epoch 1833/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8608 - val_loss: 0.3831 - val_accuracy: 0.8451\n",
            "Epoch 1834/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8640 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 1835/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8630 - val_loss: 0.3820 - val_accuracy: 0.8429\n",
            "Epoch 1836/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3332 - accuracy: 0.8619 - val_loss: 0.3823 - val_accuracy: 0.8396\n",
            "Epoch 1837/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8612 - val_loss: 0.3867 - val_accuracy: 0.8440\n",
            "Epoch 1838/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8644 - val_loss: 0.3852 - val_accuracy: 0.8451\n",
            "Epoch 1839/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8635 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1840/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8623 - val_loss: 0.3826 - val_accuracy: 0.8440\n",
            "Epoch 1841/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8646 - val_loss: 0.3832 - val_accuracy: 0.8451\n",
            "Epoch 1842/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8635 - val_loss: 0.3820 - val_accuracy: 0.8429\n",
            "Epoch 1843/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3317 - accuracy: 0.8631 - val_loss: 0.3840 - val_accuracy: 0.8462\n",
            "Epoch 1844/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8642 - val_loss: 0.3865 - val_accuracy: 0.8440\n",
            "Epoch 1845/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8623 - val_loss: 0.3843 - val_accuracy: 0.8451\n",
            "Epoch 1846/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8626 - val_loss: 0.3866 - val_accuracy: 0.8462\n",
            "Epoch 1847/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3321 - accuracy: 0.8657 - val_loss: 0.3828 - val_accuracy: 0.8451\n",
            "Epoch 1848/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8631 - val_loss: 0.3822 - val_accuracy: 0.8418\n",
            "Epoch 1849/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8628 - val_loss: 0.3823 - val_accuracy: 0.8418\n",
            "Epoch 1850/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8648 - val_loss: 0.3844 - val_accuracy: 0.8473\n",
            "Epoch 1851/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8646 - val_loss: 0.3831 - val_accuracy: 0.8440\n",
            "Epoch 1852/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8624 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1853/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8637 - val_loss: 0.3825 - val_accuracy: 0.8418\n",
            "Epoch 1854/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8624 - val_loss: 0.3841 - val_accuracy: 0.8462\n",
            "Epoch 1855/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8639 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1856/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8633 - val_loss: 0.3860 - val_accuracy: 0.8473\n",
            "Epoch 1857/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8651 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1858/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8639 - val_loss: 0.3862 - val_accuracy: 0.8440\n",
            "Epoch 1859/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8642 - val_loss: 0.3826 - val_accuracy: 0.8418\n",
            "Epoch 1860/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8649 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 1861/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8631 - val_loss: 0.3828 - val_accuracy: 0.8440\n",
            "Epoch 1862/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8633 - val_loss: 0.3829 - val_accuracy: 0.8451\n",
            "Epoch 1863/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8630 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 1864/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3322 - accuracy: 0.8619 - val_loss: 0.3884 - val_accuracy: 0.8462\n",
            "Epoch 1865/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8614 - val_loss: 0.3942 - val_accuracy: 0.8385\n",
            "Epoch 1866/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8630 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "Epoch 1867/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8633 - val_loss: 0.3867 - val_accuracy: 0.8473\n",
            "Epoch 1868/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8642 - val_loss: 0.3829 - val_accuracy: 0.8429\n",
            "Epoch 1869/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8626 - val_loss: 0.3838 - val_accuracy: 0.8451\n",
            "Epoch 1870/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8630 - val_loss: 0.3855 - val_accuracy: 0.8451\n",
            "Epoch 1871/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8617 - val_loss: 0.3867 - val_accuracy: 0.8473\n",
            "Epoch 1872/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8624 - val_loss: 0.3884 - val_accuracy: 0.8440\n",
            "Epoch 1873/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8617 - val_loss: 0.3839 - val_accuracy: 0.8473\n",
            "Epoch 1874/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8637 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1875/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8639 - val_loss: 0.3834 - val_accuracy: 0.8462\n",
            "Epoch 1876/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8626 - val_loss: 0.3830 - val_accuracy: 0.8451\n",
            "Epoch 1877/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8635 - val_loss: 0.3842 - val_accuracy: 0.8451\n",
            "Epoch 1878/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8646 - val_loss: 0.3828 - val_accuracy: 0.8418\n",
            "Epoch 1879/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3332 - accuracy: 0.8635 - val_loss: 0.3824 - val_accuracy: 0.8396\n",
            "Epoch 1880/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8626 - val_loss: 0.3876 - val_accuracy: 0.8462\n",
            "Epoch 1881/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3326 - accuracy: 0.8626 - val_loss: 0.3832 - val_accuracy: 0.8440\n",
            "Epoch 1882/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8653 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1883/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8630 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 1884/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3318 - accuracy: 0.8628 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1885/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8640 - val_loss: 0.3888 - val_accuracy: 0.8440\n",
            "Epoch 1886/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8633 - val_loss: 0.3858 - val_accuracy: 0.8451\n",
            "Epoch 1887/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8628 - val_loss: 0.3833 - val_accuracy: 0.8451\n",
            "Epoch 1888/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8624 - val_loss: 0.3860 - val_accuracy: 0.8473\n",
            "Epoch 1889/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8640 - val_loss: 0.3846 - val_accuracy: 0.8462\n",
            "Epoch 1890/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8649 - val_loss: 0.3840 - val_accuracy: 0.8462\n",
            "Epoch 1891/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8617 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1892/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8644 - val_loss: 0.3838 - val_accuracy: 0.8462\n",
            "Epoch 1893/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8648 - val_loss: 0.3859 - val_accuracy: 0.8451\n",
            "Epoch 1894/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8649 - val_loss: 0.3839 - val_accuracy: 0.8451\n",
            "Epoch 1895/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8639 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1896/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8646 - val_loss: 0.3882 - val_accuracy: 0.8462\n",
            "Epoch 1897/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8626 - val_loss: 0.3840 - val_accuracy: 0.8473\n",
            "Epoch 1898/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3314 - accuracy: 0.8644 - val_loss: 0.3845 - val_accuracy: 0.8451\n",
            "Epoch 1899/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8631 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1900/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8633 - val_loss: 0.3832 - val_accuracy: 0.8451\n",
            "Epoch 1901/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8624 - val_loss: 0.3862 - val_accuracy: 0.8451\n",
            "Epoch 1902/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8619 - val_loss: 0.3888 - val_accuracy: 0.8462\n",
            "Epoch 1903/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8623 - val_loss: 0.3881 - val_accuracy: 0.8484\n",
            "Epoch 1904/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8644 - val_loss: 0.3829 - val_accuracy: 0.8440\n",
            "Epoch 1905/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8630 - val_loss: 0.3891 - val_accuracy: 0.8451\n",
            "Epoch 1906/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8646 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1907/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8626 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1908/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8642 - val_loss: 0.3828 - val_accuracy: 0.8418\n",
            "Epoch 1909/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8630 - val_loss: 0.3827 - val_accuracy: 0.8429\n",
            "Epoch 1910/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8631 - val_loss: 0.3861 - val_accuracy: 0.8451\n",
            "Epoch 1911/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3316 - accuracy: 0.8633 - val_loss: 0.3854 - val_accuracy: 0.8451\n",
            "Epoch 1912/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8642 - val_loss: 0.3837 - val_accuracy: 0.8462\n",
            "Epoch 1913/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8639 - val_loss: 0.3845 - val_accuracy: 0.8451\n",
            "Epoch 1914/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8630 - val_loss: 0.3827 - val_accuracy: 0.8440\n",
            "Epoch 1915/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8626 - val_loss: 0.3825 - val_accuracy: 0.8418\n",
            "Epoch 1916/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8640 - val_loss: 0.3847 - val_accuracy: 0.8451\n",
            "Epoch 1917/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8621 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 1918/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8617 - val_loss: 0.3831 - val_accuracy: 0.8429\n",
            "Epoch 1919/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8649 - val_loss: 0.3855 - val_accuracy: 0.8440\n",
            "Epoch 1920/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8630 - val_loss: 0.3835 - val_accuracy: 0.8440\n",
            "Epoch 1921/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8639 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
            "Epoch 1922/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8623 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1923/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8639 - val_loss: 0.3900 - val_accuracy: 0.8440\n",
            "Epoch 1924/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8619 - val_loss: 0.3859 - val_accuracy: 0.8462\n",
            "Epoch 1925/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8619 - val_loss: 0.3908 - val_accuracy: 0.8418\n",
            "Epoch 1926/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8623 - val_loss: 0.3906 - val_accuracy: 0.8429\n",
            "Epoch 1927/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8626 - val_loss: 0.3892 - val_accuracy: 0.8429\n",
            "Epoch 1928/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8642 - val_loss: 0.3867 - val_accuracy: 0.8451\n",
            "Epoch 1929/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8637 - val_loss: 0.3863 - val_accuracy: 0.8440\n",
            "Epoch 1930/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8640 - val_loss: 0.3903 - val_accuracy: 0.8451\n",
            "Epoch 1931/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8628 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "Epoch 1932/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8621 - val_loss: 0.3854 - val_accuracy: 0.8473\n",
            "Epoch 1933/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8633 - val_loss: 0.3831 - val_accuracy: 0.8429\n",
            "Epoch 1934/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8624 - val_loss: 0.3849 - val_accuracy: 0.8462\n",
            "Epoch 1935/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8633 - val_loss: 0.3893 - val_accuracy: 0.8440\n",
            "Epoch 1936/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8621 - val_loss: 0.3861 - val_accuracy: 0.8462\n",
            "Epoch 1937/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8619 - val_loss: 0.3853 - val_accuracy: 0.8451\n",
            "Epoch 1938/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8640 - val_loss: 0.3843 - val_accuracy: 0.8462\n",
            "Epoch 1939/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8637 - val_loss: 0.3837 - val_accuracy: 0.8440\n",
            "Epoch 1940/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8628 - val_loss: 0.3865 - val_accuracy: 0.8473\n",
            "Epoch 1941/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3852 - val_accuracy: 0.8462\n",
            "Epoch 1942/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8631 - val_loss: 0.3875 - val_accuracy: 0.8440\n",
            "Epoch 1943/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8631 - val_loss: 0.3833 - val_accuracy: 0.8451\n",
            "Epoch 1944/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8630 - val_loss: 0.3834 - val_accuracy: 0.8418\n",
            "Epoch 1945/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8635 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1946/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8635 - val_loss: 0.3833 - val_accuracy: 0.8418\n",
            "Epoch 1947/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8635 - val_loss: 0.3836 - val_accuracy: 0.8440\n",
            "Epoch 1948/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8639 - val_loss: 0.3838 - val_accuracy: 0.8418\n",
            "Epoch 1949/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8631 - val_loss: 0.3899 - val_accuracy: 0.8462\n",
            "Epoch 1950/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8614 - val_loss: 0.3868 - val_accuracy: 0.8462\n",
            "Epoch 1951/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8623 - val_loss: 0.3835 - val_accuracy: 0.8462\n",
            "Epoch 1952/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8628 - val_loss: 0.3836 - val_accuracy: 0.8429\n",
            "Epoch 1953/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8617 - val_loss: 0.3836 - val_accuracy: 0.8418\n",
            "Epoch 1954/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8635 - val_loss: 0.3843 - val_accuracy: 0.8451\n",
            "Epoch 1955/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8639 - val_loss: 0.3839 - val_accuracy: 0.8451\n",
            "Epoch 1956/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8631 - val_loss: 0.3884 - val_accuracy: 0.8473\n",
            "Epoch 1957/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8623 - val_loss: 0.3930 - val_accuracy: 0.8418\n",
            "Epoch 1958/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8631 - val_loss: 0.3853 - val_accuracy: 0.8462\n",
            "Epoch 1959/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8633 - val_loss: 0.3837 - val_accuracy: 0.8440\n",
            "Epoch 1960/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8648 - val_loss: 0.3834 - val_accuracy: 0.8418\n",
            "Epoch 1961/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8630 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 1962/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8633 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 1963/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8626 - val_loss: 0.3857 - val_accuracy: 0.8462\n",
            "Epoch 1964/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8635 - val_loss: 0.3872 - val_accuracy: 0.8473\n",
            "Epoch 1965/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8619 - val_loss: 0.3914 - val_accuracy: 0.8407\n",
            "Epoch 1966/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8621 - val_loss: 0.3861 - val_accuracy: 0.8473\n",
            "Epoch 1967/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8642 - val_loss: 0.3846 - val_accuracy: 0.8462\n",
            "Epoch 1968/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8637 - val_loss: 0.3845 - val_accuracy: 0.8462\n",
            "Epoch 1969/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8637 - val_loss: 0.3886 - val_accuracy: 0.8440\n",
            "Epoch 1970/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8626 - val_loss: 0.3835 - val_accuracy: 0.8407\n",
            "Epoch 1971/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8628 - val_loss: 0.3884 - val_accuracy: 0.8440\n",
            "Epoch 1972/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8633 - val_loss: 0.3855 - val_accuracy: 0.8484\n",
            "Epoch 1973/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8633 - val_loss: 0.3909 - val_accuracy: 0.8418\n",
            "Epoch 1974/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8624 - val_loss: 0.3889 - val_accuracy: 0.8440\n",
            "Epoch 1975/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8633 - val_loss: 0.3847 - val_accuracy: 0.8440\n",
            "Epoch 1976/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8648 - val_loss: 0.3839 - val_accuracy: 0.8429\n",
            "Epoch 1977/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3327 - accuracy: 0.8614 - val_loss: 0.3838 - val_accuracy: 0.8429\n",
            "Epoch 1978/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8592 - val_loss: 0.3845 - val_accuracy: 0.8473\n",
            "Epoch 1979/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8633 - val_loss: 0.3854 - val_accuracy: 0.8462\n",
            "Epoch 1980/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8633 - val_loss: 0.3846 - val_accuracy: 0.8473\n",
            "Epoch 1981/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8630 - val_loss: 0.3866 - val_accuracy: 0.8484\n",
            "Epoch 1982/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8635 - val_loss: 0.3871 - val_accuracy: 0.8451\n",
            "Epoch 1983/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8619 - val_loss: 0.3858 - val_accuracy: 0.8484\n",
            "Epoch 1984/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8631 - val_loss: 0.3857 - val_accuracy: 0.8462\n",
            "Epoch 1985/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8624 - val_loss: 0.3831 - val_accuracy: 0.8440\n",
            "Epoch 1986/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8639 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1987/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8639 - val_loss: 0.3851 - val_accuracy: 0.8462\n",
            "Epoch 1988/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8626 - val_loss: 0.3836 - val_accuracy: 0.8429\n",
            "Epoch 1989/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8623 - val_loss: 0.3841 - val_accuracy: 0.8451\n",
            "Epoch 1990/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8633 - val_loss: 0.3834 - val_accuracy: 0.8440\n",
            "Epoch 1991/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8651 - val_loss: 0.3842 - val_accuracy: 0.8440\n",
            "Epoch 1992/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8639 - val_loss: 0.3841 - val_accuracy: 0.8429\n",
            "Epoch 1993/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8635 - val_loss: 0.3846 - val_accuracy: 0.8451\n",
            "Epoch 1994/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8631 - val_loss: 0.3832 - val_accuracy: 0.8429\n",
            "Epoch 1995/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8628 - val_loss: 0.3842 - val_accuracy: 0.8462\n",
            "Epoch 1996/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8633 - val_loss: 0.3833 - val_accuracy: 0.8429\n",
            "Epoch 1997/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3859 - val_accuracy: 0.8473\n",
            "Epoch 1998/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8640 - val_loss: 0.3844 - val_accuracy: 0.8462\n",
            "Epoch 1999/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8623 - val_loss: 0.3844 - val_accuracy: 0.8451\n",
            "Epoch 2000/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8630 - val_loss: 0.3835 - val_accuracy: 0.8418\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f562cbc6090>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.14, batch_size = 260, epochs = 2000, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2000 * 22 = 44000  kere backpropagation oldu (agirliklar guncellendi)."
      ],
      "metadata": {
        "id": "YJM-wv-ZcfL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelde 239 tane parametre var :"
      ],
      "metadata": {
        "id": "DmSSQra-cfUP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ienjqIhDXsAW",
        "outputId": "046642ce-8a89-434d-9062-7e46572d8f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 14)                126       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 105       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 239\n",
            "Trainable params: 239\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarida aldigimiz skorlari dataframe cevirerek inceledik. loss ve val_loss hata skorlarinin gittikce azaldigini, accuracy ve val_accuracy skorlarinin ise egitim ilerledikce arttigini goruyoruz."
      ],
      "metadata": {
        "id": "CahcXwXRcvE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YrOZWlHUcyUt",
        "outputId": "ca485a44-e42c-403d-ffa5-ebf3de425de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   loss  accuracy  val_loss  val_accuracy\n",
              "0 0.596     0.796     0.571         0.796\n",
              "1 0.550     0.796     0.537         0.796\n",
              "2 0.527     0.796     0.523         0.796\n",
              "3 0.515     0.796     0.512         0.796\n",
              "4 0.506     0.796     0.504         0.796"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcfbbf45-ee11-4ece-81d2-458e09c5f487\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.596</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.550</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.537</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.527</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.515</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.512</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.506</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcfbbf45-ee11-4ece-81d2-458e09c5f487')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dcfbbf45-ee11-4ece-81d2-458e09c5f487 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dcfbbf45-ee11-4ece-81d2-458e09c5f487');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "History ile aldigimiz degerleri gorsele aktardik. Alt ve ust kisimlarin ikisinde de bir overfit durumu sz konusu."
      ],
      "metadata": {
        "id": "woaazkJNc26c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "y8PMZSS7cyXl",
        "outputId": "377f7d86-5bf9-4ebb-f3e3-340304ffe42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-- __verbose__ bilgisayarin arkada hangi islemleri yaptiginin ayrintisini verir. Eger 0 dersek bize bu islemleri gostermez. --"
      ],
      "metadata": {
        "id": "VizzOZ79djw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimiz egitildikten sonra X_test ve y_test' i modelimize soktuk. Asagida aldigimiz ciktilar, test datalarinin aldigi __loss function__ ve __accuracy__ degerleri. Yukarida modeli kurarken recall' i da eklemis olsaydik burada 3 cikti alacaktik:"
      ],
      "metadata": {
        "id": "rsOEv3_tdj0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test, verbose=0)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5o0XNJlcyaL",
        "outputId": "32fac4f6-fa79-4a2d-bf52-e5c7389da391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3588966131210327, 0.8517143130302429]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarida aldigimiz ciktilara asagida isim vererek daha anlasilir hale getirdik :"
      ],
      "metadata": {
        "id": "vU16fZYCd3lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2vcKjoncydL",
        "outputId": "bda83688-fe05-4d4e-86ce-968708fcdd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.3588966131210327\n",
            "accuracy :  0.8517143130302429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__y_pred = model.predict_classes(X_test) --->__ tensorflow 2.5' e kadar bu fonksiyon kullaniliyordu, sonradan bu fonksiyon kalkti. Bu fonksiyon classification datalarinda, buldugu olasilik degerlerini 0.5' in altinda ise 0' a; 0.5' in ustunde ise 1'e atayarak veriyordu. Yeni surumlerde kullanilan __y_pred = (model.predict(X_test)__ ise sadece predict uretiyor. Bu yuzden kendimiz manuel olarak __>0.5__ ise 1 sinifina ata diyerek atama islemini kendimiz yapiyoruz __(y_pred = (model.predict(X_test) > 0.5))__ :"
      ],
      "metadata": {
        "id": "09h3ctvkePL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfddSYGBeSBp",
        "outputId": "2ccf53d7-ce4e-403e-fbfe-11f0edde4c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2636  151]\n",
            " [ 368  345]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.95      0.91      2787\n",
            "           1       0.70      0.48      0.57       713\n",
            "\n",
            "    accuracy                           0.85      3500\n",
            "   macro avg       0.79      0.71      0.74      3500\n",
            "weighted avg       0.84      0.85      0.84      3500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test)\n",
        "\n",
        "# Yukaridaki predict' in aciklamasi. Model bize 0 ile 1 arasinda predict' ler uretti.\n",
        "# Onceki yontemde (predict_classes) 0.5'ten kucuk olanlari 0 classina buyuk olanlari 1 classina atiyordu.\n",
        "# Burda atama yok, sadece degerler var."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMStHl0EeSEW",
        "outputId": "32295c60-538b-448d-8773-3dca524c3492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01990449],\n",
              "       [0.09178555],\n",
              "       [0.2958861 ],\n",
              "       ...,\n",
              "       [0.13817057],\n",
              "       [0.18091029],\n",
              "       [0.11192912]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test)>0.5\n",
        "\n",
        "# Yeni yontemde >0.5 diyerek bu islemi manuel olarak yapiyoruz.\n",
        "# ML' de predict_proba 0 ve 1 olma olasiligini dndryordu ve biz index'le hangi olasiligi istiyorsak aliyorduk.\n",
        "# Burda ise bu kodla sadece 1 olma olasiligini dndryor. (Binary classification icin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vjj6DE7eSG2",
        "outputId": "0780a148-6351-457b-c8d6-ff381cdbf6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False],\n",
              "       [False],\n",
              "       [False],\n",
              "       ...,\n",
              "       [False],\n",
              "       [False],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW2UZohTXsAW"
      },
      "source": [
        "### with class_weigth\n",
        "\n",
        "Investigate how the \"class_weight\" hyper-parameter is used in a Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqGp2gSEXsAX",
        "outputId": "e6c35009-bc57-4506-88b0-3b2d9b1576f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 0.6278979907264297, 1: 2.4546827794561934},)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(class_weight = \"balanced\",classes = np.unique(y_train),y = y_train)\n",
        "class_weights = dict(zip(np.unique(y_train), class_weights)),\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(14, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(7, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "# Yukarida structure kurduk. Asagida ise modelin egitim esnasinda kullanacagi sistemi belirledik :\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "ruCVB86GgwDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTVNGjEtXsAX"
      },
      "source": [
        "#### Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.14, batch_size = 260, epochs = 2000, verbose=1,\n",
        "          class_weight ={0 :class_weights[0][1],\n",
        "                        1: class_weights[0][0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvBTklIggwF8",
        "outputId": "d1e58cbb-4b2d-49f6-fe2a-146933a47b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "22/22 [==============================] - 1s 18ms/step - loss: 1.0654 - accuracy: 0.7959 - val_loss: 0.5695 - val_accuracy: 0.7956\n",
            "Epoch 2/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.8207 - accuracy: 0.7964 - val_loss: 0.5425 - val_accuracy: 0.7956\n",
            "Epoch 3/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.6383 - accuracy: 0.7964 - val_loss: 0.5636 - val_accuracy: 0.7956\n",
            "Epoch 4/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5522 - accuracy: 0.7964 - val_loss: 0.6029 - val_accuracy: 0.7956\n",
            "Epoch 5/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.5216 - accuracy: 0.7964 - val_loss: 0.6326 - val_accuracy: 0.7956\n",
            "Epoch 6/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5102 - accuracy: 0.7964 - val_loss: 0.6465 - val_accuracy: 0.7956\n",
            "Epoch 7/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7964 - val_loss: 0.6436 - val_accuracy: 0.7956\n",
            "Epoch 8/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7964 - val_loss: 0.6339 - val_accuracy: 0.7956\n",
            "Epoch 9/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4936 - accuracy: 0.7964 - val_loss: 0.6298 - val_accuracy: 0.7956\n",
            "Epoch 10/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7964 - val_loss: 0.6207 - val_accuracy: 0.7956\n",
            "Epoch 11/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7964 - val_loss: 0.6142 - val_accuracy: 0.7956\n",
            "Epoch 12/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4788 - accuracy: 0.7964 - val_loss: 0.6080 - val_accuracy: 0.7956\n",
            "Epoch 13/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7964 - val_loss: 0.6046 - val_accuracy: 0.7956\n",
            "Epoch 14/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7964 - val_loss: 0.5963 - val_accuracy: 0.7956\n",
            "Epoch 15/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.7964 - val_loss: 0.5939 - val_accuracy: 0.7956\n",
            "Epoch 16/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7964 - val_loss: 0.5899 - val_accuracy: 0.7956\n",
            "Epoch 17/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7964 - val_loss: 0.5839 - val_accuracy: 0.7956\n",
            "Epoch 18/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4564 - accuracy: 0.7964 - val_loss: 0.5805 - val_accuracy: 0.7956\n",
            "Epoch 19/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7964 - val_loss: 0.5777 - val_accuracy: 0.7956\n",
            "Epoch 20/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7964 - val_loss: 0.5762 - val_accuracy: 0.7956\n",
            "Epoch 21/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7964 - val_loss: 0.5769 - val_accuracy: 0.7956\n",
            "Epoch 22/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7964 - val_loss: 0.5682 - val_accuracy: 0.7956\n",
            "Epoch 23/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7964 - val_loss: 0.5711 - val_accuracy: 0.7956\n",
            "Epoch 24/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7964 - val_loss: 0.5678 - val_accuracy: 0.7956\n",
            "Epoch 25/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.7964 - val_loss: 0.5609 - val_accuracy: 0.7956\n",
            "Epoch 26/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.7964 - val_loss: 0.5640 - val_accuracy: 0.7956\n",
            "Epoch 27/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.7964 - val_loss: 0.5661 - val_accuracy: 0.7956\n",
            "Epoch 28/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4361 - accuracy: 0.7964 - val_loss: 0.5597 - val_accuracy: 0.7956\n",
            "Epoch 29/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7964 - val_loss: 0.5582 - val_accuracy: 0.7956\n",
            "Epoch 30/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.7964 - val_loss: 0.5646 - val_accuracy: 0.7956\n",
            "Epoch 31/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.7964 - val_loss: 0.5564 - val_accuracy: 0.7956\n",
            "Epoch 32/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.4294 - accuracy: 0.7964 - val_loss: 0.5664 - val_accuracy: 0.7956\n",
            "Epoch 33/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7964 - val_loss: 0.5550 - val_accuracy: 0.7956\n",
            "Epoch 34/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7964 - val_loss: 0.5569 - val_accuracy: 0.7956\n",
            "Epoch 35/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.7964 - val_loss: 0.5445 - val_accuracy: 0.7956\n",
            "Epoch 36/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.7964 - val_loss: 0.5547 - val_accuracy: 0.7956\n",
            "Epoch 37/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4194 - accuracy: 0.7962 - val_loss: 0.5483 - val_accuracy: 0.7956\n",
            "Epoch 38/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4172 - accuracy: 0.7962 - val_loss: 0.5385 - val_accuracy: 0.7956\n",
            "Epoch 39/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4150 - accuracy: 0.7962 - val_loss: 0.5421 - val_accuracy: 0.7956\n",
            "Epoch 40/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.7962 - val_loss: 0.5432 - val_accuracy: 0.7956\n",
            "Epoch 41/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.7962 - val_loss: 0.5431 - val_accuracy: 0.7956\n",
            "Epoch 42/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4084 - accuracy: 0.7959 - val_loss: 0.5391 - val_accuracy: 0.7956\n",
            "Epoch 43/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.7968 - val_loss: 0.5300 - val_accuracy: 0.7956\n",
            "Epoch 44/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.7964 - val_loss: 0.5401 - val_accuracy: 0.7956\n",
            "Epoch 45/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4026 - accuracy: 0.7966 - val_loss: 0.5364 - val_accuracy: 0.7956\n",
            "Epoch 46/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.7971 - val_loss: 0.5139 - val_accuracy: 0.7967\n",
            "Epoch 47/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.7982 - val_loss: 0.5354 - val_accuracy: 0.7967\n",
            "Epoch 48/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.7989 - val_loss: 0.5324 - val_accuracy: 0.7978\n",
            "Epoch 49/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.7996 - val_loss: 0.5332 - val_accuracy: 0.8000\n",
            "Epoch 50/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8020 - val_loss: 0.5036 - val_accuracy: 0.8011\n",
            "Epoch 51/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8043 - val_loss: 0.5358 - val_accuracy: 0.8000\n",
            "Epoch 52/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8045 - val_loss: 0.5314 - val_accuracy: 0.8022\n",
            "Epoch 53/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8054 - val_loss: 0.5154 - val_accuracy: 0.8033\n",
            "Epoch 54/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8066 - val_loss: 0.5316 - val_accuracy: 0.8033\n",
            "Epoch 55/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8068 - val_loss: 0.4996 - val_accuracy: 0.8066\n",
            "Epoch 56/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8084 - val_loss: 0.5077 - val_accuracy: 0.8066\n",
            "Epoch 57/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8086 - val_loss: 0.5002 - val_accuracy: 0.8077\n",
            "Epoch 58/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8093 - val_loss: 0.5112 - val_accuracy: 0.8077\n",
            "Epoch 59/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8107 - val_loss: 0.5007 - val_accuracy: 0.8077\n",
            "Epoch 60/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8120 - val_loss: 0.5162 - val_accuracy: 0.8077\n",
            "Epoch 61/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.8131 - val_loss: 0.5068 - val_accuracy: 0.8088\n",
            "Epoch 62/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8122 - val_loss: 0.4978 - val_accuracy: 0.8110\n",
            "Epoch 63/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8154 - val_loss: 0.5090 - val_accuracy: 0.8099\n",
            "Epoch 64/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3696 - accuracy: 0.8140 - val_loss: 0.4993 - val_accuracy: 0.8110\n",
            "Epoch 65/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8170 - val_loss: 0.5187 - val_accuracy: 0.8099\n",
            "Epoch 66/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8156 - val_loss: 0.4847 - val_accuracy: 0.8154\n",
            "Epoch 67/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8175 - val_loss: 0.4958 - val_accuracy: 0.8121\n",
            "Epoch 68/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8179 - val_loss: 0.4866 - val_accuracy: 0.8143\n",
            "Epoch 69/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8202 - val_loss: 0.4971 - val_accuracy: 0.8132\n",
            "Epoch 70/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8197 - val_loss: 0.4942 - val_accuracy: 0.8132\n",
            "Epoch 71/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8215 - val_loss: 0.4996 - val_accuracy: 0.8132\n",
            "Epoch 72/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8220 - val_loss: 0.5108 - val_accuracy: 0.8132\n",
            "Epoch 73/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8213 - val_loss: 0.4950 - val_accuracy: 0.8132\n",
            "Epoch 74/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8216 - val_loss: 0.4971 - val_accuracy: 0.8132\n",
            "Epoch 75/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8233 - val_loss: 0.4874 - val_accuracy: 0.8165\n",
            "Epoch 76/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8249 - val_loss: 0.5018 - val_accuracy: 0.8143\n",
            "Epoch 77/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8242 - val_loss: 0.5012 - val_accuracy: 0.8132\n",
            "Epoch 78/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8238 - val_loss: 0.4931 - val_accuracy: 0.8165\n",
            "Epoch 79/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8245 - val_loss: 0.4922 - val_accuracy: 0.8176\n",
            "Epoch 80/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8245 - val_loss: 0.4923 - val_accuracy: 0.8176\n",
            "Epoch 81/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8250 - val_loss: 0.4839 - val_accuracy: 0.8209\n",
            "Epoch 82/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8263 - val_loss: 0.5032 - val_accuracy: 0.8176\n",
            "Epoch 83/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8261 - val_loss: 0.5052 - val_accuracy: 0.8176\n",
            "Epoch 84/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8258 - val_loss: 0.4805 - val_accuracy: 0.8220\n",
            "Epoch 85/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3570 - accuracy: 0.8265 - val_loss: 0.4818 - val_accuracy: 0.8220\n",
            "Epoch 86/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3581 - accuracy: 0.8279 - val_loss: 0.5013 - val_accuracy: 0.8187\n",
            "Epoch 87/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3561 - accuracy: 0.8277 - val_loss: 0.4980 - val_accuracy: 0.8209\n",
            "Epoch 88/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8277 - val_loss: 0.5033 - val_accuracy: 0.8209\n",
            "Epoch 89/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8279 - val_loss: 0.4900 - val_accuracy: 0.8209\n",
            "Epoch 90/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8284 - val_loss: 0.4871 - val_accuracy: 0.8220\n",
            "Epoch 91/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8295 - val_loss: 0.5096 - val_accuracy: 0.8209\n",
            "Epoch 92/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8283 - val_loss: 0.4870 - val_accuracy: 0.8209\n",
            "Epoch 93/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3547 - accuracy: 0.8281 - val_loss: 0.4956 - val_accuracy: 0.8209\n",
            "Epoch 94/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8295 - val_loss: 0.4874 - val_accuracy: 0.8220\n",
            "Epoch 95/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3551 - accuracy: 0.8299 - val_loss: 0.4925 - val_accuracy: 0.8209\n",
            "Epoch 96/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.8292 - val_loss: 0.4993 - val_accuracy: 0.8209\n",
            "Epoch 97/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8306 - val_loss: 0.4974 - val_accuracy: 0.8209\n",
            "Epoch 98/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8306 - val_loss: 0.4969 - val_accuracy: 0.8209\n",
            "Epoch 99/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3536 - accuracy: 0.8304 - val_loss: 0.4850 - val_accuracy: 0.8220\n",
            "Epoch 100/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8311 - val_loss: 0.4991 - val_accuracy: 0.8209\n",
            "Epoch 101/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8313 - val_loss: 0.4982 - val_accuracy: 0.8209\n",
            "Epoch 102/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8331 - val_loss: 0.5007 - val_accuracy: 0.8209\n",
            "Epoch 103/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8304 - val_loss: 0.4950 - val_accuracy: 0.8209\n",
            "Epoch 104/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8309 - val_loss: 0.4805 - val_accuracy: 0.8220\n",
            "Epoch 105/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3535 - accuracy: 0.8324 - val_loss: 0.5060 - val_accuracy: 0.8209\n",
            "Epoch 106/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8335 - val_loss: 0.5166 - val_accuracy: 0.8209\n",
            "Epoch 107/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8324 - val_loss: 0.4797 - val_accuracy: 0.8220\n",
            "Epoch 108/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8331 - val_loss: 0.4923 - val_accuracy: 0.8220\n",
            "Epoch 109/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3528 - accuracy: 0.8336 - val_loss: 0.4916 - val_accuracy: 0.8220\n",
            "Epoch 110/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8311 - val_loss: 0.4874 - val_accuracy: 0.8198\n",
            "Epoch 111/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8335 - val_loss: 0.5100 - val_accuracy: 0.8209\n",
            "Epoch 112/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8345 - val_loss: 0.5015 - val_accuracy: 0.8209\n",
            "Epoch 113/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8329 - val_loss: 0.5079 - val_accuracy: 0.8209\n",
            "Epoch 114/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8335 - val_loss: 0.4992 - val_accuracy: 0.8209\n",
            "Epoch 115/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8327 - val_loss: 0.4927 - val_accuracy: 0.8220\n",
            "Epoch 116/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3517 - accuracy: 0.8333 - val_loss: 0.5081 - val_accuracy: 0.8209\n",
            "Epoch 117/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3517 - accuracy: 0.8333 - val_loss: 0.4799 - val_accuracy: 0.8231\n",
            "Epoch 118/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8342 - val_loss: 0.4874 - val_accuracy: 0.8209\n",
            "Epoch 119/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8342 - val_loss: 0.5029 - val_accuracy: 0.8198\n",
            "Epoch 120/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3519 - accuracy: 0.8347 - val_loss: 0.5007 - val_accuracy: 0.8198\n",
            "Epoch 121/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8329 - val_loss: 0.4869 - val_accuracy: 0.8209\n",
            "Epoch 122/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3512 - accuracy: 0.8358 - val_loss: 0.5150 - val_accuracy: 0.8209\n",
            "Epoch 123/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3509 - accuracy: 0.8336 - val_loss: 0.4805 - val_accuracy: 0.8231\n",
            "Epoch 124/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8336 - val_loss: 0.4929 - val_accuracy: 0.8220\n",
            "Epoch 125/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8358 - val_loss: 0.5038 - val_accuracy: 0.8220\n",
            "Epoch 126/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.8349 - val_loss: 0.4804 - val_accuracy: 0.8231\n",
            "Epoch 127/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.8326 - val_loss: 0.4938 - val_accuracy: 0.8209\n",
            "Epoch 128/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3508 - accuracy: 0.8351 - val_loss: 0.4883 - val_accuracy: 0.8209\n",
            "Epoch 129/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8349 - val_loss: 0.4967 - val_accuracy: 0.8220\n",
            "Epoch 130/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8349 - val_loss: 0.4947 - val_accuracy: 0.8220\n",
            "Epoch 131/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8356 - val_loss: 0.5004 - val_accuracy: 0.8220\n",
            "Epoch 132/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8358 - val_loss: 0.4994 - val_accuracy: 0.8209\n",
            "Epoch 133/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3516 - accuracy: 0.8347 - val_loss: 0.5048 - val_accuracy: 0.8198\n",
            "Epoch 134/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3507 - accuracy: 0.8335 - val_loss: 0.4916 - val_accuracy: 0.8220\n",
            "Epoch 135/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8358 - val_loss: 0.4966 - val_accuracy: 0.8231\n",
            "Epoch 136/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8354 - val_loss: 0.4872 - val_accuracy: 0.8231\n",
            "Epoch 137/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8356 - val_loss: 0.4916 - val_accuracy: 0.8231\n",
            "Epoch 138/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8358 - val_loss: 0.4865 - val_accuracy: 0.8231\n",
            "Epoch 139/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8352 - val_loss: 0.4826 - val_accuracy: 0.8253\n",
            "Epoch 140/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3499 - accuracy: 0.8354 - val_loss: 0.4947 - val_accuracy: 0.8231\n",
            "Epoch 141/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8361 - val_loss: 0.4733 - val_accuracy: 0.8275\n",
            "Epoch 142/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8386 - val_loss: 0.5099 - val_accuracy: 0.8209\n",
            "Epoch 143/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8363 - val_loss: 0.5049 - val_accuracy: 0.8220\n",
            "Epoch 144/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.8351 - val_loss: 0.4823 - val_accuracy: 0.8242\n",
            "Epoch 145/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8369 - val_loss: 0.4768 - val_accuracy: 0.8275\n",
            "Epoch 146/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3494 - accuracy: 0.8352 - val_loss: 0.4921 - val_accuracy: 0.8253\n",
            "Epoch 147/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8369 - val_loss: 0.4972 - val_accuracy: 0.8231\n",
            "Epoch 148/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8358 - val_loss: 0.4936 - val_accuracy: 0.8231\n",
            "Epoch 149/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8360 - val_loss: 0.4868 - val_accuracy: 0.8242\n",
            "Epoch 150/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3492 - accuracy: 0.8358 - val_loss: 0.4893 - val_accuracy: 0.8242\n",
            "Epoch 151/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3494 - accuracy: 0.8351 - val_loss: 0.4846 - val_accuracy: 0.8242\n",
            "Epoch 152/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 0.8374 - val_loss: 0.4993 - val_accuracy: 0.8231\n",
            "Epoch 153/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8351 - val_loss: 0.4890 - val_accuracy: 0.8231\n",
            "Epoch 154/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8360 - val_loss: 0.5003 - val_accuracy: 0.8220\n",
            "Epoch 155/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8363 - val_loss: 0.4963 - val_accuracy: 0.8242\n",
            "Epoch 156/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3490 - accuracy: 0.8367 - val_loss: 0.4960 - val_accuracy: 0.8242\n",
            "Epoch 157/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8354 - val_loss: 0.4998 - val_accuracy: 0.8242\n",
            "Epoch 158/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8358 - val_loss: 0.5003 - val_accuracy: 0.8242\n",
            "Epoch 159/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8369 - val_loss: 0.4995 - val_accuracy: 0.8242\n",
            "Epoch 160/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3486 - accuracy: 0.8356 - val_loss: 0.4878 - val_accuracy: 0.8242\n",
            "Epoch 161/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3484 - accuracy: 0.8367 - val_loss: 0.4864 - val_accuracy: 0.8242\n",
            "Epoch 162/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3483 - accuracy: 0.8386 - val_loss: 0.5071 - val_accuracy: 0.8220\n",
            "Epoch 163/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8369 - val_loss: 0.5013 - val_accuracy: 0.8242\n",
            "Epoch 164/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8356 - val_loss: 0.4872 - val_accuracy: 0.8242\n",
            "Epoch 165/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8372 - val_loss: 0.4881 - val_accuracy: 0.8253\n",
            "Epoch 166/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8381 - val_loss: 0.4988 - val_accuracy: 0.8242\n",
            "Epoch 167/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8374 - val_loss: 0.5072 - val_accuracy: 0.8220\n",
            "Epoch 168/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8370 - val_loss: 0.4910 - val_accuracy: 0.8242\n",
            "Epoch 169/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8361 - val_loss: 0.4799 - val_accuracy: 0.8275\n",
            "Epoch 170/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8377 - val_loss: 0.5045 - val_accuracy: 0.8231\n",
            "Epoch 171/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3480 - accuracy: 0.8374 - val_loss: 0.4952 - val_accuracy: 0.8242\n",
            "Epoch 172/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8372 - val_loss: 0.4883 - val_accuracy: 0.8242\n",
            "Epoch 173/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8360 - val_loss: 0.4847 - val_accuracy: 0.8253\n",
            "Epoch 174/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8376 - val_loss: 0.4982 - val_accuracy: 0.8253\n",
            "Epoch 175/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8376 - val_loss: 0.4950 - val_accuracy: 0.8242\n",
            "Epoch 176/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3479 - accuracy: 0.8361 - val_loss: 0.4809 - val_accuracy: 0.8253\n",
            "Epoch 177/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3478 - accuracy: 0.8385 - val_loss: 0.4927 - val_accuracy: 0.8253\n",
            "Epoch 178/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8376 - val_loss: 0.5010 - val_accuracy: 0.8242\n",
            "Epoch 179/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8385 - val_loss: 0.4976 - val_accuracy: 0.8253\n",
            "Epoch 180/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3477 - accuracy: 0.8386 - val_loss: 0.4936 - val_accuracy: 0.8253\n",
            "Epoch 181/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8372 - val_loss: 0.4879 - val_accuracy: 0.8242\n",
            "Epoch 182/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8374 - val_loss: 0.4880 - val_accuracy: 0.8242\n",
            "Epoch 183/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8381 - val_loss: 0.4911 - val_accuracy: 0.8242\n",
            "Epoch 184/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8392 - val_loss: 0.5174 - val_accuracy: 0.8187\n",
            "Epoch 185/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8361 - val_loss: 0.4724 - val_accuracy: 0.8297\n",
            "Epoch 186/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8356 - val_loss: 0.4781 - val_accuracy: 0.8275\n",
            "Epoch 187/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3483 - accuracy: 0.8385 - val_loss: 0.4901 - val_accuracy: 0.8253\n",
            "Epoch 188/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8388 - val_loss: 0.4947 - val_accuracy: 0.8253\n",
            "Epoch 189/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8390 - val_loss: 0.4993 - val_accuracy: 0.8242\n",
            "Epoch 190/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3475 - accuracy: 0.8379 - val_loss: 0.5029 - val_accuracy: 0.8242\n",
            "Epoch 191/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8379 - val_loss: 0.4965 - val_accuracy: 0.8242\n",
            "Epoch 192/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8361 - val_loss: 0.4732 - val_accuracy: 0.8297\n",
            "Epoch 193/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8379 - val_loss: 0.4933 - val_accuracy: 0.8242\n",
            "Epoch 194/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8388 - val_loss: 0.4955 - val_accuracy: 0.8242\n",
            "Epoch 195/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3467 - accuracy: 0.8370 - val_loss: 0.4915 - val_accuracy: 0.8242\n",
            "Epoch 196/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8377 - val_loss: 0.5023 - val_accuracy: 0.8231\n",
            "Epoch 197/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3471 - accuracy: 0.8377 - val_loss: 0.4945 - val_accuracy: 0.8242\n",
            "Epoch 198/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3467 - accuracy: 0.8363 - val_loss: 0.4865 - val_accuracy: 0.8253\n",
            "Epoch 199/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8386 - val_loss: 0.4956 - val_accuracy: 0.8242\n",
            "Epoch 200/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3468 - accuracy: 0.8388 - val_loss: 0.5016 - val_accuracy: 0.8231\n",
            "Epoch 201/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.8369 - val_loss: 0.4781 - val_accuracy: 0.8297\n",
            "Epoch 202/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8376 - val_loss: 0.4951 - val_accuracy: 0.8253\n",
            "Epoch 203/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8386 - val_loss: 0.4999 - val_accuracy: 0.8242\n",
            "Epoch 204/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8383 - val_loss: 0.4890 - val_accuracy: 0.8231\n",
            "Epoch 205/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8383 - val_loss: 0.4886 - val_accuracy: 0.8253\n",
            "Epoch 206/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8395 - val_loss: 0.4885 - val_accuracy: 0.8253\n",
            "Epoch 207/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8390 - val_loss: 0.4859 - val_accuracy: 0.8253\n",
            "Epoch 208/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8388 - val_loss: 0.4945 - val_accuracy: 0.8242\n",
            "Epoch 209/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8399 - val_loss: 0.4840 - val_accuracy: 0.8264\n",
            "Epoch 210/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8388 - val_loss: 0.5007 - val_accuracy: 0.8242\n",
            "Epoch 211/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8381 - val_loss: 0.4953 - val_accuracy: 0.8242\n",
            "Epoch 212/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8385 - val_loss: 0.4836 - val_accuracy: 0.8275\n",
            "Epoch 213/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3459 - accuracy: 0.8397 - val_loss: 0.5061 - val_accuracy: 0.8231\n",
            "Epoch 214/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8379 - val_loss: 0.4952 - val_accuracy: 0.8242\n",
            "Epoch 215/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8379 - val_loss: 0.4800 - val_accuracy: 0.8286\n",
            "Epoch 216/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8385 - val_loss: 0.4837 - val_accuracy: 0.8286\n",
            "Epoch 217/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8397 - val_loss: 0.4937 - val_accuracy: 0.8242\n",
            "Epoch 218/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8399 - val_loss: 0.5064 - val_accuracy: 0.8231\n",
            "Epoch 219/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3456 - accuracy: 0.8372 - val_loss: 0.4830 - val_accuracy: 0.8275\n",
            "Epoch 220/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8379 - val_loss: 0.4782 - val_accuracy: 0.8275\n",
            "Epoch 221/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8388 - val_loss: 0.4987 - val_accuracy: 0.8242\n",
            "Epoch 222/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8399 - val_loss: 0.4957 - val_accuracy: 0.8242\n",
            "Epoch 223/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8385 - val_loss: 0.4912 - val_accuracy: 0.8242\n",
            "Epoch 224/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8386 - val_loss: 0.4930 - val_accuracy: 0.8264\n",
            "Epoch 225/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3457 - accuracy: 0.8386 - val_loss: 0.4906 - val_accuracy: 0.8242\n",
            "Epoch 226/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8394 - val_loss: 0.4964 - val_accuracy: 0.8242\n",
            "Epoch 227/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8406 - val_loss: 0.5065 - val_accuracy: 0.8231\n",
            "Epoch 228/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3455 - accuracy: 0.8395 - val_loss: 0.4974 - val_accuracy: 0.8242\n",
            "Epoch 229/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8390 - val_loss: 0.4881 - val_accuracy: 0.8253\n",
            "Epoch 230/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3450 - accuracy: 0.8390 - val_loss: 0.4893 - val_accuracy: 0.8242\n",
            "Epoch 231/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8395 - val_loss: 0.4984 - val_accuracy: 0.8242\n",
            "Epoch 232/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8394 - val_loss: 0.4899 - val_accuracy: 0.8253\n",
            "Epoch 233/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8395 - val_loss: 0.4768 - val_accuracy: 0.8297\n",
            "Epoch 234/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3451 - accuracy: 0.8408 - val_loss: 0.5090 - val_accuracy: 0.8231\n",
            "Epoch 235/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8406 - val_loss: 0.4920 - val_accuracy: 0.8253\n",
            "Epoch 236/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3450 - accuracy: 0.8394 - val_loss: 0.4904 - val_accuracy: 0.8253\n",
            "Epoch 237/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8403 - val_loss: 0.4902 - val_accuracy: 0.8253\n",
            "Epoch 238/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3450 - accuracy: 0.8408 - val_loss: 0.4941 - val_accuracy: 0.8253\n",
            "Epoch 239/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3451 - accuracy: 0.8395 - val_loss: 0.4857 - val_accuracy: 0.8264\n",
            "Epoch 240/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8401 - val_loss: 0.5042 - val_accuracy: 0.8242\n",
            "Epoch 241/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8410 - val_loss: 0.4882 - val_accuracy: 0.8253\n",
            "Epoch 242/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8408 - val_loss: 0.5028 - val_accuracy: 0.8242\n",
            "Epoch 243/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8385 - val_loss: 0.4925 - val_accuracy: 0.8253\n",
            "Epoch 244/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3445 - accuracy: 0.8394 - val_loss: 0.4782 - val_accuracy: 0.8297\n",
            "Epoch 245/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8399 - val_loss: 0.4787 - val_accuracy: 0.8275\n",
            "Epoch 246/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8413 - val_loss: 0.4936 - val_accuracy: 0.8253\n",
            "Epoch 247/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8411 - val_loss: 0.4880 - val_accuracy: 0.8264\n",
            "Epoch 248/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8408 - val_loss: 0.4924 - val_accuracy: 0.8253\n",
            "Epoch 249/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8413 - val_loss: 0.4988 - val_accuracy: 0.8253\n",
            "Epoch 250/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8410 - val_loss: 0.4987 - val_accuracy: 0.8253\n",
            "Epoch 251/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8399 - val_loss: 0.4830 - val_accuracy: 0.8264\n",
            "Epoch 252/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8406 - val_loss: 0.4832 - val_accuracy: 0.8264\n",
            "Epoch 253/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8404 - val_loss: 0.4967 - val_accuracy: 0.8253\n",
            "Epoch 254/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3444 - accuracy: 0.8422 - val_loss: 0.5003 - val_accuracy: 0.8253\n",
            "Epoch 255/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3442 - accuracy: 0.8390 - val_loss: 0.4820 - val_accuracy: 0.8264\n",
            "Epoch 256/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8410 - val_loss: 0.4926 - val_accuracy: 0.8264\n",
            "Epoch 257/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3443 - accuracy: 0.8422 - val_loss: 0.5034 - val_accuracy: 0.8253\n",
            "Epoch 258/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8395 - val_loss: 0.4822 - val_accuracy: 0.8264\n",
            "Epoch 259/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8401 - val_loss: 0.4872 - val_accuracy: 0.8275\n",
            "Epoch 260/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8410 - val_loss: 0.5021 - val_accuracy: 0.8253\n",
            "Epoch 261/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8410 - val_loss: 0.4796 - val_accuracy: 0.8286\n",
            "Epoch 262/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3445 - accuracy: 0.8399 - val_loss: 0.4787 - val_accuracy: 0.8264\n",
            "Epoch 263/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3443 - accuracy: 0.8413 - val_loss: 0.4834 - val_accuracy: 0.8264\n",
            "Epoch 264/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3440 - accuracy: 0.8408 - val_loss: 0.4816 - val_accuracy: 0.8253\n",
            "Epoch 265/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8413 - val_loss: 0.4912 - val_accuracy: 0.8253\n",
            "Epoch 266/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3439 - accuracy: 0.8397 - val_loss: 0.4826 - val_accuracy: 0.8275\n",
            "Epoch 267/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8404 - val_loss: 0.4868 - val_accuracy: 0.8275\n",
            "Epoch 268/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3439 - accuracy: 0.8411 - val_loss: 0.5045 - val_accuracy: 0.8253\n",
            "Epoch 269/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8406 - val_loss: 0.4856 - val_accuracy: 0.8275\n",
            "Epoch 270/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.8406 - val_loss: 0.4922 - val_accuracy: 0.8253\n",
            "Epoch 271/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3433 - accuracy: 0.8408 - val_loss: 0.4743 - val_accuracy: 0.8286\n",
            "Epoch 272/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3447 - accuracy: 0.8406 - val_loss: 0.4917 - val_accuracy: 0.8275\n",
            "Epoch 273/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3435 - accuracy: 0.8417 - val_loss: 0.4819 - val_accuracy: 0.8253\n",
            "Epoch 274/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3437 - accuracy: 0.8417 - val_loss: 0.4961 - val_accuracy: 0.8264\n",
            "Epoch 275/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8419 - val_loss: 0.4881 - val_accuracy: 0.8275\n",
            "Epoch 276/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3436 - accuracy: 0.8408 - val_loss: 0.4887 - val_accuracy: 0.8286\n",
            "Epoch 277/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8424 - val_loss: 0.4925 - val_accuracy: 0.8264\n",
            "Epoch 278/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8419 - val_loss: 0.4965 - val_accuracy: 0.8253\n",
            "Epoch 279/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8411 - val_loss: 0.4856 - val_accuracy: 0.8264\n",
            "Epoch 280/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8420 - val_loss: 0.4839 - val_accuracy: 0.8264\n",
            "Epoch 281/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8422 - val_loss: 0.4849 - val_accuracy: 0.8264\n",
            "Epoch 282/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8420 - val_loss: 0.4871 - val_accuracy: 0.8275\n",
            "Epoch 283/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8420 - val_loss: 0.4905 - val_accuracy: 0.8275\n",
            "Epoch 284/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8406 - val_loss: 0.4782 - val_accuracy: 0.8286\n",
            "Epoch 285/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8422 - val_loss: 0.4816 - val_accuracy: 0.8286\n",
            "Epoch 286/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8424 - val_loss: 0.4901 - val_accuracy: 0.8275\n",
            "Epoch 287/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.8413 - val_loss: 0.4895 - val_accuracy: 0.8275\n",
            "Epoch 288/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3434 - accuracy: 0.8417 - val_loss: 0.4945 - val_accuracy: 0.8275\n",
            "Epoch 289/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8413 - val_loss: 0.4818 - val_accuracy: 0.8286\n",
            "Epoch 290/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8424 - val_loss: 0.4864 - val_accuracy: 0.8286\n",
            "Epoch 291/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3430 - accuracy: 0.8415 - val_loss: 0.4840 - val_accuracy: 0.8286\n",
            "Epoch 292/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3433 - accuracy: 0.8417 - val_loss: 0.4975 - val_accuracy: 0.8253\n",
            "Epoch 293/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8419 - val_loss: 0.4915 - val_accuracy: 0.8275\n",
            "Epoch 294/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3429 - accuracy: 0.8420 - val_loss: 0.4959 - val_accuracy: 0.8253\n",
            "Epoch 295/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8419 - val_loss: 0.4723 - val_accuracy: 0.8308\n",
            "Epoch 296/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3438 - accuracy: 0.8411 - val_loss: 0.4679 - val_accuracy: 0.8308\n",
            "Epoch 297/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8415 - val_loss: 0.4909 - val_accuracy: 0.8275\n",
            "Epoch 298/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8428 - val_loss: 0.4788 - val_accuracy: 0.8275\n",
            "Epoch 299/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8426 - val_loss: 0.4899 - val_accuracy: 0.8275\n",
            "Epoch 300/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8417 - val_loss: 0.4942 - val_accuracy: 0.8275\n",
            "Epoch 301/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8424 - val_loss: 0.4834 - val_accuracy: 0.8286\n",
            "Epoch 302/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.8431 - val_loss: 0.4898 - val_accuracy: 0.8286\n",
            "Epoch 303/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8426 - val_loss: 0.4789 - val_accuracy: 0.8275\n",
            "Epoch 304/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8424 - val_loss: 0.4845 - val_accuracy: 0.8275\n",
            "Epoch 305/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8424 - val_loss: 0.4867 - val_accuracy: 0.8275\n",
            "Epoch 306/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3426 - accuracy: 0.8426 - val_loss: 0.4880 - val_accuracy: 0.8275\n",
            "Epoch 307/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8424 - val_loss: 0.4895 - val_accuracy: 0.8286\n",
            "Epoch 308/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8424 - val_loss: 0.4869 - val_accuracy: 0.8275\n",
            "Epoch 309/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3424 - accuracy: 0.8413 - val_loss: 0.4682 - val_accuracy: 0.8319\n",
            "Epoch 310/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.8420 - val_loss: 0.4955 - val_accuracy: 0.8253\n",
            "Epoch 311/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8428 - val_loss: 0.5007 - val_accuracy: 0.8253\n",
            "Epoch 312/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3428 - accuracy: 0.8413 - val_loss: 0.4840 - val_accuracy: 0.8275\n",
            "Epoch 313/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.8411 - val_loss: 0.4892 - val_accuracy: 0.8286\n",
            "Epoch 314/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3425 - accuracy: 0.8429 - val_loss: 0.4960 - val_accuracy: 0.8253\n",
            "Epoch 315/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8428 - val_loss: 0.4990 - val_accuracy: 0.8253\n",
            "Epoch 316/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3422 - accuracy: 0.8424 - val_loss: 0.4895 - val_accuracy: 0.8286\n",
            "Epoch 317/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3426 - accuracy: 0.8411 - val_loss: 0.4689 - val_accuracy: 0.8308\n",
            "Epoch 318/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8426 - val_loss: 0.4883 - val_accuracy: 0.8275\n",
            "Epoch 319/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8422 - val_loss: 0.4925 - val_accuracy: 0.8275\n",
            "Epoch 320/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8429 - val_loss: 0.4956 - val_accuracy: 0.8253\n",
            "Epoch 321/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3418 - accuracy: 0.8419 - val_loss: 0.4765 - val_accuracy: 0.8275\n",
            "Epoch 322/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8428 - val_loss: 0.4843 - val_accuracy: 0.8286\n",
            "Epoch 323/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8428 - val_loss: 0.4861 - val_accuracy: 0.8275\n",
            "Epoch 324/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8420 - val_loss: 0.4835 - val_accuracy: 0.8275\n",
            "Epoch 325/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8426 - val_loss: 0.4784 - val_accuracy: 0.8275\n",
            "Epoch 326/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8422 - val_loss: 0.4806 - val_accuracy: 0.8286\n",
            "Epoch 327/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3418 - accuracy: 0.8424 - val_loss: 0.4838 - val_accuracy: 0.8286\n",
            "Epoch 328/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8429 - val_loss: 0.4906 - val_accuracy: 0.8286\n",
            "Epoch 329/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8431 - val_loss: 0.4795 - val_accuracy: 0.8264\n",
            "Epoch 330/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3417 - accuracy: 0.8426 - val_loss: 0.4847 - val_accuracy: 0.8286\n",
            "Epoch 331/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8417 - val_loss: 0.4765 - val_accuracy: 0.8275\n",
            "Epoch 332/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8426 - val_loss: 0.5002 - val_accuracy: 0.8253\n",
            "Epoch 333/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3415 - accuracy: 0.8415 - val_loss: 0.4796 - val_accuracy: 0.8275\n",
            "Epoch 334/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3420 - accuracy: 0.8419 - val_loss: 0.4765 - val_accuracy: 0.8286\n",
            "Epoch 335/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8435 - val_loss: 0.4883 - val_accuracy: 0.8286\n",
            "Epoch 336/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8429 - val_loss: 0.4906 - val_accuracy: 0.8297\n",
            "Epoch 337/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8428 - val_loss: 0.4871 - val_accuracy: 0.8286\n",
            "Epoch 338/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8428 - val_loss: 0.4867 - val_accuracy: 0.8286\n",
            "Epoch 339/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8429 - val_loss: 0.4922 - val_accuracy: 0.8275\n",
            "Epoch 340/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3413 - accuracy: 0.8435 - val_loss: 0.4958 - val_accuracy: 0.8275\n",
            "Epoch 341/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.8428 - val_loss: 0.4856 - val_accuracy: 0.8286\n",
            "Epoch 342/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.8275\n",
            "Epoch 343/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3416 - accuracy: 0.8428 - val_loss: 0.4805 - val_accuracy: 0.8286\n",
            "Epoch 344/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8438 - val_loss: 0.4935 - val_accuracy: 0.8275\n",
            "Epoch 345/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3414 - accuracy: 0.8428 - val_loss: 0.4838 - val_accuracy: 0.8286\n",
            "Epoch 346/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3415 - accuracy: 0.8431 - val_loss: 0.4829 - val_accuracy: 0.8275\n",
            "Epoch 347/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3414 - accuracy: 0.8428 - val_loss: 0.4814 - val_accuracy: 0.8286\n",
            "Epoch 348/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3412 - accuracy: 0.8431 - val_loss: 0.4973 - val_accuracy: 0.8275\n",
            "Epoch 349/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3421 - accuracy: 0.8420 - val_loss: 0.4958 - val_accuracy: 0.8253\n",
            "Epoch 350/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8433 - val_loss: 0.4962 - val_accuracy: 0.8264\n",
            "Epoch 351/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8419 - val_loss: 0.4841 - val_accuracy: 0.8275\n",
            "Epoch 352/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8433 - val_loss: 0.4937 - val_accuracy: 0.8286\n",
            "Epoch 353/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8436 - val_loss: 0.4963 - val_accuracy: 0.8264\n",
            "Epoch 354/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8429 - val_loss: 0.4791 - val_accuracy: 0.8286\n",
            "Epoch 355/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8436 - val_loss: 0.4878 - val_accuracy: 0.8286\n",
            "Epoch 356/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8431 - val_loss: 0.4878 - val_accuracy: 0.8286\n",
            "Epoch 357/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8435 - val_loss: 0.5003 - val_accuracy: 0.8253\n",
            "Epoch 358/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3416 - accuracy: 0.8435 - val_loss: 0.4952 - val_accuracy: 0.8286\n",
            "Epoch 359/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3413 - accuracy: 0.8429 - val_loss: 0.4972 - val_accuracy: 0.8264\n",
            "Epoch 360/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3406 - accuracy: 0.8436 - val_loss: 0.4783 - val_accuracy: 0.8286\n",
            "Epoch 361/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3410 - accuracy: 0.8420 - val_loss: 0.4869 - val_accuracy: 0.8286\n",
            "Epoch 362/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3409 - accuracy: 0.8442 - val_loss: 0.5012 - val_accuracy: 0.8253\n",
            "Epoch 363/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.8429 - val_loss: 0.4886 - val_accuracy: 0.8286\n",
            "Epoch 364/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8435 - val_loss: 0.4876 - val_accuracy: 0.8275\n",
            "Epoch 365/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8435 - val_loss: 0.4840 - val_accuracy: 0.8286\n",
            "Epoch 366/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3416 - accuracy: 0.8415 - val_loss: 0.4649 - val_accuracy: 0.8308\n",
            "Epoch 367/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8424 - val_loss: 0.4784 - val_accuracy: 0.8297\n",
            "Epoch 368/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.8445 - val_loss: 0.4978 - val_accuracy: 0.8264\n",
            "Epoch 369/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8435 - val_loss: 0.4931 - val_accuracy: 0.8297\n",
            "Epoch 370/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3406 - accuracy: 0.8433 - val_loss: 0.4923 - val_accuracy: 0.8297\n",
            "Epoch 371/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3405 - accuracy: 0.8436 - val_loss: 0.4956 - val_accuracy: 0.8264\n",
            "Epoch 372/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3411 - accuracy: 0.8408 - val_loss: 0.4745 - val_accuracy: 0.8286\n",
            "Epoch 373/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8438 - val_loss: 0.4880 - val_accuracy: 0.8286\n",
            "Epoch 374/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8431 - val_loss: 0.4813 - val_accuracy: 0.8275\n",
            "Epoch 375/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8440 - val_loss: 0.4912 - val_accuracy: 0.8286\n",
            "Epoch 376/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8426 - val_loss: 0.4928 - val_accuracy: 0.8275\n",
            "Epoch 377/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8442 - val_loss: 0.4893 - val_accuracy: 0.8286\n",
            "Epoch 378/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8447 - val_loss: 0.5038 - val_accuracy: 0.8253\n",
            "Epoch 379/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3404 - accuracy: 0.8422 - val_loss: 0.4779 - val_accuracy: 0.8297\n",
            "Epoch 380/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8445 - val_loss: 0.4977 - val_accuracy: 0.8264\n",
            "Epoch 381/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8431 - val_loss: 0.4714 - val_accuracy: 0.8308\n",
            "Epoch 382/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3403 - accuracy: 0.8429 - val_loss: 0.4975 - val_accuracy: 0.8275\n",
            "Epoch 383/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3401 - accuracy: 0.8444 - val_loss: 0.4846 - val_accuracy: 0.8286\n",
            "Epoch 384/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8431 - val_loss: 0.4791 - val_accuracy: 0.8297\n",
            "Epoch 385/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8442 - val_loss: 0.4863 - val_accuracy: 0.8297\n",
            "Epoch 386/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8433 - val_loss: 0.4937 - val_accuracy: 0.8275\n",
            "Epoch 387/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8444 - val_loss: 0.4852 - val_accuracy: 0.8297\n",
            "Epoch 388/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3407 - accuracy: 0.8420 - val_loss: 0.4621 - val_accuracy: 0.8319\n",
            "Epoch 389/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8431 - val_loss: 0.4911 - val_accuracy: 0.8286\n",
            "Epoch 390/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3411 - accuracy: 0.8428 - val_loss: 0.4933 - val_accuracy: 0.8275\n",
            "Epoch 391/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3401 - accuracy: 0.8445 - val_loss: 0.4830 - val_accuracy: 0.8297\n",
            "Epoch 392/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8436 - val_loss: 0.4879 - val_accuracy: 0.8286\n",
            "Epoch 393/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3396 - accuracy: 0.8442 - val_loss: 0.4865 - val_accuracy: 0.8297\n",
            "Epoch 394/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8444 - val_loss: 0.4934 - val_accuracy: 0.8286\n",
            "Epoch 395/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3404 - accuracy: 0.8442 - val_loss: 0.4864 - val_accuracy: 0.8297\n",
            "Epoch 396/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3398 - accuracy: 0.8417 - val_loss: 0.4665 - val_accuracy: 0.8319\n",
            "Epoch 397/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8428 - val_loss: 0.4825 - val_accuracy: 0.8297\n",
            "Epoch 398/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8449 - val_loss: 0.4963 - val_accuracy: 0.8286\n",
            "Epoch 399/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8435 - val_loss: 0.4811 - val_accuracy: 0.8297\n",
            "Epoch 400/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8442 - val_loss: 0.4836 - val_accuracy: 0.8297\n",
            "Epoch 401/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8440 - val_loss: 0.4839 - val_accuracy: 0.8297\n",
            "Epoch 402/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8440 - val_loss: 0.4846 - val_accuracy: 0.8297\n",
            "Epoch 403/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3399 - accuracy: 0.8429 - val_loss: 0.4860 - val_accuracy: 0.8308\n",
            "Epoch 404/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.8444 - val_loss: 0.4859 - val_accuracy: 0.8297\n",
            "Epoch 405/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8438 - val_loss: 0.4889 - val_accuracy: 0.8286\n",
            "Epoch 406/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3393 - accuracy: 0.8433 - val_loss: 0.4935 - val_accuracy: 0.8297\n",
            "Epoch 407/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3402 - accuracy: 0.8426 - val_loss: 0.4740 - val_accuracy: 0.8319\n",
            "Epoch 408/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8438 - val_loss: 0.4987 - val_accuracy: 0.8297\n",
            "Epoch 409/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8435 - val_loss: 0.4757 - val_accuracy: 0.8308\n",
            "Epoch 410/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8447 - val_loss: 0.4886 - val_accuracy: 0.8297\n",
            "Epoch 411/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3396 - accuracy: 0.8449 - val_loss: 0.4829 - val_accuracy: 0.8297\n",
            "Epoch 412/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8435 - val_loss: 0.4865 - val_accuracy: 0.8297\n",
            "Epoch 413/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8449 - val_loss: 0.5014 - val_accuracy: 0.8264\n",
            "Epoch 414/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8428 - val_loss: 0.4777 - val_accuracy: 0.8308\n",
            "Epoch 415/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8445 - val_loss: 0.5070 - val_accuracy: 0.8275\n",
            "Epoch 416/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8438 - val_loss: 0.4875 - val_accuracy: 0.8297\n",
            "Epoch 417/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8433 - val_loss: 0.4881 - val_accuracy: 0.8308\n",
            "Epoch 418/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3394 - accuracy: 0.8436 - val_loss: 0.4917 - val_accuracy: 0.8297\n",
            "Epoch 419/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3388 - accuracy: 0.8447 - val_loss: 0.4800 - val_accuracy: 0.8308\n",
            "Epoch 420/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8451 - val_loss: 0.4868 - val_accuracy: 0.8297\n",
            "Epoch 421/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3392 - accuracy: 0.8440 - val_loss: 0.4848 - val_accuracy: 0.8297\n",
            "Epoch 422/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3390 - accuracy: 0.8444 - val_loss: 0.4698 - val_accuracy: 0.8330\n",
            "Epoch 423/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8451 - val_loss: 0.4903 - val_accuracy: 0.8297\n",
            "Epoch 424/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8453 - val_loss: 0.4915 - val_accuracy: 0.8308\n",
            "Epoch 425/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8447 - val_loss: 0.4803 - val_accuracy: 0.8308\n",
            "Epoch 426/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8454 - val_loss: 0.4996 - val_accuracy: 0.8297\n",
            "Epoch 427/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8442 - val_loss: 0.4677 - val_accuracy: 0.8341\n",
            "Epoch 428/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3392 - accuracy: 0.8453 - val_loss: 0.4780 - val_accuracy: 0.8308\n",
            "Epoch 429/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8445 - val_loss: 0.4819 - val_accuracy: 0.8308\n",
            "Epoch 430/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8440 - val_loss: 0.4920 - val_accuracy: 0.8297\n",
            "Epoch 431/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8445 - val_loss: 0.4849 - val_accuracy: 0.8308\n",
            "Epoch 432/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8451 - val_loss: 0.4814 - val_accuracy: 0.8308\n",
            "Epoch 433/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8445 - val_loss: 0.4773 - val_accuracy: 0.8319\n",
            "Epoch 434/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3385 - accuracy: 0.8440 - val_loss: 0.4826 - val_accuracy: 0.8308\n",
            "Epoch 435/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3386 - accuracy: 0.8442 - val_loss: 0.4735 - val_accuracy: 0.8330\n",
            "Epoch 436/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8456 - val_loss: 0.4749 - val_accuracy: 0.8319\n",
            "Epoch 437/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8444 - val_loss: 0.4805 - val_accuracy: 0.8308\n",
            "Epoch 438/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8462 - val_loss: 0.4981 - val_accuracy: 0.8308\n",
            "Epoch 439/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8449 - val_loss: 0.4750 - val_accuracy: 0.8319\n",
            "Epoch 440/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8447 - val_loss: 0.4840 - val_accuracy: 0.8308\n",
            "Epoch 441/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3391 - accuracy: 0.8435 - val_loss: 0.4593 - val_accuracy: 0.8341\n",
            "Epoch 442/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8449 - val_loss: 0.4946 - val_accuracy: 0.8319\n",
            "Epoch 443/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8444 - val_loss: 0.4772 - val_accuracy: 0.8330\n",
            "Epoch 444/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8435 - val_loss: 0.4742 - val_accuracy: 0.8330\n",
            "Epoch 445/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3386 - accuracy: 0.8449 - val_loss: 0.4936 - val_accuracy: 0.8297\n",
            "Epoch 446/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3384 - accuracy: 0.8447 - val_loss: 0.4826 - val_accuracy: 0.8308\n",
            "Epoch 447/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8447 - val_loss: 0.4870 - val_accuracy: 0.8308\n",
            "Epoch 448/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 0.8445 - val_loss: 0.4760 - val_accuracy: 0.8330\n",
            "Epoch 449/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8447 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 450/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8451 - val_loss: 0.4881 - val_accuracy: 0.8308\n",
            "Epoch 451/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8451 - val_loss: 0.4767 - val_accuracy: 0.8319\n",
            "Epoch 452/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8465 - val_loss: 0.5128 - val_accuracy: 0.8275\n",
            "Epoch 453/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3389 - accuracy: 0.8431 - val_loss: 0.4695 - val_accuracy: 0.8330\n",
            "Epoch 454/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8442 - val_loss: 0.4782 - val_accuracy: 0.8330\n",
            "Epoch 455/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8454 - val_loss: 0.4974 - val_accuracy: 0.8297\n",
            "Epoch 456/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3383 - accuracy: 0.8436 - val_loss: 0.4858 - val_accuracy: 0.8319\n",
            "Epoch 457/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3380 - accuracy: 0.8447 - val_loss: 0.4804 - val_accuracy: 0.8308\n",
            "Epoch 458/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3376 - accuracy: 0.8435 - val_loss: 0.4836 - val_accuracy: 0.8319\n",
            "Epoch 459/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8442 - val_loss: 0.4883 - val_accuracy: 0.8330\n",
            "Epoch 460/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8431 - val_loss: 0.4709 - val_accuracy: 0.8341\n",
            "Epoch 461/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3378 - accuracy: 0.8447 - val_loss: 0.4830 - val_accuracy: 0.8308\n",
            "Epoch 462/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3382 - accuracy: 0.8433 - val_loss: 0.4691 - val_accuracy: 0.8330\n",
            "Epoch 463/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3379 - accuracy: 0.8444 - val_loss: 0.4789 - val_accuracy: 0.8319\n",
            "Epoch 464/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8438 - val_loss: 0.4711 - val_accuracy: 0.8341\n",
            "Epoch 465/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8449 - val_loss: 0.4809 - val_accuracy: 0.8319\n",
            "Epoch 466/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8451 - val_loss: 0.4797 - val_accuracy: 0.8319\n",
            "Epoch 467/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3375 - accuracy: 0.8449 - val_loss: 0.4804 - val_accuracy: 0.8319\n",
            "Epoch 468/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.8444 - val_loss: 0.4772 - val_accuracy: 0.8319\n",
            "Epoch 469/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.8453 - val_loss: 0.4921 - val_accuracy: 0.8330\n",
            "Epoch 470/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8445 - val_loss: 0.4849 - val_accuracy: 0.8319\n",
            "Epoch 471/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8445 - val_loss: 0.4677 - val_accuracy: 0.8341\n",
            "Epoch 472/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8442 - val_loss: 0.4760 - val_accuracy: 0.8341\n",
            "Epoch 473/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8456 - val_loss: 0.4785 - val_accuracy: 0.8341\n",
            "Epoch 474/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8454 - val_loss: 0.4823 - val_accuracy: 0.8308\n",
            "Epoch 475/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3374 - accuracy: 0.8444 - val_loss: 0.4799 - val_accuracy: 0.8319\n",
            "Epoch 476/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8449 - val_loss: 0.4869 - val_accuracy: 0.8319\n",
            "Epoch 477/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8444 - val_loss: 0.4886 - val_accuracy: 0.8330\n",
            "Epoch 478/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8449 - val_loss: 0.4913 - val_accuracy: 0.8319\n",
            "Epoch 479/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8438 - val_loss: 0.4782 - val_accuracy: 0.8330\n",
            "Epoch 480/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8449 - val_loss: 0.4775 - val_accuracy: 0.8319\n",
            "Epoch 481/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3376 - accuracy: 0.8444 - val_loss: 0.4753 - val_accuracy: 0.8352\n",
            "Epoch 482/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8447 - val_loss: 0.4693 - val_accuracy: 0.8330\n",
            "Epoch 483/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8440 - val_loss: 0.4804 - val_accuracy: 0.8330\n",
            "Epoch 484/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3373 - accuracy: 0.8442 - val_loss: 0.4768 - val_accuracy: 0.8341\n",
            "Epoch 485/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8451 - val_loss: 0.4771 - val_accuracy: 0.8341\n",
            "Epoch 486/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8453 - val_loss: 0.5089 - val_accuracy: 0.8286\n",
            "Epoch 487/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8436 - val_loss: 0.4789 - val_accuracy: 0.8341\n",
            "Epoch 488/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8442 - val_loss: 0.4721 - val_accuracy: 0.8352\n",
            "Epoch 489/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8451 - val_loss: 0.4809 - val_accuracy: 0.8319\n",
            "Epoch 490/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3374 - accuracy: 0.8445 - val_loss: 0.4738 - val_accuracy: 0.8341\n",
            "Epoch 491/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8444 - val_loss: 0.4758 - val_accuracy: 0.8341\n",
            "Epoch 492/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3377 - accuracy: 0.8442 - val_loss: 0.4756 - val_accuracy: 0.8352\n",
            "Epoch 493/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8462 - val_loss: 0.4986 - val_accuracy: 0.8319\n",
            "Epoch 494/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3377 - accuracy: 0.8445 - val_loss: 0.4840 - val_accuracy: 0.8308\n",
            "Epoch 495/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3372 - accuracy: 0.8442 - val_loss: 0.4832 - val_accuracy: 0.8319\n",
            "Epoch 496/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8451 - val_loss: 0.4885 - val_accuracy: 0.8319\n",
            "Epoch 497/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8445 - val_loss: 0.4847 - val_accuracy: 0.8308\n",
            "Epoch 498/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8449 - val_loss: 0.4800 - val_accuracy: 0.8341\n",
            "Epoch 499/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3372 - accuracy: 0.8440 - val_loss: 0.4690 - val_accuracy: 0.8341\n",
            "Epoch 500/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8454 - val_loss: 0.4908 - val_accuracy: 0.8319\n",
            "Epoch 501/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3372 - accuracy: 0.8442 - val_loss: 0.4836 - val_accuracy: 0.8319\n",
            "Epoch 502/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8449 - val_loss: 0.4857 - val_accuracy: 0.8319\n",
            "Epoch 503/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.8438 - val_loss: 0.4823 - val_accuracy: 0.8341\n",
            "Epoch 504/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8453 - val_loss: 0.4930 - val_accuracy: 0.8330\n",
            "Epoch 505/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8456 - val_loss: 0.4941 - val_accuracy: 0.8330\n",
            "Epoch 506/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3373 - accuracy: 0.8445 - val_loss: 0.4794 - val_accuracy: 0.8352\n",
            "Epoch 507/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8431 - val_loss: 0.4690 - val_accuracy: 0.8341\n",
            "Epoch 508/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8449 - val_loss: 0.4923 - val_accuracy: 0.8330\n",
            "Epoch 509/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3367 - accuracy: 0.8445 - val_loss: 0.4837 - val_accuracy: 0.8330\n",
            "Epoch 510/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8445 - val_loss: 0.4788 - val_accuracy: 0.8319\n",
            "Epoch 511/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3374 - accuracy: 0.8445 - val_loss: 0.4638 - val_accuracy: 0.8341\n",
            "Epoch 512/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3379 - accuracy: 0.8442 - val_loss: 0.4699 - val_accuracy: 0.8341\n",
            "Epoch 513/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8449 - val_loss: 0.4873 - val_accuracy: 0.8319\n",
            "Epoch 514/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8453 - val_loss: 0.4860 - val_accuracy: 0.8330\n",
            "Epoch 515/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8442 - val_loss: 0.4798 - val_accuracy: 0.8341\n",
            "Epoch 516/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8444 - val_loss: 0.4794 - val_accuracy: 0.8341\n",
            "Epoch 517/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8436 - val_loss: 0.4813 - val_accuracy: 0.8352\n",
            "Epoch 518/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8444 - val_loss: 0.4848 - val_accuracy: 0.8319\n",
            "Epoch 519/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8454 - val_loss: 0.4791 - val_accuracy: 0.8341\n",
            "Epoch 520/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8447 - val_loss: 0.4706 - val_accuracy: 0.8341\n",
            "Epoch 521/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3371 - accuracy: 0.8453 - val_loss: 0.4707 - val_accuracy: 0.8341\n",
            "Epoch 522/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8444 - val_loss: 0.4706 - val_accuracy: 0.8341\n",
            "Epoch 523/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8449 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 524/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8447 - val_loss: 0.4835 - val_accuracy: 0.8330\n",
            "Epoch 525/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8445 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 526/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8447 - val_loss: 0.4815 - val_accuracy: 0.8330\n",
            "Epoch 527/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8444 - val_loss: 0.4685 - val_accuracy: 0.8352\n",
            "Epoch 528/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8460 - val_loss: 0.4901 - val_accuracy: 0.8330\n",
            "Epoch 529/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8444 - val_loss: 0.4746 - val_accuracy: 0.8341\n",
            "Epoch 530/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8454 - val_loss: 0.5096 - val_accuracy: 0.8297\n",
            "Epoch 531/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3375 - accuracy: 0.8438 - val_loss: 0.4702 - val_accuracy: 0.8341\n",
            "Epoch 532/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3368 - accuracy: 0.8435 - val_loss: 0.4815 - val_accuracy: 0.8330\n",
            "Epoch 533/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8445 - val_loss: 0.4853 - val_accuracy: 0.8330\n",
            "Epoch 534/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8444 - val_loss: 0.4835 - val_accuracy: 0.8330\n",
            "Epoch 535/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8426 - val_loss: 0.4617 - val_accuracy: 0.8363\n",
            "Epoch 536/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8453 - val_loss: 0.4898 - val_accuracy: 0.8319\n",
            "Epoch 537/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8449 - val_loss: 0.4855 - val_accuracy: 0.8319\n",
            "Epoch 538/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8433 - val_loss: 0.4703 - val_accuracy: 0.8352\n",
            "Epoch 539/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8447 - val_loss: 0.4709 - val_accuracy: 0.8363\n",
            "Epoch 540/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8451 - val_loss: 0.4879 - val_accuracy: 0.8319\n",
            "Epoch 541/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8445 - val_loss: 0.4870 - val_accuracy: 0.8319\n",
            "Epoch 542/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8442 - val_loss: 0.4771 - val_accuracy: 0.8341\n",
            "Epoch 543/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8451 - val_loss: 0.4919 - val_accuracy: 0.8330\n",
            "Epoch 544/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8449 - val_loss: 0.4768 - val_accuracy: 0.8341\n",
            "Epoch 545/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8444 - val_loss: 0.4787 - val_accuracy: 0.8341\n",
            "Epoch 546/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8442 - val_loss: 0.4816 - val_accuracy: 0.8341\n",
            "Epoch 547/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8445 - val_loss: 0.4851 - val_accuracy: 0.8319\n",
            "Epoch 548/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8445 - val_loss: 0.4784 - val_accuracy: 0.8352\n",
            "Epoch 549/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8458 - val_loss: 0.4879 - val_accuracy: 0.8330\n",
            "Epoch 550/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8456 - val_loss: 0.4886 - val_accuracy: 0.8330\n",
            "Epoch 551/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8449 - val_loss: 0.5006 - val_accuracy: 0.8319\n",
            "Epoch 552/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8444 - val_loss: 0.4692 - val_accuracy: 0.8363\n",
            "Epoch 553/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8454 - val_loss: 0.4808 - val_accuracy: 0.8341\n",
            "Epoch 554/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8444 - val_loss: 0.4834 - val_accuracy: 0.8341\n",
            "Epoch 555/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8453 - val_loss: 0.4950 - val_accuracy: 0.8330\n",
            "Epoch 556/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8436 - val_loss: 0.4759 - val_accuracy: 0.8352\n",
            "Epoch 557/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8454 - val_loss: 0.4907 - val_accuracy: 0.8319\n",
            "Epoch 558/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8453 - val_loss: 0.4854 - val_accuracy: 0.8319\n",
            "Epoch 559/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8447 - val_loss: 0.4837 - val_accuracy: 0.8341\n",
            "Epoch 560/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8447 - val_loss: 0.4797 - val_accuracy: 0.8330\n",
            "Epoch 561/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8454 - val_loss: 0.4845 - val_accuracy: 0.8341\n",
            "Epoch 562/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3361 - accuracy: 0.8454 - val_loss: 0.4857 - val_accuracy: 0.8341\n",
            "Epoch 563/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8436 - val_loss: 0.4819 - val_accuracy: 0.8341\n",
            "Epoch 564/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8447 - val_loss: 0.4866 - val_accuracy: 0.8330\n",
            "Epoch 565/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 0.8447 - val_loss: 0.4834 - val_accuracy: 0.8352\n",
            "Epoch 566/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8445 - val_loss: 0.4769 - val_accuracy: 0.8352\n",
            "Epoch 567/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8438 - val_loss: 0.4772 - val_accuracy: 0.8352\n",
            "Epoch 568/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3359 - accuracy: 0.8462 - val_loss: 0.4958 - val_accuracy: 0.8330\n",
            "Epoch 569/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8465 - val_loss: 0.4794 - val_accuracy: 0.8352\n",
            "Epoch 570/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3362 - accuracy: 0.8438 - val_loss: 0.4760 - val_accuracy: 0.8352\n",
            "Epoch 571/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8445 - val_loss: 0.4860 - val_accuracy: 0.8330\n",
            "Epoch 572/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8451 - val_loss: 0.5047 - val_accuracy: 0.8330\n",
            "Epoch 573/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.8454 - val_loss: 0.4789 - val_accuracy: 0.8352\n",
            "Epoch 574/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8442 - val_loss: 0.4762 - val_accuracy: 0.8352\n",
            "Epoch 575/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8444 - val_loss: 0.4673 - val_accuracy: 0.8363\n",
            "Epoch 576/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3359 - accuracy: 0.8454 - val_loss: 0.4939 - val_accuracy: 0.8330\n",
            "Epoch 577/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8438 - val_loss: 0.5007 - val_accuracy: 0.8341\n",
            "Epoch 578/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8444 - val_loss: 0.4857 - val_accuracy: 0.8330\n",
            "Epoch 579/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8453 - val_loss: 0.4702 - val_accuracy: 0.8363\n",
            "Epoch 580/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3357 - accuracy: 0.8444 - val_loss: 0.4753 - val_accuracy: 0.8352\n",
            "Epoch 581/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.8460 - val_loss: 0.4931 - val_accuracy: 0.8330\n",
            "Epoch 582/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3356 - accuracy: 0.8451 - val_loss: 0.4845 - val_accuracy: 0.8341\n",
            "Epoch 583/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3359 - accuracy: 0.8447 - val_loss: 0.4784 - val_accuracy: 0.8352\n",
            "Epoch 584/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8447 - val_loss: 0.4773 - val_accuracy: 0.8352\n",
            "Epoch 585/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3356 - accuracy: 0.8451 - val_loss: 0.4810 - val_accuracy: 0.8341\n",
            "Epoch 586/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3363 - accuracy: 0.8447 - val_loss: 0.4778 - val_accuracy: 0.8352\n",
            "Epoch 587/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8451 - val_loss: 0.4887 - val_accuracy: 0.8330\n",
            "Epoch 588/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8444 - val_loss: 0.4938 - val_accuracy: 0.8330\n",
            "Epoch 589/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8440 - val_loss: 0.4631 - val_accuracy: 0.8352\n",
            "Epoch 590/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8462 - val_loss: 0.4876 - val_accuracy: 0.8341\n",
            "Epoch 591/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8445 - val_loss: 0.4831 - val_accuracy: 0.8341\n",
            "Epoch 592/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8444 - val_loss: 0.4825 - val_accuracy: 0.8341\n",
            "Epoch 593/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8449 - val_loss: 0.4852 - val_accuracy: 0.8319\n",
            "Epoch 594/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8447 - val_loss: 0.4759 - val_accuracy: 0.8352\n",
            "Epoch 595/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8440 - val_loss: 0.4773 - val_accuracy: 0.8341\n",
            "Epoch 596/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8451 - val_loss: 0.4787 - val_accuracy: 0.8352\n",
            "Epoch 597/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3353 - accuracy: 0.8451 - val_loss: 0.4853 - val_accuracy: 0.8330\n",
            "Epoch 598/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8442 - val_loss: 0.4721 - val_accuracy: 0.8352\n",
            "Epoch 599/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8445 - val_loss: 0.4771 - val_accuracy: 0.8352\n",
            "Epoch 600/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8445 - val_loss: 0.4859 - val_accuracy: 0.8330\n",
            "Epoch 601/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8449 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 602/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8449 - val_loss: 0.4829 - val_accuracy: 0.8330\n",
            "Epoch 603/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8440 - val_loss: 0.4774 - val_accuracy: 0.8352\n",
            "Epoch 604/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8447 - val_loss: 0.4889 - val_accuracy: 0.8330\n",
            "Epoch 605/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8451 - val_loss: 0.4894 - val_accuracy: 0.8319\n",
            "Epoch 606/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8449 - val_loss: 0.4844 - val_accuracy: 0.8330\n",
            "Epoch 607/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8436 - val_loss: 0.4696 - val_accuracy: 0.8352\n",
            "Epoch 608/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8447 - val_loss: 0.4866 - val_accuracy: 0.8341\n",
            "Epoch 609/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8442 - val_loss: 0.4788 - val_accuracy: 0.8352\n",
            "Epoch 610/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8444 - val_loss: 0.4764 - val_accuracy: 0.8352\n",
            "Epoch 611/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8462 - val_loss: 0.4744 - val_accuracy: 0.8363\n",
            "Epoch 612/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3365 - accuracy: 0.8440 - val_loss: 0.4611 - val_accuracy: 0.8352\n",
            "Epoch 613/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3355 - accuracy: 0.8438 - val_loss: 0.4789 - val_accuracy: 0.8352\n",
            "Epoch 614/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8447 - val_loss: 0.4762 - val_accuracy: 0.8341\n",
            "Epoch 615/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8462 - val_loss: 0.5001 - val_accuracy: 0.8330\n",
            "Epoch 616/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8442 - val_loss: 0.4817 - val_accuracy: 0.8341\n",
            "Epoch 617/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8447 - val_loss: 0.4867 - val_accuracy: 0.8330\n",
            "Epoch 618/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8454 - val_loss: 0.4839 - val_accuracy: 0.8330\n",
            "Epoch 619/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8442 - val_loss: 0.4729 - val_accuracy: 0.8352\n",
            "Epoch 620/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8454 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 621/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8453 - val_loss: 0.5035 - val_accuracy: 0.8319\n",
            "Epoch 622/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3362 - accuracy: 0.8456 - val_loss: 0.4816 - val_accuracy: 0.8352\n",
            "Epoch 623/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8444 - val_loss: 0.4806 - val_accuracy: 0.8330\n",
            "Epoch 624/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3363 - accuracy: 0.8440 - val_loss: 0.4644 - val_accuracy: 0.8363\n",
            "Epoch 625/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8453 - val_loss: 0.4953 - val_accuracy: 0.8330\n",
            "Epoch 626/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8440 - val_loss: 0.4837 - val_accuracy: 0.8341\n",
            "Epoch 627/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.8458 - val_loss: 0.4750 - val_accuracy: 0.8363\n",
            "Epoch 628/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8442 - val_loss: 0.4728 - val_accuracy: 0.8352\n",
            "Epoch 629/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8449 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 630/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8451 - val_loss: 0.4910 - val_accuracy: 0.8319\n",
            "Epoch 631/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8444 - val_loss: 0.4979 - val_accuracy: 0.8330\n",
            "Epoch 632/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8444 - val_loss: 0.4794 - val_accuracy: 0.8330\n",
            "Epoch 633/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8447 - val_loss: 0.4721 - val_accuracy: 0.8352\n",
            "Epoch 634/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3352 - accuracy: 0.8444 - val_loss: 0.4716 - val_accuracy: 0.8352\n",
            "Epoch 635/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8449 - val_loss: 0.4883 - val_accuracy: 0.8330\n",
            "Epoch 636/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8442 - val_loss: 0.4961 - val_accuracy: 0.8341\n",
            "Epoch 637/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8447 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 638/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8442 - val_loss: 0.4705 - val_accuracy: 0.8363\n",
            "Epoch 639/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3366 - accuracy: 0.8436 - val_loss: 0.4677 - val_accuracy: 0.8352\n",
            "Epoch 640/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8456 - val_loss: 0.4825 - val_accuracy: 0.8330\n",
            "Epoch 641/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8445 - val_loss: 0.4811 - val_accuracy: 0.8341\n",
            "Epoch 642/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3348 - accuracy: 0.8458 - val_loss: 0.4878 - val_accuracy: 0.8330\n",
            "Epoch 643/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8451 - val_loss: 0.4813 - val_accuracy: 0.8341\n",
            "Epoch 644/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8447 - val_loss: 0.4815 - val_accuracy: 0.8330\n",
            "Epoch 645/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3349 - accuracy: 0.8440 - val_loss: 0.4772 - val_accuracy: 0.8341\n",
            "Epoch 646/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3354 - accuracy: 0.8463 - val_loss: 0.5082 - val_accuracy: 0.8297\n",
            "Epoch 647/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3357 - accuracy: 0.8456 - val_loss: 0.4868 - val_accuracy: 0.8330\n",
            "Epoch 648/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8444 - val_loss: 0.4724 - val_accuracy: 0.8352\n",
            "Epoch 649/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3352 - accuracy: 0.8451 - val_loss: 0.4740 - val_accuracy: 0.8374\n",
            "Epoch 650/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8451 - val_loss: 0.4829 - val_accuracy: 0.8330\n",
            "Epoch 651/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8449 - val_loss: 0.4879 - val_accuracy: 0.8330\n",
            "Epoch 652/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8445 - val_loss: 0.4785 - val_accuracy: 0.8352\n",
            "Epoch 653/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8447 - val_loss: 0.4888 - val_accuracy: 0.8330\n",
            "Epoch 654/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8456 - val_loss: 0.4980 - val_accuracy: 0.8319\n",
            "Epoch 655/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8447 - val_loss: 0.4843 - val_accuracy: 0.8330\n",
            "Epoch 656/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3347 - accuracy: 0.8447 - val_loss: 0.4897 - val_accuracy: 0.8319\n",
            "Epoch 657/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8451 - val_loss: 0.4770 - val_accuracy: 0.8363\n",
            "Epoch 658/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8453 - val_loss: 0.4972 - val_accuracy: 0.8330\n",
            "Epoch 659/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8458 - val_loss: 0.4788 - val_accuracy: 0.8352\n",
            "Epoch 660/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8449 - val_loss: 0.4814 - val_accuracy: 0.8352\n",
            "Epoch 661/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8462 - val_loss: 0.4959 - val_accuracy: 0.8319\n",
            "Epoch 662/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8433 - val_loss: 0.4704 - val_accuracy: 0.8363\n",
            "Epoch 663/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8445 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 664/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8447 - val_loss: 0.4836 - val_accuracy: 0.8330\n",
            "Epoch 665/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.8451 - val_loss: 0.4788 - val_accuracy: 0.8352\n",
            "Epoch 666/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3350 - accuracy: 0.8440 - val_loss: 0.4762 - val_accuracy: 0.8352\n",
            "Epoch 667/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3344 - accuracy: 0.8462 - val_loss: 0.4874 - val_accuracy: 0.8330\n",
            "Epoch 668/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8456 - val_loss: 0.5053 - val_accuracy: 0.8330\n",
            "Epoch 669/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3354 - accuracy: 0.8445 - val_loss: 0.4851 - val_accuracy: 0.8330\n",
            "Epoch 670/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3342 - accuracy: 0.8436 - val_loss: 0.4659 - val_accuracy: 0.8363\n",
            "Epoch 671/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3347 - accuracy: 0.8462 - val_loss: 0.4913 - val_accuracy: 0.8330\n",
            "Epoch 672/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8454 - val_loss: 0.4800 - val_accuracy: 0.8341\n",
            "Epoch 673/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8449 - val_loss: 0.4789 - val_accuracy: 0.8341\n",
            "Epoch 674/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8438 - val_loss: 0.4649 - val_accuracy: 0.8374\n",
            "Epoch 675/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3345 - accuracy: 0.8453 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 676/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8451 - val_loss: 0.4784 - val_accuracy: 0.8330\n",
            "Epoch 677/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3348 - accuracy: 0.8454 - val_loss: 0.4833 - val_accuracy: 0.8330\n",
            "Epoch 678/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8435 - val_loss: 0.4675 - val_accuracy: 0.8352\n",
            "Epoch 679/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3350 - accuracy: 0.8456 - val_loss: 0.4838 - val_accuracy: 0.8330\n",
            "Epoch 680/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8460 - val_loss: 0.5004 - val_accuracy: 0.8341\n",
            "Epoch 681/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.8438 - val_loss: 0.4691 - val_accuracy: 0.8352\n",
            "Epoch 682/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8454 - val_loss: 0.4847 - val_accuracy: 0.8341\n",
            "Epoch 683/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8444 - val_loss: 0.4764 - val_accuracy: 0.8341\n",
            "Epoch 684/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8447 - val_loss: 0.4797 - val_accuracy: 0.8330\n",
            "Epoch 685/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8449 - val_loss: 0.4779 - val_accuracy: 0.8330\n",
            "Epoch 686/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3348 - accuracy: 0.8460 - val_loss: 0.4760 - val_accuracy: 0.8374\n",
            "Epoch 687/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8449 - val_loss: 0.4799 - val_accuracy: 0.8330\n",
            "Epoch 688/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8444 - val_loss: 0.4682 - val_accuracy: 0.8341\n",
            "Epoch 689/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.8460 - val_loss: 0.4824 - val_accuracy: 0.8352\n",
            "Epoch 690/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8460 - val_loss: 0.5018 - val_accuracy: 0.8330\n",
            "Epoch 691/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8440 - val_loss: 0.4785 - val_accuracy: 0.8330\n",
            "Epoch 692/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8445 - val_loss: 0.4776 - val_accuracy: 0.8352\n",
            "Epoch 693/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8447 - val_loss: 0.4771 - val_accuracy: 0.8352\n",
            "Epoch 694/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8456 - val_loss: 0.4925 - val_accuracy: 0.8330\n",
            "Epoch 695/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8451 - val_loss: 0.4771 - val_accuracy: 0.8341\n",
            "Epoch 696/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8445 - val_loss: 0.4752 - val_accuracy: 0.8341\n",
            "Epoch 697/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8460 - val_loss: 0.4789 - val_accuracy: 0.8352\n",
            "Epoch 698/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8454 - val_loss: 0.4791 - val_accuracy: 0.8330\n",
            "Epoch 699/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8449 - val_loss: 0.4861 - val_accuracy: 0.8319\n",
            "Epoch 700/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8456 - val_loss: 0.4850 - val_accuracy: 0.8330\n",
            "Epoch 701/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3343 - accuracy: 0.8453 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 702/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8453 - val_loss: 0.4637 - val_accuracy: 0.8374\n",
            "Epoch 703/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8447 - val_loss: 0.4989 - val_accuracy: 0.8330\n",
            "Epoch 704/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8454 - val_loss: 0.4838 - val_accuracy: 0.8330\n",
            "Epoch 705/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8447 - val_loss: 0.4786 - val_accuracy: 0.8319\n",
            "Epoch 706/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8453 - val_loss: 0.4834 - val_accuracy: 0.8352\n",
            "Epoch 707/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8453 - val_loss: 0.4707 - val_accuracy: 0.8352\n",
            "Epoch 708/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8453 - val_loss: 0.4710 - val_accuracy: 0.8352\n",
            "Epoch 709/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8445 - val_loss: 0.4754 - val_accuracy: 0.8341\n",
            "Epoch 710/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8451 - val_loss: 0.4840 - val_accuracy: 0.8319\n",
            "Epoch 711/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8447 - val_loss: 0.4931 - val_accuracy: 0.8319\n",
            "Epoch 712/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8456 - val_loss: 0.4744 - val_accuracy: 0.8330\n",
            "Epoch 713/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8447 - val_loss: 0.4672 - val_accuracy: 0.8374\n",
            "Epoch 714/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3343 - accuracy: 0.8451 - val_loss: 0.4829 - val_accuracy: 0.8330\n",
            "Epoch 715/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8453 - val_loss: 0.4842 - val_accuracy: 0.8319\n",
            "Epoch 716/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8447 - val_loss: 0.4755 - val_accuracy: 0.8341\n",
            "Epoch 717/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8453 - val_loss: 0.4803 - val_accuracy: 0.8319\n",
            "Epoch 718/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3336 - accuracy: 0.8449 - val_loss: 0.4771 - val_accuracy: 0.8341\n",
            "Epoch 719/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3346 - accuracy: 0.8438 - val_loss: 0.4698 - val_accuracy: 0.8352\n",
            "Epoch 720/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8465 - val_loss: 0.4905 - val_accuracy: 0.8319\n",
            "Epoch 721/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8445 - val_loss: 0.4705 - val_accuracy: 0.8374\n",
            "Epoch 722/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8456 - val_loss: 0.4890 - val_accuracy: 0.8319\n",
            "Epoch 723/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8456 - val_loss: 0.4814 - val_accuracy: 0.8330\n",
            "Epoch 724/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.8456 - val_loss: 0.4779 - val_accuracy: 0.8363\n",
            "Epoch 725/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8444 - val_loss: 0.4777 - val_accuracy: 0.8330\n",
            "Epoch 726/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3338 - accuracy: 0.8460 - val_loss: 0.4792 - val_accuracy: 0.8341\n",
            "Epoch 727/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.4856 - val_accuracy: 0.8319\n",
            "Epoch 728/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8447 - val_loss: 0.4751 - val_accuracy: 0.8330\n",
            "Epoch 729/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3347 - accuracy: 0.8445 - val_loss: 0.4653 - val_accuracy: 0.8374\n",
            "Epoch 730/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8451 - val_loss: 0.4914 - val_accuracy: 0.8319\n",
            "Epoch 731/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3341 - accuracy: 0.8447 - val_loss: 0.4975 - val_accuracy: 0.8308\n",
            "Epoch 732/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3343 - accuracy: 0.8453 - val_loss: 0.4922 - val_accuracy: 0.8319\n",
            "Epoch 733/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8454 - val_loss: 0.4864 - val_accuracy: 0.8319\n",
            "Epoch 734/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8449 - val_loss: 0.4778 - val_accuracy: 0.8330\n",
            "Epoch 735/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3334 - accuracy: 0.8453 - val_loss: 0.4819 - val_accuracy: 0.8330\n",
            "Epoch 736/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8451 - val_loss: 0.4800 - val_accuracy: 0.8319\n",
            "Epoch 737/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8449 - val_loss: 0.4794 - val_accuracy: 0.8319\n",
            "Epoch 738/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8445 - val_loss: 0.4747 - val_accuracy: 0.8330\n",
            "Epoch 739/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8453 - val_loss: 0.4917 - val_accuracy: 0.8319\n",
            "Epoch 740/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3337 - accuracy: 0.8451 - val_loss: 0.4899 - val_accuracy: 0.8319\n",
            "Epoch 741/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8462 - val_loss: 0.4620 - val_accuracy: 0.8363\n",
            "Epoch 742/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8460 - val_loss: 0.4878 - val_accuracy: 0.8319\n",
            "Epoch 743/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8463 - val_loss: 0.4962 - val_accuracy: 0.8308\n",
            "Epoch 744/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8449 - val_loss: 0.4825 - val_accuracy: 0.8319\n",
            "Epoch 745/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8454 - val_loss: 0.4726 - val_accuracy: 0.8341\n",
            "Epoch 746/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8456 - val_loss: 0.4726 - val_accuracy: 0.8330\n",
            "Epoch 747/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3340 - accuracy: 0.8454 - val_loss: 0.4935 - val_accuracy: 0.8319\n",
            "Epoch 748/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3344 - accuracy: 0.8442 - val_loss: 0.4887 - val_accuracy: 0.8319\n",
            "Epoch 749/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8454 - val_loss: 0.4953 - val_accuracy: 0.8319\n",
            "Epoch 750/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3331 - accuracy: 0.8451 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 751/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.4840 - val_accuracy: 0.8330\n",
            "Epoch 752/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.4926 - val_accuracy: 0.8319\n",
            "Epoch 753/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3335 - accuracy: 0.8453 - val_loss: 0.4846 - val_accuracy: 0.8319\n",
            "Epoch 754/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3337 - accuracy: 0.8445 - val_loss: 0.4677 - val_accuracy: 0.8352\n",
            "Epoch 755/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8451 - val_loss: 0.4998 - val_accuracy: 0.8319\n",
            "Epoch 756/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8444 - val_loss: 0.4785 - val_accuracy: 0.8330\n",
            "Epoch 757/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8449 - val_loss: 0.4959 - val_accuracy: 0.8319\n",
            "Epoch 758/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3331 - accuracy: 0.8456 - val_loss: 0.4752 - val_accuracy: 0.8341\n",
            "Epoch 759/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8458 - val_loss: 0.4916 - val_accuracy: 0.8319\n",
            "Epoch 760/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8469 - val_loss: 0.5035 - val_accuracy: 0.8308\n",
            "Epoch 761/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3339 - accuracy: 0.8444 - val_loss: 0.4842 - val_accuracy: 0.8319\n",
            "Epoch 762/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8458 - val_loss: 0.4914 - val_accuracy: 0.8319\n",
            "Epoch 763/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8451 - val_loss: 0.4794 - val_accuracy: 0.8319\n",
            "Epoch 764/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8451 - val_loss: 0.4756 - val_accuracy: 0.8330\n",
            "Epoch 765/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8447 - val_loss: 0.4793 - val_accuracy: 0.8330\n",
            "Epoch 766/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8460 - val_loss: 0.4892 - val_accuracy: 0.8319\n",
            "Epoch 767/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8447 - val_loss: 0.4773 - val_accuracy: 0.8330\n",
            "Epoch 768/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8451 - val_loss: 0.4835 - val_accuracy: 0.8319\n",
            "Epoch 769/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8454 - val_loss: 0.4781 - val_accuracy: 0.8330\n",
            "Epoch 770/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.8453 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 771/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8458 - val_loss: 0.4848 - val_accuracy: 0.8319\n",
            "Epoch 772/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3330 - accuracy: 0.8449 - val_loss: 0.4794 - val_accuracy: 0.8330\n",
            "Epoch 773/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.8460 - val_loss: 0.4813 - val_accuracy: 0.8330\n",
            "Epoch 774/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8453 - val_loss: 0.4803 - val_accuracy: 0.8330\n",
            "Epoch 775/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8451 - val_loss: 0.4679 - val_accuracy: 0.8352\n",
            "Epoch 776/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8462 - val_loss: 0.5008 - val_accuracy: 0.8319\n",
            "Epoch 777/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8456 - val_loss: 0.4715 - val_accuracy: 0.8341\n",
            "Epoch 778/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8456 - val_loss: 0.4960 - val_accuracy: 0.8319\n",
            "Epoch 779/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8462 - val_loss: 0.4848 - val_accuracy: 0.8330\n",
            "Epoch 780/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3329 - accuracy: 0.8451 - val_loss: 0.4762 - val_accuracy: 0.8330\n",
            "Epoch 781/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8456 - val_loss: 0.4844 - val_accuracy: 0.8330\n",
            "Epoch 782/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8467 - val_loss: 0.4894 - val_accuracy: 0.8319\n",
            "Epoch 783/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8456 - val_loss: 0.4841 - val_accuracy: 0.8330\n",
            "Epoch 784/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8449 - val_loss: 0.4850 - val_accuracy: 0.8330\n",
            "Epoch 785/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3327 - accuracy: 0.8456 - val_loss: 0.4827 - val_accuracy: 0.8319\n",
            "Epoch 786/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8453 - val_loss: 0.4843 - val_accuracy: 0.8330\n",
            "Epoch 787/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8460 - val_loss: 0.4740 - val_accuracy: 0.8341\n",
            "Epoch 788/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3336 - accuracy: 0.8456 - val_loss: 0.4924 - val_accuracy: 0.8330\n",
            "Epoch 789/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8476 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 790/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8456 - val_loss: 0.4837 - val_accuracy: 0.8319\n",
            "Epoch 791/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8453 - val_loss: 0.4685 - val_accuracy: 0.8352\n",
            "Epoch 792/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8463 - val_loss: 0.4716 - val_accuracy: 0.8341\n",
            "Epoch 793/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8453 - val_loss: 0.4893 - val_accuracy: 0.8319\n",
            "Epoch 794/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8451 - val_loss: 0.4845 - val_accuracy: 0.8330\n",
            "Epoch 795/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8456 - val_loss: 0.4873 - val_accuracy: 0.8330\n",
            "Epoch 796/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8462 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 797/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.8465 - val_loss: 0.4769 - val_accuracy: 0.8330\n",
            "Epoch 798/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8451 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 799/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8456 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 800/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8476 - val_loss: 0.5041 - val_accuracy: 0.8319\n",
            "Epoch 801/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3340 - accuracy: 0.8451 - val_loss: 0.4653 - val_accuracy: 0.8352\n",
            "Epoch 802/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8456 - val_loss: 0.4844 - val_accuracy: 0.8330\n",
            "Epoch 803/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8458 - val_loss: 0.4860 - val_accuracy: 0.8330\n",
            "Epoch 804/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8458 - val_loss: 0.4931 - val_accuracy: 0.8319\n",
            "Epoch 805/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8462 - val_loss: 0.4767 - val_accuracy: 0.8341\n",
            "Epoch 806/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8458 - val_loss: 0.4868 - val_accuracy: 0.8330\n",
            "Epoch 807/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8460 - val_loss: 0.4952 - val_accuracy: 0.8319\n",
            "Epoch 808/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8454 - val_loss: 0.4670 - val_accuracy: 0.8341\n",
            "Epoch 809/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8470 - val_loss: 0.4949 - val_accuracy: 0.8319\n",
            "Epoch 810/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8453 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 811/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8453 - val_loss: 0.4740 - val_accuracy: 0.8341\n",
            "Epoch 812/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3324 - accuracy: 0.8465 - val_loss: 0.4865 - val_accuracy: 0.8330\n",
            "Epoch 813/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8454 - val_loss: 0.4895 - val_accuracy: 0.8319\n",
            "Epoch 814/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8453 - val_loss: 0.4810 - val_accuracy: 0.8330\n",
            "Epoch 815/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8453 - val_loss: 0.4787 - val_accuracy: 0.8330\n",
            "Epoch 816/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8479 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 817/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3328 - accuracy: 0.8445 - val_loss: 0.4793 - val_accuracy: 0.8330\n",
            "Epoch 818/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8463 - val_loss: 0.4813 - val_accuracy: 0.8330\n",
            "Epoch 819/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8463 - val_loss: 0.5041 - val_accuracy: 0.8319\n",
            "Epoch 820/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8463 - val_loss: 0.4899 - val_accuracy: 0.8330\n",
            "Epoch 821/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8463 - val_loss: 0.4773 - val_accuracy: 0.8330\n",
            "Epoch 822/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3330 - accuracy: 0.8442 - val_loss: 0.4682 - val_accuracy: 0.8341\n",
            "Epoch 823/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8469 - val_loss: 0.4988 - val_accuracy: 0.8319\n",
            "Epoch 824/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8460 - val_loss: 0.4851 - val_accuracy: 0.8330\n",
            "Epoch 825/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8462 - val_loss: 0.4795 - val_accuracy: 0.8330\n",
            "Epoch 826/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8458 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 827/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3328 - accuracy: 0.8458 - val_loss: 0.4996 - val_accuracy: 0.8319\n",
            "Epoch 828/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8465 - val_loss: 0.4800 - val_accuracy: 0.8330\n",
            "Epoch 829/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8454 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 830/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8454 - val_loss: 0.4635 - val_accuracy: 0.8341\n",
            "Epoch 831/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8465 - val_loss: 0.4913 - val_accuracy: 0.8319\n",
            "Epoch 832/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8458 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 833/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8454 - val_loss: 0.4807 - val_accuracy: 0.8330\n",
            "Epoch 834/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8463 - val_loss: 0.5027 - val_accuracy: 0.8319\n",
            "Epoch 835/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8458 - val_loss: 0.4835 - val_accuracy: 0.8330\n",
            "Epoch 836/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8458 - val_loss: 0.4832 - val_accuracy: 0.8330\n",
            "Epoch 837/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3323 - accuracy: 0.8458 - val_loss: 0.4861 - val_accuracy: 0.8330\n",
            "Epoch 838/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8458 - val_loss: 0.4776 - val_accuracy: 0.8341\n",
            "Epoch 839/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8465 - val_loss: 0.5005 - val_accuracy: 0.8319\n",
            "Epoch 840/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8460 - val_loss: 0.4672 - val_accuracy: 0.8341\n",
            "Epoch 841/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8453 - val_loss: 0.4886 - val_accuracy: 0.8330\n",
            "Epoch 842/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.8467 - val_loss: 0.4961 - val_accuracy: 0.8330\n",
            "Epoch 843/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8454 - val_loss: 0.4801 - val_accuracy: 0.8330\n",
            "Epoch 844/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3332 - accuracy: 0.8453 - val_loss: 0.4613 - val_accuracy: 0.8341\n",
            "Epoch 845/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8469 - val_loss: 0.4925 - val_accuracy: 0.8330\n",
            "Epoch 846/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8462 - val_loss: 0.4776 - val_accuracy: 0.8330\n",
            "Epoch 847/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3322 - accuracy: 0.8472 - val_loss: 0.4952 - val_accuracy: 0.8330\n",
            "Epoch 848/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3322 - accuracy: 0.8465 - val_loss: 0.4951 - val_accuracy: 0.8330\n",
            "Epoch 849/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8454 - val_loss: 0.4991 - val_accuracy: 0.8319\n",
            "Epoch 850/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3323 - accuracy: 0.8458 - val_loss: 0.4761 - val_accuracy: 0.8341\n",
            "Epoch 851/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8470 - val_loss: 0.4951 - val_accuracy: 0.8308\n",
            "Epoch 852/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8458 - val_loss: 0.4812 - val_accuracy: 0.8330\n",
            "Epoch 853/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8460 - val_loss: 0.4889 - val_accuracy: 0.8330\n",
            "Epoch 854/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8453 - val_loss: 0.4719 - val_accuracy: 0.8341\n",
            "Epoch 855/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8456 - val_loss: 0.4781 - val_accuracy: 0.8330\n",
            "Epoch 856/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8485 - val_loss: 0.5033 - val_accuracy: 0.8330\n",
            "Epoch 857/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3336 - accuracy: 0.8465 - val_loss: 0.5024 - val_accuracy: 0.8319\n",
            "Epoch 858/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3327 - accuracy: 0.8453 - val_loss: 0.4814 - val_accuracy: 0.8330\n",
            "Epoch 859/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3320 - accuracy: 0.8469 - val_loss: 0.4720 - val_accuracy: 0.8330\n",
            "Epoch 860/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8453 - val_loss: 0.4698 - val_accuracy: 0.8341\n",
            "Epoch 861/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8463 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 862/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8458 - val_loss: 0.4822 - val_accuracy: 0.8330\n",
            "Epoch 863/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8470 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 864/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8458 - val_loss: 0.5011 - val_accuracy: 0.8330\n",
            "Epoch 865/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3326 - accuracy: 0.8469 - val_loss: 0.4895 - val_accuracy: 0.8330\n",
            "Epoch 866/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8458 - val_loss: 0.4890 - val_accuracy: 0.8330\n",
            "Epoch 867/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8465 - val_loss: 0.4881 - val_accuracy: 0.8330\n",
            "Epoch 868/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8447 - val_loss: 0.4755 - val_accuracy: 0.8341\n",
            "Epoch 869/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8454 - val_loss: 0.4831 - val_accuracy: 0.8330\n",
            "Epoch 870/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8462 - val_loss: 0.4922 - val_accuracy: 0.8319\n",
            "Epoch 871/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8454 - val_loss: 0.4711 - val_accuracy: 0.8341\n",
            "Epoch 872/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.8462 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 873/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8467 - val_loss: 0.4902 - val_accuracy: 0.8330\n",
            "Epoch 874/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8460 - val_loss: 0.4812 - val_accuracy: 0.8330\n",
            "Epoch 875/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3316 - accuracy: 0.8465 - val_loss: 0.4967 - val_accuracy: 0.8330\n",
            "Epoch 876/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8463 - val_loss: 0.4820 - val_accuracy: 0.8330\n",
            "Epoch 877/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8453 - val_loss: 0.4873 - val_accuracy: 0.8330\n",
            "Epoch 878/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3315 - accuracy: 0.8460 - val_loss: 0.4814 - val_accuracy: 0.8330\n",
            "Epoch 879/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8458 - val_loss: 0.4831 - val_accuracy: 0.8330\n",
            "Epoch 880/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8469 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 881/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8456 - val_loss: 0.4839 - val_accuracy: 0.8330\n",
            "Epoch 882/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3314 - accuracy: 0.8460 - val_loss: 0.4826 - val_accuracy: 0.8330\n",
            "Epoch 883/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8462 - val_loss: 0.5013 - val_accuracy: 0.8330\n",
            "Epoch 884/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3320 - accuracy: 0.8458 - val_loss: 0.4877 - val_accuracy: 0.8319\n",
            "Epoch 885/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8463 - val_loss: 0.4879 - val_accuracy: 0.8330\n",
            "Epoch 886/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8462 - val_loss: 0.4724 - val_accuracy: 0.8341\n",
            "Epoch 887/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8456 - val_loss: 0.4722 - val_accuracy: 0.8330\n",
            "Epoch 888/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8456 - val_loss: 0.4979 - val_accuracy: 0.8330\n",
            "Epoch 889/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8463 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 890/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8465 - val_loss: 0.4812 - val_accuracy: 0.8341\n",
            "Epoch 891/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8456 - val_loss: 0.4820 - val_accuracy: 0.8330\n",
            "Epoch 892/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8472 - val_loss: 0.5079 - val_accuracy: 0.8330\n",
            "Epoch 893/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8460 - val_loss: 0.4989 - val_accuracy: 0.8319\n",
            "Epoch 894/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8454 - val_loss: 0.4928 - val_accuracy: 0.8319\n",
            "Epoch 895/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8458 - val_loss: 0.4830 - val_accuracy: 0.8330\n",
            "Epoch 896/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3311 - accuracy: 0.8470 - val_loss: 0.4983 - val_accuracy: 0.8330\n",
            "Epoch 897/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8460 - val_loss: 0.4832 - val_accuracy: 0.8330\n",
            "Epoch 898/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.8460 - val_loss: 0.4736 - val_accuracy: 0.8308\n",
            "Epoch 899/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8470 - val_loss: 0.4950 - val_accuracy: 0.8319\n",
            "Epoch 900/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8467 - val_loss: 0.4901 - val_accuracy: 0.8319\n",
            "Epoch 901/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8453 - val_loss: 0.4889 - val_accuracy: 0.8319\n",
            "Epoch 902/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8463 - val_loss: 0.4893 - val_accuracy: 0.8330\n",
            "Epoch 903/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8462 - val_loss: 0.4838 - val_accuracy: 0.8330\n",
            "Epoch 904/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8476 - val_loss: 0.5012 - val_accuracy: 0.8330\n",
            "Epoch 905/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3317 - accuracy: 0.8456 - val_loss: 0.4850 - val_accuracy: 0.8319\n",
            "Epoch 906/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8465 - val_loss: 0.4755 - val_accuracy: 0.8341\n",
            "Epoch 907/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8456 - val_loss: 0.4727 - val_accuracy: 0.8341\n",
            "Epoch 908/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3318 - accuracy: 0.8460 - val_loss: 0.4789 - val_accuracy: 0.8341\n",
            "Epoch 909/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3329 - accuracy: 0.8465 - val_loss: 0.4910 - val_accuracy: 0.8319\n",
            "Epoch 910/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3311 - accuracy: 0.8460 - val_loss: 0.4886 - val_accuracy: 0.8330\n",
            "Epoch 911/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8451 - val_loss: 0.4672 - val_accuracy: 0.8341\n",
            "Epoch 912/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8472 - val_loss: 0.4850 - val_accuracy: 0.8330\n",
            "Epoch 913/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8467 - val_loss: 0.4825 - val_accuracy: 0.8330\n",
            "Epoch 914/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3322 - accuracy: 0.8453 - val_loss: 0.4549 - val_accuracy: 0.8374\n",
            "Epoch 915/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3325 - accuracy: 0.8478 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
            "Epoch 916/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8465 - val_loss: 0.4857 - val_accuracy: 0.8330\n",
            "Epoch 917/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8449 - val_loss: 0.4917 - val_accuracy: 0.8319\n",
            "Epoch 918/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8467 - val_loss: 0.4968 - val_accuracy: 0.8319\n",
            "Epoch 919/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8472 - val_loss: 0.4804 - val_accuracy: 0.8330\n",
            "Epoch 920/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8472 - val_loss: 0.5003 - val_accuracy: 0.8330\n",
            "Epoch 921/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8456 - val_loss: 0.4821 - val_accuracy: 0.8330\n",
            "Epoch 922/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8453 - val_loss: 0.4813 - val_accuracy: 0.8330\n",
            "Epoch 923/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8463 - val_loss: 0.4942 - val_accuracy: 0.8319\n",
            "Epoch 924/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8463 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 925/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8469 - val_loss: 0.4950 - val_accuracy: 0.8319\n",
            "Epoch 926/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8460 - val_loss: 0.4953 - val_accuracy: 0.8330\n",
            "Epoch 927/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8462 - val_loss: 0.4803 - val_accuracy: 0.8330\n",
            "Epoch 928/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8465 - val_loss: 0.4906 - val_accuracy: 0.8330\n",
            "Epoch 929/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8456 - val_loss: 0.4732 - val_accuracy: 0.8341\n",
            "Epoch 930/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3315 - accuracy: 0.8463 - val_loss: 0.4855 - val_accuracy: 0.8341\n",
            "Epoch 931/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8470 - val_loss: 0.4774 - val_accuracy: 0.8341\n",
            "Epoch 932/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3312 - accuracy: 0.8454 - val_loss: 0.4814 - val_accuracy: 0.8330\n",
            "Epoch 933/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3319 - accuracy: 0.8463 - val_loss: 0.4965 - val_accuracy: 0.8330\n",
            "Epoch 934/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8469 - val_loss: 0.5007 - val_accuracy: 0.8319\n",
            "Epoch 935/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3325 - accuracy: 0.8462 - val_loss: 0.4731 - val_accuracy: 0.8341\n",
            "Epoch 936/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3314 - accuracy: 0.8453 - val_loss: 0.4742 - val_accuracy: 0.8330\n",
            "Epoch 937/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8463 - val_loss: 0.4963 - val_accuracy: 0.8319\n",
            "Epoch 938/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8460 - val_loss: 0.4735 - val_accuracy: 0.8330\n",
            "Epoch 939/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3313 - accuracy: 0.8467 - val_loss: 0.4912 - val_accuracy: 0.8330\n",
            "Epoch 940/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8470 - val_loss: 0.4958 - val_accuracy: 0.8319\n",
            "Epoch 941/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8451 - val_loss: 0.4758 - val_accuracy: 0.8330\n",
            "Epoch 942/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8470 - val_loss: 0.4797 - val_accuracy: 0.8341\n",
            "Epoch 943/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8462 - val_loss: 0.4948 - val_accuracy: 0.8319\n",
            "Epoch 944/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8469 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 945/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8465 - val_loss: 0.4830 - val_accuracy: 0.8330\n",
            "Epoch 946/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8456 - val_loss: 0.4884 - val_accuracy: 0.8330\n",
            "Epoch 947/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3309 - accuracy: 0.8462 - val_loss: 0.4855 - val_accuracy: 0.8330\n",
            "Epoch 948/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8456 - val_loss: 0.4706 - val_accuracy: 0.8341\n",
            "Epoch 949/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8470 - val_loss: 0.4920 - val_accuracy: 0.8330\n",
            "Epoch 950/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8456 - val_loss: 0.4863 - val_accuracy: 0.8330\n",
            "Epoch 951/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8453 - val_loss: 0.4978 - val_accuracy: 0.8319\n",
            "Epoch 952/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8462 - val_loss: 0.4950 - val_accuracy: 0.8319\n",
            "Epoch 953/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8458 - val_loss: 0.4834 - val_accuracy: 0.8341\n",
            "Epoch 954/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8472 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 955/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8478 - val_loss: 0.4976 - val_accuracy: 0.8319\n",
            "Epoch 956/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8449 - val_loss: 0.4866 - val_accuracy: 0.8330\n",
            "Epoch 957/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3315 - accuracy: 0.8479 - val_loss: 0.5045 - val_accuracy: 0.8319\n",
            "Epoch 958/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3318 - accuracy: 0.8467 - val_loss: 0.5131 - val_accuracy: 0.8297\n",
            "Epoch 959/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8462 - val_loss: 0.4896 - val_accuracy: 0.8330\n",
            "Epoch 960/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8465 - val_loss: 0.4777 - val_accuracy: 0.8330\n",
            "Epoch 961/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8469 - val_loss: 0.4827 - val_accuracy: 0.8341\n",
            "Epoch 962/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8467 - val_loss: 0.4809 - val_accuracy: 0.8341\n",
            "Epoch 963/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8470 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
            "Epoch 964/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8472 - val_loss: 0.4957 - val_accuracy: 0.8319\n",
            "Epoch 965/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8470 - val_loss: 0.4887 - val_accuracy: 0.8330\n",
            "Epoch 966/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8472 - val_loss: 0.4974 - val_accuracy: 0.8319\n",
            "Epoch 967/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8460 - val_loss: 0.4755 - val_accuracy: 0.8341\n",
            "Epoch 968/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8465 - val_loss: 0.4812 - val_accuracy: 0.8330\n",
            "Epoch 969/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8456 - val_loss: 0.5012 - val_accuracy: 0.8330\n",
            "Epoch 970/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8474 - val_loss: 0.5030 - val_accuracy: 0.8330\n",
            "Epoch 971/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8465 - val_loss: 0.4791 - val_accuracy: 0.8341\n",
            "Epoch 972/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8463 - val_loss: 0.4903 - val_accuracy: 0.8330\n",
            "Epoch 973/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3312 - accuracy: 0.8469 - val_loss: 0.4871 - val_accuracy: 0.8330\n",
            "Epoch 974/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8462 - val_loss: 0.4899 - val_accuracy: 0.8319\n",
            "Epoch 975/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8463 - val_loss: 0.4761 - val_accuracy: 0.8330\n",
            "Epoch 976/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8478 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 977/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8465 - val_loss: 0.4714 - val_accuracy: 0.8341\n",
            "Epoch 978/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8467 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 979/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8458 - val_loss: 0.4773 - val_accuracy: 0.8330\n",
            "Epoch 980/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3311 - accuracy: 0.8458 - val_loss: 0.4808 - val_accuracy: 0.8330\n",
            "Epoch 981/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8479 - val_loss: 0.5040 - val_accuracy: 0.8319\n",
            "Epoch 982/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8460 - val_loss: 0.4795 - val_accuracy: 0.8341\n",
            "Epoch 983/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3310 - accuracy: 0.8458 - val_loss: 0.4697 - val_accuracy: 0.8330\n",
            "Epoch 984/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3312 - accuracy: 0.8458 - val_loss: 0.4765 - val_accuracy: 0.8330\n",
            "Epoch 985/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8465 - val_loss: 0.4754 - val_accuracy: 0.8330\n",
            "Epoch 986/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8472 - val_loss: 0.4868 - val_accuracy: 0.8330\n",
            "Epoch 987/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8470 - val_loss: 0.4998 - val_accuracy: 0.8319\n",
            "Epoch 988/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8465 - val_loss: 0.4999 - val_accuracy: 0.8319\n",
            "Epoch 989/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8465 - val_loss: 0.4912 - val_accuracy: 0.8330\n",
            "Epoch 990/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8467 - val_loss: 0.4797 - val_accuracy: 0.8319\n",
            "Epoch 991/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8467 - val_loss: 0.4771 - val_accuracy: 0.8330\n",
            "Epoch 992/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8460 - val_loss: 0.4936 - val_accuracy: 0.8319\n",
            "Epoch 993/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8487 - val_loss: 0.5075 - val_accuracy: 0.8330\n",
            "Epoch 994/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8462 - val_loss: 0.4873 - val_accuracy: 0.8330\n",
            "Epoch 995/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8463 - val_loss: 0.4935 - val_accuracy: 0.8319\n",
            "Epoch 996/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8462 - val_loss: 0.4818 - val_accuracy: 0.8330\n",
            "Epoch 997/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8469 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 998/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8467 - val_loss: 0.4958 - val_accuracy: 0.8319\n",
            "Epoch 999/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8465 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1000/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8465 - val_loss: 0.4930 - val_accuracy: 0.8319\n",
            "Epoch 1001/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8472 - val_loss: 0.5026 - val_accuracy: 0.8319\n",
            "Epoch 1002/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3302 - accuracy: 0.8465 - val_loss: 0.4775 - val_accuracy: 0.8341\n",
            "Epoch 1003/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.8460 - val_loss: 0.4872 - val_accuracy: 0.8319\n",
            "Epoch 1004/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8458 - val_loss: 0.4922 - val_accuracy: 0.8319\n",
            "Epoch 1005/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3304 - accuracy: 0.8467 - val_loss: 0.4779 - val_accuracy: 0.8352\n",
            "Epoch 1006/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8454 - val_loss: 0.4761 - val_accuracy: 0.8341\n",
            "Epoch 1007/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8476 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 1008/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8474 - val_loss: 0.4809 - val_accuracy: 0.8330\n",
            "Epoch 1009/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8478 - val_loss: 0.5165 - val_accuracy: 0.8319\n",
            "Epoch 1010/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.8469 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
            "Epoch 1011/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8460 - val_loss: 0.4811 - val_accuracy: 0.8319\n",
            "Epoch 1012/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8460 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 1013/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8476 - val_loss: 0.4909 - val_accuracy: 0.8330\n",
            "Epoch 1014/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8462 - val_loss: 0.4729 - val_accuracy: 0.8330\n",
            "Epoch 1015/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8458 - val_loss: 0.4846 - val_accuracy: 0.8330\n",
            "Epoch 1016/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8476 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1017/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8470 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 1018/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8462 - val_loss: 0.4808 - val_accuracy: 0.8319\n",
            "Epoch 1019/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8465 - val_loss: 0.4856 - val_accuracy: 0.8330\n",
            "Epoch 1020/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8460 - val_loss: 0.4684 - val_accuracy: 0.8352\n",
            "Epoch 1021/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8463 - val_loss: 0.4862 - val_accuracy: 0.8341\n",
            "Epoch 1022/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8479 - val_loss: 0.4966 - val_accuracy: 0.8319\n",
            "Epoch 1023/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8458 - val_loss: 0.4769 - val_accuracy: 0.8319\n",
            "Epoch 1024/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3300 - accuracy: 0.8463 - val_loss: 0.4965 - val_accuracy: 0.8319\n",
            "Epoch 1025/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3307 - accuracy: 0.8462 - val_loss: 0.4846 - val_accuracy: 0.8330\n",
            "Epoch 1026/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8463 - val_loss: 0.4825 - val_accuracy: 0.8341\n",
            "Epoch 1027/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8470 - val_loss: 0.4935 - val_accuracy: 0.8319\n",
            "Epoch 1028/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8460 - val_loss: 0.4775 - val_accuracy: 0.8341\n",
            "Epoch 1029/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3302 - accuracy: 0.8472 - val_loss: 0.4945 - val_accuracy: 0.8330\n",
            "Epoch 1030/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8467 - val_loss: 0.4931 - val_accuracy: 0.8319\n",
            "Epoch 1031/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8470 - val_loss: 0.5052 - val_accuracy: 0.8319\n",
            "Epoch 1032/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8470 - val_loss: 0.4816 - val_accuracy: 0.8341\n",
            "Epoch 1033/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8460 - val_loss: 0.4837 - val_accuracy: 0.8341\n",
            "Epoch 1034/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8467 - val_loss: 0.4961 - val_accuracy: 0.8319\n",
            "Epoch 1035/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8472 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1036/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8462 - val_loss: 0.4794 - val_accuracy: 0.8341\n",
            "Epoch 1037/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3303 - accuracy: 0.8483 - val_loss: 0.4998 - val_accuracy: 0.8319\n",
            "Epoch 1038/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8472 - val_loss: 0.4951 - val_accuracy: 0.8319\n",
            "Epoch 1039/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8463 - val_loss: 0.4920 - val_accuracy: 0.8330\n",
            "Epoch 1040/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8470 - val_loss: 0.4953 - val_accuracy: 0.8319\n",
            "Epoch 1041/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8470 - val_loss: 0.4928 - val_accuracy: 0.8319\n",
            "Epoch 1042/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8458 - val_loss: 0.4878 - val_accuracy: 0.8319\n",
            "Epoch 1043/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8474 - val_loss: 0.5020 - val_accuracy: 0.8319\n",
            "Epoch 1044/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8463 - val_loss: 0.4872 - val_accuracy: 0.8330\n",
            "Epoch 1045/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8463 - val_loss: 0.4774 - val_accuracy: 0.8341\n",
            "Epoch 1046/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8454 - val_loss: 0.4752 - val_accuracy: 0.8352\n",
            "Epoch 1047/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3295 - accuracy: 0.8479 - val_loss: 0.5088 - val_accuracy: 0.8330\n",
            "Epoch 1048/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8465 - val_loss: 0.4923 - val_accuracy: 0.8330\n",
            "Epoch 1049/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8467 - val_loss: 0.4796 - val_accuracy: 0.8330\n",
            "Epoch 1050/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8458 - val_loss: 0.4838 - val_accuracy: 0.8330\n",
            "Epoch 1051/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8463 - val_loss: 0.4703 - val_accuracy: 0.8330\n",
            "Epoch 1052/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3310 - accuracy: 0.8483 - val_loss: 0.4831 - val_accuracy: 0.8341\n",
            "Epoch 1053/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8472 - val_loss: 0.4842 - val_accuracy: 0.8341\n",
            "Epoch 1054/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8456 - val_loss: 0.4901 - val_accuracy: 0.8330\n",
            "Epoch 1055/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8462 - val_loss: 0.4684 - val_accuracy: 0.8330\n",
            "Epoch 1056/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8474 - val_loss: 0.4990 - val_accuracy: 0.8319\n",
            "Epoch 1057/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8465 - val_loss: 0.4757 - val_accuracy: 0.8352\n",
            "Epoch 1058/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8470 - val_loss: 0.5009 - val_accuracy: 0.8319\n",
            "Epoch 1059/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.8476 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 1060/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3309 - accuracy: 0.8476 - val_loss: 0.4933 - val_accuracy: 0.8330\n",
            "Epoch 1061/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8465 - val_loss: 0.4713 - val_accuracy: 0.8319\n",
            "Epoch 1062/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3307 - accuracy: 0.8470 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 1063/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8481 - val_loss: 0.4880 - val_accuracy: 0.8341\n",
            "Epoch 1064/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8470 - val_loss: 0.4961 - val_accuracy: 0.8319\n",
            "Epoch 1065/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8456 - val_loss: 0.4833 - val_accuracy: 0.8341\n",
            "Epoch 1066/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8476 - val_loss: 0.4673 - val_accuracy: 0.8330\n",
            "Epoch 1067/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3306 - accuracy: 0.8465 - val_loss: 0.5011 - val_accuracy: 0.8319\n",
            "Epoch 1068/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8479 - val_loss: 0.4951 - val_accuracy: 0.8330\n",
            "Epoch 1069/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8465 - val_loss: 0.4775 - val_accuracy: 0.8341\n",
            "Epoch 1070/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8465 - val_loss: 0.4791 - val_accuracy: 0.8341\n",
            "Epoch 1071/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8469 - val_loss: 0.4923 - val_accuracy: 0.8319\n",
            "Epoch 1072/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.8472 - val_loss: 0.4919 - val_accuracy: 0.8330\n",
            "Epoch 1073/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8467 - val_loss: 0.4890 - val_accuracy: 0.8330\n",
            "Epoch 1074/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8454 - val_loss: 0.4783 - val_accuracy: 0.8341\n",
            "Epoch 1075/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8476 - val_loss: 0.4954 - val_accuracy: 0.8330\n",
            "Epoch 1076/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8478 - val_loss: 0.4856 - val_accuracy: 0.8330\n",
            "Epoch 1077/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3305 - accuracy: 0.8472 - val_loss: 0.5029 - val_accuracy: 0.8319\n",
            "Epoch 1078/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8465 - val_loss: 0.4845 - val_accuracy: 0.8330\n",
            "Epoch 1079/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8474 - val_loss: 0.4783 - val_accuracy: 0.8341\n",
            "Epoch 1080/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8463 - val_loss: 0.4809 - val_accuracy: 0.8341\n",
            "Epoch 1081/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8467 - val_loss: 0.5043 - val_accuracy: 0.8319\n",
            "Epoch 1082/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8465 - val_loss: 0.4785 - val_accuracy: 0.8330\n",
            "Epoch 1083/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8479 - val_loss: 0.4922 - val_accuracy: 0.8330\n",
            "Epoch 1084/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8462 - val_loss: 0.4825 - val_accuracy: 0.8330\n",
            "Epoch 1085/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8462 - val_loss: 0.4771 - val_accuracy: 0.8341\n",
            "Epoch 1086/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8479 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 1087/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8469 - val_loss: 0.4968 - val_accuracy: 0.8319\n",
            "Epoch 1088/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8472 - val_loss: 0.4881 - val_accuracy: 0.8330\n",
            "Epoch 1089/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8472 - val_loss: 0.4933 - val_accuracy: 0.8319\n",
            "Epoch 1090/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8472 - val_loss: 0.4946 - val_accuracy: 0.8319\n",
            "Epoch 1091/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8472 - val_loss: 0.4893 - val_accuracy: 0.8330\n",
            "Epoch 1092/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8472 - val_loss: 0.4791 - val_accuracy: 0.8330\n",
            "Epoch 1093/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8474 - val_loss: 0.5048 - val_accuracy: 0.8319\n",
            "Epoch 1094/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8474 - val_loss: 0.4779 - val_accuracy: 0.8330\n",
            "Epoch 1095/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8472 - val_loss: 0.5028 - val_accuracy: 0.8319\n",
            "Epoch 1096/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3307 - accuracy: 0.8465 - val_loss: 0.5036 - val_accuracy: 0.8319\n",
            "Epoch 1097/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8467 - val_loss: 0.4781 - val_accuracy: 0.8341\n",
            "Epoch 1098/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8469 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 1099/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8470 - val_loss: 0.4921 - val_accuracy: 0.8330\n",
            "Epoch 1100/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3300 - accuracy: 0.8465 - val_loss: 0.4915 - val_accuracy: 0.8330\n",
            "Epoch 1101/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8462 - val_loss: 0.4882 - val_accuracy: 0.8330\n",
            "Epoch 1102/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8478 - val_loss: 0.5124 - val_accuracy: 0.8330\n",
            "Epoch 1103/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8467 - val_loss: 0.4806 - val_accuracy: 0.8330\n",
            "Epoch 1104/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8479 - val_loss: 0.4892 - val_accuracy: 0.8330\n",
            "Epoch 1105/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8488 - val_loss: 0.5111 - val_accuracy: 0.8330\n",
            "Epoch 1106/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8463 - val_loss: 0.4832 - val_accuracy: 0.8330\n",
            "Epoch 1107/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8474 - val_loss: 0.4883 - val_accuracy: 0.8330\n",
            "Epoch 1108/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8470 - val_loss: 0.4875 - val_accuracy: 0.8330\n",
            "Epoch 1109/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8474 - val_loss: 0.4953 - val_accuracy: 0.8330\n",
            "Epoch 1110/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3303 - accuracy: 0.8462 - val_loss: 0.4903 - val_accuracy: 0.8319\n",
            "Epoch 1111/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8470 - val_loss: 0.4972 - val_accuracy: 0.8330\n",
            "Epoch 1112/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8463 - val_loss: 0.4712 - val_accuracy: 0.8319\n",
            "Epoch 1113/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8470 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 1114/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8465 - val_loss: 0.5026 - val_accuracy: 0.8319\n",
            "Epoch 1115/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8456 - val_loss: 0.4651 - val_accuracy: 0.8374\n",
            "Epoch 1116/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3306 - accuracy: 0.8487 - val_loss: 0.4927 - val_accuracy: 0.8330\n",
            "Epoch 1117/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8470 - val_loss: 0.4989 - val_accuracy: 0.8319\n",
            "Epoch 1118/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8460 - val_loss: 0.4782 - val_accuracy: 0.8341\n",
            "Epoch 1119/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8462 - val_loss: 0.4971 - val_accuracy: 0.8319\n",
            "Epoch 1120/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8476 - val_loss: 0.4828 - val_accuracy: 0.8330\n",
            "Epoch 1121/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8465 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 1122/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8481 - val_loss: 0.4981 - val_accuracy: 0.8319\n",
            "Epoch 1123/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8469 - val_loss: 0.4913 - val_accuracy: 0.8330\n",
            "Epoch 1124/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8463 - val_loss: 0.4820 - val_accuracy: 0.8330\n",
            "Epoch 1125/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8472 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1126/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8469 - val_loss: 0.4895 - val_accuracy: 0.8330\n",
            "Epoch 1127/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8476 - val_loss: 0.4986 - val_accuracy: 0.8319\n",
            "Epoch 1128/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8463 - val_loss: 0.4777 - val_accuracy: 0.8341\n",
            "Epoch 1129/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8476 - val_loss: 0.5048 - val_accuracy: 0.8319\n",
            "Epoch 1130/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8472 - val_loss: 0.4875 - val_accuracy: 0.8330\n",
            "Epoch 1131/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8472 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 1132/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8467 - val_loss: 0.4900 - val_accuracy: 0.8330\n",
            "Epoch 1133/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8472 - val_loss: 0.4921 - val_accuracy: 0.8330\n",
            "Epoch 1134/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8474 - val_loss: 0.4964 - val_accuracy: 0.8319\n",
            "Epoch 1135/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8469 - val_loss: 0.4768 - val_accuracy: 0.8319\n",
            "Epoch 1136/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8474 - val_loss: 0.4949 - val_accuracy: 0.8319\n",
            "Epoch 1137/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8470 - val_loss: 0.4861 - val_accuracy: 0.8330\n",
            "Epoch 1138/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3294 - accuracy: 0.8474 - val_loss: 0.4902 - val_accuracy: 0.8330\n",
            "Epoch 1139/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8469 - val_loss: 0.5000 - val_accuracy: 0.8319\n",
            "Epoch 1140/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8474 - val_loss: 0.4935 - val_accuracy: 0.8330\n",
            "Epoch 1141/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8474 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 1142/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8465 - val_loss: 0.4739 - val_accuracy: 0.8319\n",
            "Epoch 1143/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8474 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 1144/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8472 - val_loss: 0.4896 - val_accuracy: 0.8330\n",
            "Epoch 1145/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8476 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1146/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8479 - val_loss: 0.5041 - val_accuracy: 0.8319\n",
            "Epoch 1147/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8467 - val_loss: 0.4996 - val_accuracy: 0.8319\n",
            "Epoch 1148/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8458 - val_loss: 0.4910 - val_accuracy: 0.8330\n",
            "Epoch 1149/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.8470 - val_loss: 0.4867 - val_accuracy: 0.8330\n",
            "Epoch 1150/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8483 - val_loss: 0.4860 - val_accuracy: 0.8330\n",
            "Epoch 1151/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8481 - val_loss: 0.4988 - val_accuracy: 0.8308\n",
            "Epoch 1152/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8470 - val_loss: 0.4943 - val_accuracy: 0.8319\n",
            "Epoch 1153/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8470 - val_loss: 0.4795 - val_accuracy: 0.8341\n",
            "Epoch 1154/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8481 - val_loss: 0.4803 - val_accuracy: 0.8330\n",
            "Epoch 1155/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8474 - val_loss: 0.4947 - val_accuracy: 0.8330\n",
            "Epoch 1156/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8470 - val_loss: 0.4958 - val_accuracy: 0.8330\n",
            "Epoch 1157/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8476 - val_loss: 0.4878 - val_accuracy: 0.8330\n",
            "Epoch 1158/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8483 - val_loss: 0.4967 - val_accuracy: 0.8319\n",
            "Epoch 1159/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8470 - val_loss: 0.4979 - val_accuracy: 0.8319\n",
            "Epoch 1160/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8463 - val_loss: 0.4918 - val_accuracy: 0.8330\n",
            "Epoch 1161/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8478 - val_loss: 0.4833 - val_accuracy: 0.8341\n",
            "Epoch 1162/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8470 - val_loss: 0.4888 - val_accuracy: 0.8330\n",
            "Epoch 1163/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8481 - val_loss: 0.4873 - val_accuracy: 0.8330\n",
            "Epoch 1164/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3293 - accuracy: 0.8472 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 1165/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8470 - val_loss: 0.4971 - val_accuracy: 0.8330\n",
            "Epoch 1166/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8472 - val_loss: 0.4846 - val_accuracy: 0.8330\n",
            "Epoch 1167/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8465 - val_loss: 0.4977 - val_accuracy: 0.8330\n",
            "Epoch 1168/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8474 - val_loss: 0.4907 - val_accuracy: 0.8330\n",
            "Epoch 1169/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8463 - val_loss: 0.4805 - val_accuracy: 0.8341\n",
            "Epoch 1170/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8476 - val_loss: 0.4908 - val_accuracy: 0.8330\n",
            "Epoch 1171/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8479 - val_loss: 0.4965 - val_accuracy: 0.8319\n",
            "Epoch 1172/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3300 - accuracy: 0.8467 - val_loss: 0.5000 - val_accuracy: 0.8319\n",
            "Epoch 1173/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8465 - val_loss: 0.4693 - val_accuracy: 0.8352\n",
            "Epoch 1174/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8494 - val_loss: 0.4981 - val_accuracy: 0.8330\n",
            "Epoch 1175/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8465 - val_loss: 0.4823 - val_accuracy: 0.8341\n",
            "Epoch 1176/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8478 - val_loss: 0.4821 - val_accuracy: 0.8330\n",
            "Epoch 1177/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3295 - accuracy: 0.8481 - val_loss: 0.5092 - val_accuracy: 0.8319\n",
            "Epoch 1178/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3295 - accuracy: 0.8469 - val_loss: 0.4791 - val_accuracy: 0.8341\n",
            "Epoch 1179/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8479 - val_loss: 0.4926 - val_accuracy: 0.8330\n",
            "Epoch 1180/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8460 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
            "Epoch 1181/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8474 - val_loss: 0.4853 - val_accuracy: 0.8330\n",
            "Epoch 1182/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8478 - val_loss: 0.4917 - val_accuracy: 0.8330\n",
            "Epoch 1183/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8478 - val_loss: 0.4945 - val_accuracy: 0.8330\n",
            "Epoch 1184/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8465 - val_loss: 0.4765 - val_accuracy: 0.8319\n",
            "Epoch 1185/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8476 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 1186/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8469 - val_loss: 0.4857 - val_accuracy: 0.8330\n",
            "Epoch 1187/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8470 - val_loss: 0.4921 - val_accuracy: 0.8330\n",
            "Epoch 1188/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8478 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 1189/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8467 - val_loss: 0.4932 - val_accuracy: 0.8330\n",
            "Epoch 1190/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8463 - val_loss: 0.4816 - val_accuracy: 0.8341\n",
            "Epoch 1191/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8485 - val_loss: 0.4971 - val_accuracy: 0.8330\n",
            "Epoch 1192/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8479 - val_loss: 0.4912 - val_accuracy: 0.8330\n",
            "Epoch 1193/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8462 - val_loss: 0.4777 - val_accuracy: 0.8341\n",
            "Epoch 1194/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8485 - val_loss: 0.4994 - val_accuracy: 0.8319\n",
            "Epoch 1195/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8467 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 1196/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8472 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 1197/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8470 - val_loss: 0.4827 - val_accuracy: 0.8330\n",
            "Epoch 1198/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8483 - val_loss: 0.4958 - val_accuracy: 0.8330\n",
            "Epoch 1199/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8470 - val_loss: 0.4821 - val_accuracy: 0.8330\n",
            "Epoch 1200/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8470 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 1201/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8479 - val_loss: 0.4851 - val_accuracy: 0.8330\n",
            "Epoch 1202/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8470 - val_loss: 0.4765 - val_accuracy: 0.8319\n",
            "Epoch 1203/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8474 - val_loss: 0.4819 - val_accuracy: 0.8330\n",
            "Epoch 1204/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8470 - val_loss: 0.4779 - val_accuracy: 0.8330\n",
            "Epoch 1205/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8490 - val_loss: 0.4969 - val_accuracy: 0.8330\n",
            "Epoch 1206/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3292 - accuracy: 0.8472 - val_loss: 0.4827 - val_accuracy: 0.8330\n",
            "Epoch 1207/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8458 - val_loss: 0.4951 - val_accuracy: 0.8319\n",
            "Epoch 1208/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8472 - val_loss: 0.5009 - val_accuracy: 0.8319\n",
            "Epoch 1209/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8469 - val_loss: 0.5045 - val_accuracy: 0.8308\n",
            "Epoch 1210/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3299 - accuracy: 0.8485 - val_loss: 0.5027 - val_accuracy: 0.8330\n",
            "Epoch 1211/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8469 - val_loss: 0.4786 - val_accuracy: 0.8341\n",
            "Epoch 1212/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8472 - val_loss: 0.4805 - val_accuracy: 0.8330\n",
            "Epoch 1213/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8470 - val_loss: 0.4887 - val_accuracy: 0.8319\n",
            "Epoch 1214/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8462 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 1215/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8478 - val_loss: 0.4866 - val_accuracy: 0.8330\n",
            "Epoch 1216/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8485 - val_loss: 0.4987 - val_accuracy: 0.8330\n",
            "Epoch 1217/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8472 - val_loss: 0.4944 - val_accuracy: 0.8330\n",
            "Epoch 1218/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8472 - val_loss: 0.4957 - val_accuracy: 0.8330\n",
            "Epoch 1219/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8467 - val_loss: 0.4972 - val_accuracy: 0.8330\n",
            "Epoch 1220/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8470 - val_loss: 0.4824 - val_accuracy: 0.8330\n",
            "Epoch 1221/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8462 - val_loss: 0.4806 - val_accuracy: 0.8341\n",
            "Epoch 1222/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8476 - val_loss: 0.4930 - val_accuracy: 0.8330\n",
            "Epoch 1223/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4794 - val_accuracy: 0.8330\n",
            "Epoch 1224/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8488 - val_loss: 0.4901 - val_accuracy: 0.8330\n",
            "Epoch 1225/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8470 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1226/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8462 - val_loss: 0.4699 - val_accuracy: 0.8330\n",
            "Epoch 1227/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8479 - val_loss: 0.4972 - val_accuracy: 0.8319\n",
            "Epoch 1228/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3296 - accuracy: 0.8483 - val_loss: 0.5072 - val_accuracy: 0.8308\n",
            "Epoch 1229/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8485 - val_loss: 0.4816 - val_accuracy: 0.8319\n",
            "Epoch 1230/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8462 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 1231/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8463 - val_loss: 0.4693 - val_accuracy: 0.8341\n",
            "Epoch 1232/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3311 - accuracy: 0.8474 - val_loss: 0.4783 - val_accuracy: 0.8330\n",
            "Epoch 1233/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8472 - val_loss: 0.4887 - val_accuracy: 0.8330\n",
            "Epoch 1234/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4936 - val_accuracy: 0.8330\n",
            "Epoch 1235/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8478 - val_loss: 0.4924 - val_accuracy: 0.8330\n",
            "Epoch 1236/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8469 - val_loss: 0.4892 - val_accuracy: 0.8330\n",
            "Epoch 1237/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8470 - val_loss: 0.4918 - val_accuracy: 0.8330\n",
            "Epoch 1238/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8490 - val_loss: 0.4907 - val_accuracy: 0.8330\n",
            "Epoch 1239/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8478 - val_loss: 0.5049 - val_accuracy: 0.8308\n",
            "Epoch 1240/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8467 - val_loss: 0.4959 - val_accuracy: 0.8330\n",
            "Epoch 1241/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3303 - accuracy: 0.8485 - val_loss: 0.5142 - val_accuracy: 0.8297\n",
            "Epoch 1242/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8479 - val_loss: 0.4907 - val_accuracy: 0.8330\n",
            "Epoch 1243/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8462 - val_loss: 0.4812 - val_accuracy: 0.8341\n",
            "Epoch 1244/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8483 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 1245/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8485 - val_loss: 0.5041 - val_accuracy: 0.8308\n",
            "Epoch 1246/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8478 - val_loss: 0.4934 - val_accuracy: 0.8330\n",
            "Epoch 1247/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3299 - accuracy: 0.8478 - val_loss: 0.4717 - val_accuracy: 0.8319\n",
            "Epoch 1248/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8467 - val_loss: 0.4857 - val_accuracy: 0.8330\n",
            "Epoch 1249/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8494 - val_loss: 0.5024 - val_accuracy: 0.8319\n",
            "Epoch 1250/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8469 - val_loss: 0.4810 - val_accuracy: 0.8330\n",
            "Epoch 1251/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8476 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 1252/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8465 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1253/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8483 - val_loss: 0.4896 - val_accuracy: 0.8330\n",
            "Epoch 1254/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.5014 - val_accuracy: 0.8308\n",
            "Epoch 1255/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8472 - val_loss: 0.4805 - val_accuracy: 0.8330\n",
            "Epoch 1256/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8476 - val_loss: 0.4646 - val_accuracy: 0.8374\n",
            "Epoch 1257/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3302 - accuracy: 0.8467 - val_loss: 0.4798 - val_accuracy: 0.8341\n",
            "Epoch 1258/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8501 - val_loss: 0.5065 - val_accuracy: 0.8297\n",
            "Epoch 1259/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8474 - val_loss: 0.4958 - val_accuracy: 0.8319\n",
            "Epoch 1260/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8465 - val_loss: 0.4837 - val_accuracy: 0.8341\n",
            "Epoch 1261/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8474 - val_loss: 0.4935 - val_accuracy: 0.8330\n",
            "Epoch 1262/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.8483 - val_loss: 0.5045 - val_accuracy: 0.8308\n",
            "Epoch 1263/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8472 - val_loss: 0.4934 - val_accuracy: 0.8330\n",
            "Epoch 1264/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8472 - val_loss: 0.4957 - val_accuracy: 0.8319\n",
            "Epoch 1265/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8474 - val_loss: 0.4944 - val_accuracy: 0.8330\n",
            "Epoch 1266/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8483 - val_loss: 0.4771 - val_accuracy: 0.8330\n",
            "Epoch 1267/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8472 - val_loss: 0.5046 - val_accuracy: 0.8308\n",
            "Epoch 1268/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8478 - val_loss: 0.4841 - val_accuracy: 0.8341\n",
            "Epoch 1269/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8478 - val_loss: 0.4811 - val_accuracy: 0.8330\n",
            "Epoch 1270/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8474 - val_loss: 0.4992 - val_accuracy: 0.8319\n",
            "Epoch 1271/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8472 - val_loss: 0.5000 - val_accuracy: 0.8308\n",
            "Epoch 1272/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8472 - val_loss: 0.4812 - val_accuracy: 0.8330\n",
            "Epoch 1273/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8485 - val_loss: 0.4856 - val_accuracy: 0.8330\n",
            "Epoch 1274/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3293 - accuracy: 0.8478 - val_loss: 0.4802 - val_accuracy: 0.8330\n",
            "Epoch 1275/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4850 - val_accuracy: 0.8341\n",
            "Epoch 1276/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8469 - val_loss: 0.4949 - val_accuracy: 0.8308\n",
            "Epoch 1277/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3291 - accuracy: 0.8483 - val_loss: 0.4748 - val_accuracy: 0.8352\n",
            "Epoch 1278/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8481 - val_loss: 0.4856 - val_accuracy: 0.8341\n",
            "Epoch 1279/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8470 - val_loss: 0.4836 - val_accuracy: 0.8330\n",
            "Epoch 1280/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8470 - val_loss: 0.4795 - val_accuracy: 0.8341\n",
            "Epoch 1281/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8478 - val_loss: 0.4809 - val_accuracy: 0.8330\n",
            "Epoch 1282/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8472 - val_loss: 0.5027 - val_accuracy: 0.8308\n",
            "Epoch 1283/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8487 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1284/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8487 - val_loss: 0.4821 - val_accuracy: 0.8330\n",
            "Epoch 1285/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4825 - val_accuracy: 0.8341\n",
            "Epoch 1286/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8472 - val_loss: 0.4808 - val_accuracy: 0.8341\n",
            "Epoch 1287/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8481 - val_loss: 0.4881 - val_accuracy: 0.8341\n",
            "Epoch 1288/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8481 - val_loss: 0.4955 - val_accuracy: 0.8319\n",
            "Epoch 1289/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4999 - val_accuracy: 0.8319\n",
            "Epoch 1290/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8470 - val_loss: 0.4930 - val_accuracy: 0.8319\n",
            "Epoch 1291/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.4914 - val_accuracy: 0.8330\n",
            "Epoch 1292/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8470 - val_loss: 0.4978 - val_accuracy: 0.8308\n",
            "Epoch 1293/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8463 - val_loss: 0.4789 - val_accuracy: 0.8319\n",
            "Epoch 1294/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8469 - val_loss: 0.4919 - val_accuracy: 0.8330\n",
            "Epoch 1295/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8476 - val_loss: 0.4965 - val_accuracy: 0.8308\n",
            "Epoch 1296/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8462 - val_loss: 0.4832 - val_accuracy: 0.8341\n",
            "Epoch 1297/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8481 - val_loss: 0.5144 - val_accuracy: 0.8297\n",
            "Epoch 1298/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8472 - val_loss: 0.4909 - val_accuracy: 0.8330\n",
            "Epoch 1299/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8479 - val_loss: 0.4923 - val_accuracy: 0.8330\n",
            "Epoch 1300/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8492 - val_loss: 0.4980 - val_accuracy: 0.8308\n",
            "Epoch 1301/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8472 - val_loss: 0.4885 - val_accuracy: 0.8330\n",
            "Epoch 1302/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8463 - val_loss: 0.4833 - val_accuracy: 0.8341\n",
            "Epoch 1303/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8481 - val_loss: 0.4843 - val_accuracy: 0.8341\n",
            "Epoch 1304/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8472 - val_loss: 0.4829 - val_accuracy: 0.8330\n",
            "Epoch 1305/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8476 - val_loss: 0.4955 - val_accuracy: 0.8330\n",
            "Epoch 1306/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8481 - val_loss: 0.4918 - val_accuracy: 0.8330\n",
            "Epoch 1307/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8467 - val_loss: 0.4816 - val_accuracy: 0.8330\n",
            "Epoch 1308/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8472 - val_loss: 0.4697 - val_accuracy: 0.8363\n",
            "Epoch 1309/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.8483 - val_loss: 0.4894 - val_accuracy: 0.8330\n",
            "Epoch 1310/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8470 - val_loss: 0.4844 - val_accuracy: 0.8319\n",
            "Epoch 1311/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8474 - val_loss: 0.4833 - val_accuracy: 0.8341\n",
            "Epoch 1312/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.8487 - val_loss: 0.4903 - val_accuracy: 0.8330\n",
            "Epoch 1313/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8478 - val_loss: 0.4976 - val_accuracy: 0.8319\n",
            "Epoch 1314/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8462 - val_loss: 0.4793 - val_accuracy: 0.8341\n",
            "Epoch 1315/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8474 - val_loss: 0.4845 - val_accuracy: 0.8341\n",
            "Epoch 1316/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3299 - accuracy: 0.8479 - val_loss: 0.4817 - val_accuracy: 0.8330\n",
            "Epoch 1317/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3288 - accuracy: 0.8474 - val_loss: 0.4867 - val_accuracy: 0.8330\n",
            "Epoch 1318/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8479 - val_loss: 0.4849 - val_accuracy: 0.8330\n",
            "Epoch 1319/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8472 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 1320/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8476 - val_loss: 0.5049 - val_accuracy: 0.8308\n",
            "Epoch 1321/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8474 - val_loss: 0.4928 - val_accuracy: 0.8330\n",
            "Epoch 1322/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8472 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 1323/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3287 - accuracy: 0.8492 - val_loss: 0.5197 - val_accuracy: 0.8297\n",
            "Epoch 1324/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8478 - val_loss: 0.5017 - val_accuracy: 0.8308\n",
            "Epoch 1325/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8467 - val_loss: 0.4848 - val_accuracy: 0.8341\n",
            "Epoch 1326/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8454 - val_loss: 0.4796 - val_accuracy: 0.8330\n",
            "Epoch 1327/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8501 - val_loss: 0.5127 - val_accuracy: 0.8308\n",
            "Epoch 1328/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8474 - val_loss: 0.4772 - val_accuracy: 0.8341\n",
            "Epoch 1329/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8487 - val_loss: 0.4850 - val_accuracy: 0.8341\n",
            "Epoch 1330/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3294 - accuracy: 0.8476 - val_loss: 0.5085 - val_accuracy: 0.8308\n",
            "Epoch 1331/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8487 - val_loss: 0.4894 - val_accuracy: 0.8330\n",
            "Epoch 1332/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8469 - val_loss: 0.4817 - val_accuracy: 0.8341\n",
            "Epoch 1333/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8490 - val_loss: 0.5013 - val_accuracy: 0.8319\n",
            "Epoch 1334/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8465 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 1335/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8478 - val_loss: 0.4913 - val_accuracy: 0.8330\n",
            "Epoch 1336/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8478 - val_loss: 0.4976 - val_accuracy: 0.8319\n",
            "Epoch 1337/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8479 - val_loss: 0.4929 - val_accuracy: 0.8330\n",
            "Epoch 1338/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.4872 - val_accuracy: 0.8341\n",
            "Epoch 1339/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8467 - val_loss: 0.4766 - val_accuracy: 0.8341\n",
            "Epoch 1340/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3300 - accuracy: 0.8483 - val_loss: 0.4996 - val_accuracy: 0.8308\n",
            "Epoch 1341/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8472 - val_loss: 0.4912 - val_accuracy: 0.8319\n",
            "Epoch 1342/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8481 - val_loss: 0.4959 - val_accuracy: 0.8308\n",
            "Epoch 1343/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8470 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1344/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.4802 - val_accuracy: 0.8341\n",
            "Epoch 1345/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8476 - val_loss: 0.4900 - val_accuracy: 0.8330\n",
            "Epoch 1346/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8490 - val_loss: 0.4950 - val_accuracy: 0.8330\n",
            "Epoch 1347/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8469 - val_loss: 0.4866 - val_accuracy: 0.8330\n",
            "Epoch 1348/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8481 - val_loss: 0.4899 - val_accuracy: 0.8330\n",
            "Epoch 1349/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8469 - val_loss: 0.4995 - val_accuracy: 0.8308\n",
            "Epoch 1350/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.8476 - val_loss: 0.4840 - val_accuracy: 0.8341\n",
            "Epoch 1351/2000\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.3283 - accuracy: 0.8479 - val_loss: 0.4923 - val_accuracy: 0.8319\n",
            "Epoch 1352/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.8472 - val_loss: 0.4934 - val_accuracy: 0.8330\n",
            "Epoch 1353/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1354/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8483 - val_loss: 0.4729 - val_accuracy: 0.8352\n",
            "Epoch 1355/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8474 - val_loss: 0.4985 - val_accuracy: 0.8308\n",
            "Epoch 1356/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8479 - val_loss: 0.5052 - val_accuracy: 0.8308\n",
            "Epoch 1357/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8485 - val_loss: 0.4930 - val_accuracy: 0.8330\n",
            "Epoch 1358/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.8474 - val_loss: 0.4843 - val_accuracy: 0.8330\n",
            "Epoch 1359/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8479 - val_loss: 0.4904 - val_accuracy: 0.8319\n",
            "Epoch 1360/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8478 - val_loss: 0.4862 - val_accuracy: 0.8330\n",
            "Epoch 1361/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8485 - val_loss: 0.5052 - val_accuracy: 0.8308\n",
            "Epoch 1362/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8479 - val_loss: 0.5024 - val_accuracy: 0.8308\n",
            "Epoch 1363/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.8463 - val_loss: 0.4681 - val_accuracy: 0.8352\n",
            "Epoch 1364/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3289 - accuracy: 0.8476 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 1365/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8490 - val_loss: 0.4998 - val_accuracy: 0.8319\n",
            "Epoch 1366/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8488 - val_loss: 0.5143 - val_accuracy: 0.8297\n",
            "Epoch 1367/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8472 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1368/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8485 - val_loss: 0.4902 - val_accuracy: 0.8330\n",
            "Epoch 1369/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8476 - val_loss: 0.4931 - val_accuracy: 0.8319\n",
            "Epoch 1370/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8499 - val_loss: 0.4938 - val_accuracy: 0.8330\n",
            "Epoch 1371/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3291 - accuracy: 0.8478 - val_loss: 0.4984 - val_accuracy: 0.8319\n",
            "Epoch 1372/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3292 - accuracy: 0.8485 - val_loss: 0.4853 - val_accuracy: 0.8341\n",
            "Epoch 1373/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8479 - val_loss: 0.4953 - val_accuracy: 0.8319\n",
            "Epoch 1374/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8479 - val_loss: 0.4807 - val_accuracy: 0.8330\n",
            "Epoch 1375/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4921 - val_accuracy: 0.8319\n",
            "Epoch 1376/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8476 - val_loss: 0.5045 - val_accuracy: 0.8308\n",
            "Epoch 1377/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8488 - val_loss: 0.4744 - val_accuracy: 0.8341\n",
            "Epoch 1378/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8483 - val_loss: 0.4838 - val_accuracy: 0.8341\n",
            "Epoch 1379/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.8478 - val_loss: 0.4861 - val_accuracy: 0.8341\n",
            "Epoch 1380/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3281 - accuracy: 0.8469 - val_loss: 0.4990 - val_accuracy: 0.8319\n",
            "Epoch 1381/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8490 - val_loss: 0.4886 - val_accuracy: 0.8341\n",
            "Epoch 1382/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4996 - val_accuracy: 0.8308\n",
            "Epoch 1383/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4931 - val_accuracy: 0.8319\n",
            "Epoch 1384/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8479 - val_loss: 0.4997 - val_accuracy: 0.8308\n",
            "Epoch 1385/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8492 - val_loss: 0.4986 - val_accuracy: 0.8330\n",
            "Epoch 1386/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8476 - val_loss: 0.4879 - val_accuracy: 0.8319\n",
            "Epoch 1387/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8497 - val_loss: 0.5113 - val_accuracy: 0.8308\n",
            "Epoch 1388/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8481 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1389/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.8472 - val_loss: 0.4883 - val_accuracy: 0.8330\n",
            "Epoch 1390/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8499 - val_loss: 0.5033 - val_accuracy: 0.8308\n",
            "Epoch 1391/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8465 - val_loss: 0.4834 - val_accuracy: 0.8341\n",
            "Epoch 1392/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8481 - val_loss: 0.4767 - val_accuracy: 0.8330\n",
            "Epoch 1393/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8490 - val_loss: 0.5050 - val_accuracy: 0.8319\n",
            "Epoch 1394/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8476 - val_loss: 0.4881 - val_accuracy: 0.8330\n",
            "Epoch 1395/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8469 - val_loss: 0.4814 - val_accuracy: 0.8330\n",
            "Epoch 1396/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8474 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1397/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8490 - val_loss: 0.4909 - val_accuracy: 0.8330\n",
            "Epoch 1398/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8472 - val_loss: 0.4749 - val_accuracy: 0.8352\n",
            "Epoch 1399/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8485 - val_loss: 0.4845 - val_accuracy: 0.8341\n",
            "Epoch 1400/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8483 - val_loss: 0.4839 - val_accuracy: 0.8341\n",
            "Epoch 1401/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3280 - accuracy: 0.8474 - val_loss: 0.4867 - val_accuracy: 0.8341\n",
            "Epoch 1402/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8488 - val_loss: 0.4929 - val_accuracy: 0.8319\n",
            "Epoch 1403/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3279 - accuracy: 0.8474 - val_loss: 0.4744 - val_accuracy: 0.8341\n",
            "Epoch 1404/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.8483 - val_loss: 0.4838 - val_accuracy: 0.8341\n",
            "Epoch 1405/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8485 - val_loss: 0.4852 - val_accuracy: 0.8319\n",
            "Epoch 1406/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8485 - val_loss: 0.4949 - val_accuracy: 0.8319\n",
            "Epoch 1407/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8470 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 1408/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8478 - val_loss: 0.4960 - val_accuracy: 0.8319\n",
            "Epoch 1409/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8485 - val_loss: 0.4992 - val_accuracy: 0.8308\n",
            "Epoch 1410/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8476 - val_loss: 0.4860 - val_accuracy: 0.8341\n",
            "Epoch 1411/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8474 - val_loss: 0.4866 - val_accuracy: 0.8341\n",
            "Epoch 1412/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8479 - val_loss: 0.4796 - val_accuracy: 0.8330\n",
            "Epoch 1413/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8485 - val_loss: 0.4790 - val_accuracy: 0.8341\n",
            "Epoch 1414/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8479 - val_loss: 0.4785 - val_accuracy: 0.8341\n",
            "Epoch 1415/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8496 - val_loss: 0.5045 - val_accuracy: 0.8308\n",
            "Epoch 1416/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8470 - val_loss: 0.4732 - val_accuracy: 0.8352\n",
            "Epoch 1417/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8470 - val_loss: 0.4896 - val_accuracy: 0.8319\n",
            "Epoch 1418/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8487 - val_loss: 0.4974 - val_accuracy: 0.8330\n",
            "Epoch 1419/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8472 - val_loss: 0.4896 - val_accuracy: 0.8319\n",
            "Epoch 1420/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8494 - val_loss: 0.5112 - val_accuracy: 0.8308\n",
            "Epoch 1421/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8478 - val_loss: 0.4815 - val_accuracy: 0.8341\n",
            "Epoch 1422/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3293 - accuracy: 0.8476 - val_loss: 0.4765 - val_accuracy: 0.8341\n",
            "Epoch 1423/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8496 - val_loss: 0.5084 - val_accuracy: 0.8297\n",
            "Epoch 1424/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8476 - val_loss: 0.5013 - val_accuracy: 0.8308\n",
            "Epoch 1425/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8481 - val_loss: 0.4858 - val_accuracy: 0.8330\n",
            "Epoch 1426/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8478 - val_loss: 0.4867 - val_accuracy: 0.8319\n",
            "Epoch 1427/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8465 - val_loss: 0.4710 - val_accuracy: 0.8352\n",
            "Epoch 1428/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8483 - val_loss: 0.4977 - val_accuracy: 0.8319\n",
            "Epoch 1429/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4833 - val_accuracy: 0.8330\n",
            "Epoch 1430/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8485 - val_loss: 0.4829 - val_accuracy: 0.8341\n",
            "Epoch 1431/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3287 - accuracy: 0.8483 - val_loss: 0.5014 - val_accuracy: 0.8308\n",
            "Epoch 1432/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8481 - val_loss: 0.4948 - val_accuracy: 0.8319\n",
            "Epoch 1433/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8469 - val_loss: 0.4916 - val_accuracy: 0.8319\n",
            "Epoch 1434/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4832 - val_accuracy: 0.8341\n",
            "Epoch 1435/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8476 - val_loss: 0.4840 - val_accuracy: 0.8341\n",
            "Epoch 1436/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8481 - val_loss: 0.4851 - val_accuracy: 0.8341\n",
            "Epoch 1437/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8496 - val_loss: 0.4937 - val_accuracy: 0.8330\n",
            "Epoch 1438/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8470 - val_loss: 0.4797 - val_accuracy: 0.8330\n",
            "Epoch 1439/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8494 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 1440/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8479 - val_loss: 0.4954 - val_accuracy: 0.8319\n",
            "Epoch 1441/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8488 - val_loss: 0.4908 - val_accuracy: 0.8319\n",
            "Epoch 1442/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8469 - val_loss: 0.4875 - val_accuracy: 0.8330\n",
            "Epoch 1443/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8474 - val_loss: 0.4796 - val_accuracy: 0.8352\n",
            "Epoch 1444/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8499 - val_loss: 0.5036 - val_accuracy: 0.8319\n",
            "Epoch 1445/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8470 - val_loss: 0.4840 - val_accuracy: 0.8341\n",
            "Epoch 1446/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8474 - val_loss: 0.4827 - val_accuracy: 0.8330\n",
            "Epoch 1447/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8501 - val_loss: 0.4928 - val_accuracy: 0.8319\n",
            "Epoch 1448/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8474 - val_loss: 0.4806 - val_accuracy: 0.8330\n",
            "Epoch 1449/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8465 - val_loss: 0.4774 - val_accuracy: 0.8341\n",
            "Epoch 1450/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8479 - val_loss: 0.4996 - val_accuracy: 0.8319\n",
            "Epoch 1451/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8487 - val_loss: 0.5000 - val_accuracy: 0.8319\n",
            "Epoch 1452/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.8490 - val_loss: 0.5056 - val_accuracy: 0.8308\n",
            "Epoch 1453/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.8478 - val_loss: 0.5205 - val_accuracy: 0.8286\n",
            "Epoch 1454/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3288 - accuracy: 0.8492 - val_loss: 0.5025 - val_accuracy: 0.8308\n",
            "Epoch 1455/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8481 - val_loss: 0.4837 - val_accuracy: 0.8330\n",
            "Epoch 1456/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8487 - val_loss: 0.4844 - val_accuracy: 0.8341\n",
            "Epoch 1457/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8487 - val_loss: 0.4971 - val_accuracy: 0.8308\n",
            "Epoch 1458/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8483 - val_loss: 0.4813 - val_accuracy: 0.8341\n",
            "Epoch 1459/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8488 - val_loss: 0.4822 - val_accuracy: 0.8330\n",
            "Epoch 1460/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8476 - val_loss: 0.4919 - val_accuracy: 0.8319\n",
            "Epoch 1461/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8483 - val_loss: 0.4903 - val_accuracy: 0.8319\n",
            "Epoch 1462/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8487 - val_loss: 0.4903 - val_accuracy: 0.8319\n",
            "Epoch 1463/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8487 - val_loss: 0.4952 - val_accuracy: 0.8319\n",
            "Epoch 1464/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8476 - val_loss: 0.4774 - val_accuracy: 0.8330\n",
            "Epoch 1465/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8463 - val_loss: 0.4791 - val_accuracy: 0.8341\n",
            "Epoch 1466/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.8481 - val_loss: 0.4837 - val_accuracy: 0.8308\n",
            "Epoch 1467/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3294 - accuracy: 0.8478 - val_loss: 0.5127 - val_accuracy: 0.8297\n",
            "Epoch 1468/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8487 - val_loss: 0.4896 - val_accuracy: 0.8330\n",
            "Epoch 1469/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8483 - val_loss: 0.4904 - val_accuracy: 0.8319\n",
            "Epoch 1470/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8483 - val_loss: 0.4953 - val_accuracy: 0.8319\n",
            "Epoch 1471/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8476 - val_loss: 0.4932 - val_accuracy: 0.8319\n",
            "Epoch 1472/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3286 - accuracy: 0.8476 - val_loss: 0.4946 - val_accuracy: 0.8319\n",
            "Epoch 1473/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.8330\n",
            "Epoch 1474/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8485 - val_loss: 0.4886 - val_accuracy: 0.8319\n",
            "Epoch 1475/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4908 - val_accuracy: 0.8319\n",
            "Epoch 1476/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8515 - val_loss: 0.5266 - val_accuracy: 0.8308\n",
            "Epoch 1477/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3316 - accuracy: 0.8476 - val_loss: 0.5100 - val_accuracy: 0.8297\n",
            "Epoch 1478/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3298 - accuracy: 0.8465 - val_loss: 0.4945 - val_accuracy: 0.8319\n",
            "Epoch 1479/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3284 - accuracy: 0.8478 - val_loss: 0.4777 - val_accuracy: 0.8341\n",
            "Epoch 1480/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8485 - val_loss: 0.4912 - val_accuracy: 0.8319\n",
            "Epoch 1481/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8490 - val_loss: 0.5059 - val_accuracy: 0.8308\n",
            "Epoch 1482/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3295 - accuracy: 0.8474 - val_loss: 0.5057 - val_accuracy: 0.8297\n",
            "Epoch 1483/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8483 - val_loss: 0.4789 - val_accuracy: 0.8319\n",
            "Epoch 1484/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8474 - val_loss: 0.4872 - val_accuracy: 0.8330\n",
            "Epoch 1485/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8485 - val_loss: 0.4934 - val_accuracy: 0.8319\n",
            "Epoch 1486/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8494 - val_loss: 0.4916 - val_accuracy: 0.8330\n",
            "Epoch 1487/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8494 - val_loss: 0.4945 - val_accuracy: 0.8319\n",
            "Epoch 1488/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8479 - val_loss: 0.4825 - val_accuracy: 0.8330\n",
            "Epoch 1489/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8470 - val_loss: 0.4796 - val_accuracy: 0.8341\n",
            "Epoch 1490/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3292 - accuracy: 0.8478 - val_loss: 0.4882 - val_accuracy: 0.8319\n",
            "Epoch 1491/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8496 - val_loss: 0.4978 - val_accuracy: 0.8319\n",
            "Epoch 1492/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8478 - val_loss: 0.4936 - val_accuracy: 0.8319\n",
            "Epoch 1493/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8481 - val_loss: 0.4812 - val_accuracy: 0.8352\n",
            "Epoch 1494/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.8488 - val_loss: 0.4971 - val_accuracy: 0.8319\n",
            "Epoch 1495/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4796 - val_accuracy: 0.8330\n",
            "Epoch 1496/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8476 - val_loss: 0.4840 - val_accuracy: 0.8352\n",
            "Epoch 1497/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.8490 - val_loss: 0.4875 - val_accuracy: 0.8330\n",
            "Epoch 1498/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8490 - val_loss: 0.4860 - val_accuracy: 0.8330\n",
            "Epoch 1499/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8485 - val_loss: 0.4988 - val_accuracy: 0.8308\n",
            "Epoch 1500/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8479 - val_loss: 0.4932 - val_accuracy: 0.8319\n",
            "Epoch 1501/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8479 - val_loss: 0.4861 - val_accuracy: 0.8330\n",
            "Epoch 1502/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8488 - val_loss: 0.4986 - val_accuracy: 0.8319\n",
            "Epoch 1503/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8476 - val_loss: 0.4813 - val_accuracy: 0.8330\n",
            "Epoch 1504/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8481 - val_loss: 0.4911 - val_accuracy: 0.8319\n",
            "Epoch 1505/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8490 - val_loss: 0.5039 - val_accuracy: 0.8308\n",
            "Epoch 1506/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8485 - val_loss: 0.5056 - val_accuracy: 0.8308\n",
            "Epoch 1507/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8485 - val_loss: 0.5052 - val_accuracy: 0.8308\n",
            "Epoch 1508/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.8479 - val_loss: 0.4934 - val_accuracy: 0.8319\n",
            "Epoch 1509/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8499 - val_loss: 0.5009 - val_accuracy: 0.8308\n",
            "Epoch 1510/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.8488 - val_loss: 0.4911 - val_accuracy: 0.8319\n",
            "Epoch 1511/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8470 - val_loss: 0.4863 - val_accuracy: 0.8330\n",
            "Epoch 1512/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8487 - val_loss: 0.4938 - val_accuracy: 0.8319\n",
            "Epoch 1513/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8487 - val_loss: 0.5029 - val_accuracy: 0.8308\n",
            "Epoch 1514/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8494 - val_loss: 0.5063 - val_accuracy: 0.8308\n",
            "Epoch 1515/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8481 - val_loss: 0.4936 - val_accuracy: 0.8319\n",
            "Epoch 1516/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8462 - val_loss: 0.4698 - val_accuracy: 0.8363\n",
            "Epoch 1517/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.8487 - val_loss: 0.4855 - val_accuracy: 0.8330\n",
            "Epoch 1518/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8481 - val_loss: 0.4828 - val_accuracy: 0.8330\n",
            "Epoch 1519/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8497 - val_loss: 0.5144 - val_accuracy: 0.8297\n",
            "Epoch 1520/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.8485 - val_loss: 0.4815 - val_accuracy: 0.8330\n",
            "Epoch 1521/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3283 - accuracy: 0.8478 - val_loss: 0.4785 - val_accuracy: 0.8341\n",
            "Epoch 1522/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8488 - val_loss: 0.4971 - val_accuracy: 0.8319\n",
            "Epoch 1523/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8488 - val_loss: 0.4890 - val_accuracy: 0.8330\n",
            "Epoch 1524/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3285 - accuracy: 0.8481 - val_loss: 0.5080 - val_accuracy: 0.8297\n",
            "Epoch 1525/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3290 - accuracy: 0.8492 - val_loss: 0.5158 - val_accuracy: 0.8297\n",
            "Epoch 1526/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8474 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1527/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.8483 - val_loss: 0.4934 - val_accuracy: 0.8319\n",
            "Epoch 1528/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.8492 - val_loss: 0.4945 - val_accuracy: 0.8319\n",
            "Epoch 1529/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8476 - val_loss: 0.4945 - val_accuracy: 0.8319\n",
            "Epoch 1530/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8481 - val_loss: 0.4854 - val_accuracy: 0.8330\n",
            "Epoch 1531/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8494 - val_loss: 0.4984 - val_accuracy: 0.8319\n",
            "Epoch 1532/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8490 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1533/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8499 - val_loss: 0.5031 - val_accuracy: 0.8297\n",
            "Epoch 1534/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8483 - val_loss: 0.4859 - val_accuracy: 0.8330\n",
            "Epoch 1535/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8487 - val_loss: 0.4966 - val_accuracy: 0.8319\n",
            "Epoch 1536/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8479 - val_loss: 0.4756 - val_accuracy: 0.8341\n",
            "Epoch 1537/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3288 - accuracy: 0.8470 - val_loss: 0.4839 - val_accuracy: 0.8330\n",
            "Epoch 1538/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8478 - val_loss: 0.4825 - val_accuracy: 0.8341\n",
            "Epoch 1539/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8494 - val_loss: 0.4927 - val_accuracy: 0.8319\n",
            "Epoch 1540/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8470 - val_loss: 0.4848 - val_accuracy: 0.8319\n",
            "Epoch 1541/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8487 - val_loss: 0.4878 - val_accuracy: 0.8319\n",
            "Epoch 1542/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3287 - accuracy: 0.8496 - val_loss: 0.5039 - val_accuracy: 0.8308\n",
            "Epoch 1543/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3273 - accuracy: 0.8490 - val_loss: 0.4918 - val_accuracy: 0.8319\n",
            "Epoch 1544/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8492 - val_loss: 0.5058 - val_accuracy: 0.8308\n",
            "Epoch 1545/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8467 - val_loss: 0.4703 - val_accuracy: 0.8341\n",
            "Epoch 1546/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.8506 - val_loss: 0.5091 - val_accuracy: 0.8297\n",
            "Epoch 1547/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8481 - val_loss: 0.4953 - val_accuracy: 0.8319\n",
            "Epoch 1548/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8476 - val_loss: 0.4789 - val_accuracy: 0.8352\n",
            "Epoch 1549/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8494 - val_loss: 0.4939 - val_accuracy: 0.8319\n",
            "Epoch 1550/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8474 - val_loss: 0.4879 - val_accuracy: 0.8319\n",
            "Epoch 1551/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8490 - val_loss: 0.4945 - val_accuracy: 0.8319\n",
            "Epoch 1552/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8496 - val_loss: 0.5005 - val_accuracy: 0.8319\n",
            "Epoch 1553/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8470 - val_loss: 0.4886 - val_accuracy: 0.8319\n",
            "Epoch 1554/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8490 - val_loss: 0.4850 - val_accuracy: 0.8319\n",
            "Epoch 1555/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8487 - val_loss: 0.4899 - val_accuracy: 0.8319\n",
            "Epoch 1556/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8496 - val_loss: 0.4936 - val_accuracy: 0.8319\n",
            "Epoch 1557/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8474 - val_loss: 0.4905 - val_accuracy: 0.8319\n",
            "Epoch 1558/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8485 - val_loss: 0.4767 - val_accuracy: 0.8363\n",
            "Epoch 1559/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8508 - val_loss: 0.5033 - val_accuracy: 0.8308\n",
            "Epoch 1560/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8494 - val_loss: 0.5090 - val_accuracy: 0.8297\n",
            "Epoch 1561/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8483 - val_loss: 0.4917 - val_accuracy: 0.8330\n",
            "Epoch 1562/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8490 - val_loss: 0.5036 - val_accuracy: 0.8308\n",
            "Epoch 1563/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8478 - val_loss: 0.4972 - val_accuracy: 0.8319\n",
            "Epoch 1564/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8504 - val_loss: 0.5104 - val_accuracy: 0.8308\n",
            "Epoch 1565/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8479 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1566/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8472 - val_loss: 0.4881 - val_accuracy: 0.8308\n",
            "Epoch 1567/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8497 - val_loss: 0.4876 - val_accuracy: 0.8330\n",
            "Epoch 1568/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8504 - val_loss: 0.4907 - val_accuracy: 0.8330\n",
            "Epoch 1569/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8479 - val_loss: 0.4828 - val_accuracy: 0.8330\n",
            "Epoch 1570/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8488 - val_loss: 0.4935 - val_accuracy: 0.8319\n",
            "Epoch 1571/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8479 - val_loss: 0.4867 - val_accuracy: 0.8330\n",
            "Epoch 1572/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8485 - val_loss: 0.4923 - val_accuracy: 0.8319\n",
            "Epoch 1573/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8497 - val_loss: 0.4993 - val_accuracy: 0.8319\n",
            "Epoch 1574/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8487 - val_loss: 0.4956 - val_accuracy: 0.8319\n",
            "Epoch 1575/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8490 - val_loss: 0.4894 - val_accuracy: 0.8330\n",
            "Epoch 1576/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8478 - val_loss: 0.4879 - val_accuracy: 0.8330\n",
            "Epoch 1577/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8490 - val_loss: 0.4808 - val_accuracy: 0.8341\n",
            "Epoch 1578/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3283 - accuracy: 0.8479 - val_loss: 0.4835 - val_accuracy: 0.8319\n",
            "Epoch 1579/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3282 - accuracy: 0.8503 - val_loss: 0.5036 - val_accuracy: 0.8319\n",
            "Epoch 1580/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8487 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 1581/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8496 - val_loss: 0.4913 - val_accuracy: 0.8319\n",
            "Epoch 1582/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8481 - val_loss: 0.4805 - val_accuracy: 0.8330\n",
            "Epoch 1583/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8487 - val_loss: 0.4921 - val_accuracy: 0.8319\n",
            "Epoch 1584/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8496 - val_loss: 0.4874 - val_accuracy: 0.8330\n",
            "Epoch 1585/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8487 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 1586/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8470 - val_loss: 0.4876 - val_accuracy: 0.8330\n",
            "Epoch 1587/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3278 - accuracy: 0.8487 - val_loss: 0.4820 - val_accuracy: 0.8341\n",
            "Epoch 1588/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.4966 - val_accuracy: 0.8319\n",
            "Epoch 1589/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8494 - val_loss: 0.5012 - val_accuracy: 0.8319\n",
            "Epoch 1590/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8483 - val_loss: 0.5035 - val_accuracy: 0.8308\n",
            "Epoch 1591/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8485 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1592/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8490 - val_loss: 0.4937 - val_accuracy: 0.8319\n",
            "Epoch 1593/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8470 - val_loss: 0.4859 - val_accuracy: 0.8330\n",
            "Epoch 1594/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8483 - val_loss: 0.4949 - val_accuracy: 0.8319\n",
            "Epoch 1595/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8499 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 1596/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8465 - val_loss: 0.4817 - val_accuracy: 0.8330\n",
            "Epoch 1597/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8499 - val_loss: 0.5003 - val_accuracy: 0.8319\n",
            "Epoch 1598/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8488 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1599/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8497 - val_loss: 0.4966 - val_accuracy: 0.8319\n",
            "Epoch 1600/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8476 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 1601/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8488 - val_loss: 0.4861 - val_accuracy: 0.8330\n",
            "Epoch 1602/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8488 - val_loss: 0.5103 - val_accuracy: 0.8297\n",
            "Epoch 1603/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8487 - val_loss: 0.4861 - val_accuracy: 0.8330\n",
            "Epoch 1604/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8472 - val_loss: 0.4812 - val_accuracy: 0.8330\n",
            "Epoch 1605/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8494 - val_loss: 0.4908 - val_accuracy: 0.8330\n",
            "Epoch 1606/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8501 - val_loss: 0.5020 - val_accuracy: 0.8319\n",
            "Epoch 1607/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3286 - accuracy: 0.8485 - val_loss: 0.4976 - val_accuracy: 0.8319\n",
            "Epoch 1608/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8474 - val_loss: 0.4836 - val_accuracy: 0.8330\n",
            "Epoch 1609/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8496 - val_loss: 0.4975 - val_accuracy: 0.8319\n",
            "Epoch 1610/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8481 - val_loss: 0.4905 - val_accuracy: 0.8319\n",
            "Epoch 1611/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8483 - val_loss: 0.4818 - val_accuracy: 0.8319\n",
            "Epoch 1612/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8492 - val_loss: 0.5044 - val_accuracy: 0.8319\n",
            "Epoch 1613/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8479 - val_loss: 0.4721 - val_accuracy: 0.8330\n",
            "Epoch 1614/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8490 - val_loss: 0.4799 - val_accuracy: 0.8330\n",
            "Epoch 1615/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8478 - val_loss: 0.4800 - val_accuracy: 0.8319\n",
            "Epoch 1616/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8485 - val_loss: 0.4820 - val_accuracy: 0.8330\n",
            "Epoch 1617/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8506 - val_loss: 0.5096 - val_accuracy: 0.8297\n",
            "Epoch 1618/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8487 - val_loss: 0.5030 - val_accuracy: 0.8319\n",
            "Epoch 1619/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3286 - accuracy: 0.8470 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 1620/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8478 - val_loss: 0.4936 - val_accuracy: 0.8319\n",
            "Epoch 1621/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8481 - val_loss: 0.4840 - val_accuracy: 0.8319\n",
            "Epoch 1622/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8497 - val_loss: 0.5106 - val_accuracy: 0.8308\n",
            "Epoch 1623/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8488 - val_loss: 0.4884 - val_accuracy: 0.8330\n",
            "Epoch 1624/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8474 - val_loss: 0.4715 - val_accuracy: 0.8341\n",
            "Epoch 1625/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8488 - val_loss: 0.4831 - val_accuracy: 0.8341\n",
            "Epoch 1626/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8497 - val_loss: 0.4915 - val_accuracy: 0.8319\n",
            "Epoch 1627/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8497 - val_loss: 0.4971 - val_accuracy: 0.8319\n",
            "Epoch 1628/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8474 - val_loss: 0.4833 - val_accuracy: 0.8319\n",
            "Epoch 1629/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8490 - val_loss: 0.4968 - val_accuracy: 0.8319\n",
            "Epoch 1630/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3277 - accuracy: 0.8492 - val_loss: 0.4852 - val_accuracy: 0.8319\n",
            "Epoch 1631/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8488 - val_loss: 0.4763 - val_accuracy: 0.8330\n",
            "Epoch 1632/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8501 - val_loss: 0.5031 - val_accuracy: 0.8319\n",
            "Epoch 1633/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8496 - val_loss: 0.4957 - val_accuracy: 0.8319\n",
            "Epoch 1634/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8472 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 1635/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8481 - val_loss: 0.4827 - val_accuracy: 0.8319\n",
            "Epoch 1636/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8494 - val_loss: 0.4821 - val_accuracy: 0.8319\n",
            "Epoch 1637/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8483 - val_loss: 0.5025 - val_accuracy: 0.8319\n",
            "Epoch 1638/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8481 - val_loss: 0.4778 - val_accuracy: 0.8330\n",
            "Epoch 1639/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8497 - val_loss: 0.5048 - val_accuracy: 0.8297\n",
            "Epoch 1640/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8478 - val_loss: 0.4832 - val_accuracy: 0.8319\n",
            "Epoch 1641/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8501 - val_loss: 0.4972 - val_accuracy: 0.8319\n",
            "Epoch 1642/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8490 - val_loss: 0.4854 - val_accuracy: 0.8330\n",
            "Epoch 1643/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8488 - val_loss: 0.4905 - val_accuracy: 0.8319\n",
            "Epoch 1644/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8485 - val_loss: 0.4899 - val_accuracy: 0.8330\n",
            "Epoch 1645/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8492 - val_loss: 0.5018 - val_accuracy: 0.8319\n",
            "Epoch 1646/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8488 - val_loss: 0.4943 - val_accuracy: 0.8319\n",
            "Epoch 1647/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8508 - val_loss: 0.5039 - val_accuracy: 0.8319\n",
            "Epoch 1648/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8483 - val_loss: 0.4835 - val_accuracy: 0.8330\n",
            "Epoch 1649/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8481 - val_loss: 0.4911 - val_accuracy: 0.8319\n",
            "Epoch 1650/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8494 - val_loss: 0.5045 - val_accuracy: 0.8319\n",
            "Epoch 1651/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8467 - val_loss: 0.4816 - val_accuracy: 0.8330\n",
            "Epoch 1652/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8481 - val_loss: 0.4942 - val_accuracy: 0.8319\n",
            "Epoch 1653/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8490 - val_loss: 0.4891 - val_accuracy: 0.8330\n",
            "Epoch 1654/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8503 - val_loss: 0.4895 - val_accuracy: 0.8330\n",
            "Epoch 1655/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8470 - val_loss: 0.4761 - val_accuracy: 0.8341\n",
            "Epoch 1656/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8499 - val_loss: 0.4967 - val_accuracy: 0.8319\n",
            "Epoch 1657/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8494 - val_loss: 0.5132 - val_accuracy: 0.8297\n",
            "Epoch 1658/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8487 - val_loss: 0.5046 - val_accuracy: 0.8308\n",
            "Epoch 1659/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8478 - val_loss: 0.4929 - val_accuracy: 0.8330\n",
            "Epoch 1660/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8481 - val_loss: 0.4967 - val_accuracy: 0.8319\n",
            "Epoch 1661/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8501 - val_loss: 0.5074 - val_accuracy: 0.8308\n",
            "Epoch 1662/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8479 - val_loss: 0.4902 - val_accuracy: 0.8330\n",
            "Epoch 1663/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8497 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1664/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8501 - val_loss: 0.5159 - val_accuracy: 0.8297\n",
            "Epoch 1665/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8487 - val_loss: 0.4970 - val_accuracy: 0.8330\n",
            "Epoch 1666/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8487 - val_loss: 0.4888 - val_accuracy: 0.8330\n",
            "Epoch 1667/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8478 - val_loss: 0.4742 - val_accuracy: 0.8330\n",
            "Epoch 1668/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8479 - val_loss: 0.4753 - val_accuracy: 0.8341\n",
            "Epoch 1669/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8478 - val_loss: 0.4794 - val_accuracy: 0.8319\n",
            "Epoch 1670/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8487 - val_loss: 0.4891 - val_accuracy: 0.8330\n",
            "Epoch 1671/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8497 - val_loss: 0.4911 - val_accuracy: 0.8330\n",
            "Epoch 1672/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8487 - val_loss: 0.4844 - val_accuracy: 0.8330\n",
            "Epoch 1673/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8496 - val_loss: 0.4989 - val_accuracy: 0.8319\n",
            "Epoch 1674/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8497 - val_loss: 0.4801 - val_accuracy: 0.8319\n",
            "Epoch 1675/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8496 - val_loss: 0.4880 - val_accuracy: 0.8330\n",
            "Epoch 1676/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8494 - val_loss: 0.4927 - val_accuracy: 0.8319\n",
            "Epoch 1677/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8472 - val_loss: 0.4798 - val_accuracy: 0.8330\n",
            "Epoch 1678/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8488 - val_loss: 0.4945 - val_accuracy: 0.8330\n",
            "Epoch 1679/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8479 - val_loss: 0.5093 - val_accuracy: 0.8297\n",
            "Epoch 1680/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8503 - val_loss: 0.4958 - val_accuracy: 0.8330\n",
            "Epoch 1681/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8499 - val_loss: 0.4990 - val_accuracy: 0.8319\n",
            "Epoch 1682/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8490 - val_loss: 0.5038 - val_accuracy: 0.8308\n",
            "Epoch 1683/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8487 - val_loss: 0.5014 - val_accuracy: 0.8319\n",
            "Epoch 1684/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8476 - val_loss: 0.4886 - val_accuracy: 0.8330\n",
            "Epoch 1685/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8483 - val_loss: 0.4763 - val_accuracy: 0.8330\n",
            "Epoch 1686/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8492 - val_loss: 0.4934 - val_accuracy: 0.8330\n",
            "Epoch 1687/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8488 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1688/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8497 - val_loss: 0.5038 - val_accuracy: 0.8319\n",
            "Epoch 1689/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8481 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1690/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8469 - val_loss: 0.4751 - val_accuracy: 0.8341\n",
            "Epoch 1691/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8496 - val_loss: 0.4961 - val_accuracy: 0.8319\n",
            "Epoch 1692/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8481 - val_loss: 0.4931 - val_accuracy: 0.8330\n",
            "Epoch 1693/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8487 - val_loss: 0.4864 - val_accuracy: 0.8341\n",
            "Epoch 1694/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8490 - val_loss: 0.4898 - val_accuracy: 0.8330\n",
            "Epoch 1695/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8469 - val_loss: 0.4841 - val_accuracy: 0.8330\n",
            "Epoch 1696/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8490 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1697/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8503 - val_loss: 0.5012 - val_accuracy: 0.8319\n",
            "Epoch 1698/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8499 - val_loss: 0.5104 - val_accuracy: 0.8308\n",
            "Epoch 1699/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8483 - val_loss: 0.5073 - val_accuracy: 0.8297\n",
            "Epoch 1700/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8479 - val_loss: 0.4847 - val_accuracy: 0.8330\n",
            "Epoch 1701/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8483 - val_loss: 0.4920 - val_accuracy: 0.8330\n",
            "Epoch 1702/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8497 - val_loss: 0.4906 - val_accuracy: 0.8330\n",
            "Epoch 1703/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8481 - val_loss: 0.4818 - val_accuracy: 0.8341\n",
            "Epoch 1704/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8488 - val_loss: 0.4866 - val_accuracy: 0.8330\n",
            "Epoch 1705/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8474 - val_loss: 0.4863 - val_accuracy: 0.8330\n",
            "Epoch 1706/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8492 - val_loss: 0.4936 - val_accuracy: 0.8330\n",
            "Epoch 1707/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8492 - val_loss: 0.5027 - val_accuracy: 0.8319\n",
            "Epoch 1708/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8479 - val_loss: 0.4847 - val_accuracy: 0.8330\n",
            "Epoch 1709/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8496 - val_loss: 0.4878 - val_accuracy: 0.8330\n",
            "Epoch 1710/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8497 - val_loss: 0.5024 - val_accuracy: 0.8308\n",
            "Epoch 1711/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8479 - val_loss: 0.4931 - val_accuracy: 0.8330\n",
            "Epoch 1712/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8501 - val_loss: 0.4941 - val_accuracy: 0.8330\n",
            "Epoch 1713/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8499 - val_loss: 0.5069 - val_accuracy: 0.8319\n",
            "Epoch 1714/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8485 - val_loss: 0.5071 - val_accuracy: 0.8297\n",
            "Epoch 1715/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8490 - val_loss: 0.4824 - val_accuracy: 0.8330\n",
            "Epoch 1716/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.4949 - val_accuracy: 0.8330\n",
            "Epoch 1717/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8496 - val_loss: 0.4941 - val_accuracy: 0.8319\n",
            "Epoch 1718/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8478 - val_loss: 0.4729 - val_accuracy: 0.8341\n",
            "Epoch 1719/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8485 - val_loss: 0.4841 - val_accuracy: 0.8330\n",
            "Epoch 1720/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.4997 - val_accuracy: 0.8319\n",
            "Epoch 1721/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8494 - val_loss: 0.5053 - val_accuracy: 0.8297\n",
            "Epoch 1722/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8481 - val_loss: 0.5028 - val_accuracy: 0.8319\n",
            "Epoch 1723/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8487 - val_loss: 0.5053 - val_accuracy: 0.8319\n",
            "Epoch 1724/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8496 - val_loss: 0.4730 - val_accuracy: 0.8330\n",
            "Epoch 1725/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8474 - val_loss: 0.4763 - val_accuracy: 0.8330\n",
            "Epoch 1726/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8499 - val_loss: 0.4907 - val_accuracy: 0.8330\n",
            "Epoch 1727/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8503 - val_loss: 0.5111 - val_accuracy: 0.8308\n",
            "Epoch 1728/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8485 - val_loss: 0.4950 - val_accuracy: 0.8319\n",
            "Epoch 1729/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8501 - val_loss: 0.5002 - val_accuracy: 0.8319\n",
            "Epoch 1730/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3278 - accuracy: 0.8458 - val_loss: 0.4895 - val_accuracy: 0.8319\n",
            "Epoch 1731/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8494 - val_loss: 0.4929 - val_accuracy: 0.8330\n",
            "Epoch 1732/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8485 - val_loss: 0.4791 - val_accuracy: 0.8330\n",
            "Epoch 1733/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8494 - val_loss: 0.4945 - val_accuracy: 0.8330\n",
            "Epoch 1734/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8497 - val_loss: 0.5013 - val_accuracy: 0.8319\n",
            "Epoch 1735/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8483 - val_loss: 0.4826 - val_accuracy: 0.8330\n",
            "Epoch 1736/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8496 - val_loss: 0.5007 - val_accuracy: 0.8319\n",
            "Epoch 1737/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8503 - val_loss: 0.5044 - val_accuracy: 0.8308\n",
            "Epoch 1738/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8479 - val_loss: 0.4967 - val_accuracy: 0.8330\n",
            "Epoch 1739/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8487 - val_loss: 0.4926 - val_accuracy: 0.8330\n",
            "Epoch 1740/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8481 - val_loss: 0.4982 - val_accuracy: 0.8319\n",
            "Epoch 1741/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8492 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1742/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8479 - val_loss: 0.5023 - val_accuracy: 0.8319\n",
            "Epoch 1743/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8506 - val_loss: 0.5006 - val_accuracy: 0.8319\n",
            "Epoch 1744/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8485 - val_loss: 0.4831 - val_accuracy: 0.8330\n",
            "Epoch 1745/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8472 - val_loss: 0.4748 - val_accuracy: 0.8352\n",
            "Epoch 1746/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8474 - val_loss: 0.4846 - val_accuracy: 0.8330\n",
            "Epoch 1747/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8503 - val_loss: 0.5099 - val_accuracy: 0.8297\n",
            "Epoch 1748/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.4867 - val_accuracy: 0.8330\n",
            "Epoch 1749/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8487 - val_loss: 0.4822 - val_accuracy: 0.8330\n",
            "Epoch 1750/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8494 - val_loss: 0.4894 - val_accuracy: 0.8330\n",
            "Epoch 1751/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8496 - val_loss: 0.4955 - val_accuracy: 0.8330\n",
            "Epoch 1752/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8474 - val_loss: 0.4742 - val_accuracy: 0.8341\n",
            "Epoch 1753/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 0.8481 - val_loss: 0.4906 - val_accuracy: 0.8330\n",
            "Epoch 1754/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8492 - val_loss: 0.4865 - val_accuracy: 0.8330\n",
            "Epoch 1755/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8481 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1756/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.8479 - val_loss: 0.4680 - val_accuracy: 0.8396\n",
            "Epoch 1757/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8492 - val_loss: 0.4872 - val_accuracy: 0.8330\n",
            "Epoch 1758/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8510 - val_loss: 0.5101 - val_accuracy: 0.8297\n",
            "Epoch 1759/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8483 - val_loss: 0.5039 - val_accuracy: 0.8319\n",
            "Epoch 1760/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8467 - val_loss: 0.4958 - val_accuracy: 0.8319\n",
            "Epoch 1761/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8483 - val_loss: 0.4735 - val_accuracy: 0.8385\n",
            "Epoch 1762/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8508 - val_loss: 0.5048 - val_accuracy: 0.8319\n",
            "Epoch 1763/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8492 - val_loss: 0.5017 - val_accuracy: 0.8308\n",
            "Epoch 1764/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8483 - val_loss: 0.5006 - val_accuracy: 0.8319\n",
            "Epoch 1765/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8487 - val_loss: 0.4957 - val_accuracy: 0.8330\n",
            "Epoch 1766/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8488 - val_loss: 0.5080 - val_accuracy: 0.8297\n",
            "Epoch 1767/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8481 - val_loss: 0.4813 - val_accuracy: 0.8341\n",
            "Epoch 1768/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8474 - val_loss: 0.4981 - val_accuracy: 0.8319\n",
            "Epoch 1769/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8503 - val_loss: 0.5013 - val_accuracy: 0.8319\n",
            "Epoch 1770/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8497 - val_loss: 0.4899 - val_accuracy: 0.8330\n",
            "Epoch 1771/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8494 - val_loss: 0.4988 - val_accuracy: 0.8319\n",
            "Epoch 1772/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8478 - val_loss: 0.4800 - val_accuracy: 0.8330\n",
            "Epoch 1773/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8503 - val_loss: 0.4978 - val_accuracy: 0.8330\n",
            "Epoch 1774/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8492 - val_loss: 0.4805 - val_accuracy: 0.8330\n",
            "Epoch 1775/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8487 - val_loss: 0.4821 - val_accuracy: 0.8341\n",
            "Epoch 1776/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8510 - val_loss: 0.5048 - val_accuracy: 0.8319\n",
            "Epoch 1777/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3279 - accuracy: 0.8485 - val_loss: 0.4993 - val_accuracy: 0.8319\n",
            "Epoch 1778/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8496 - val_loss: 0.4938 - val_accuracy: 0.8330\n",
            "Epoch 1779/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8488 - val_loss: 0.4878 - val_accuracy: 0.8341\n",
            "Epoch 1780/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8488 - val_loss: 0.4681 - val_accuracy: 0.8385\n",
            "Epoch 1781/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8513 - val_loss: 0.5036 - val_accuracy: 0.8319\n",
            "Epoch 1782/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8487 - val_loss: 0.4882 - val_accuracy: 0.8330\n",
            "Epoch 1783/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8497 - val_loss: 0.4789 - val_accuracy: 0.8341\n",
            "Epoch 1784/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8496 - val_loss: 0.5035 - val_accuracy: 0.8319\n",
            "Epoch 1785/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8490 - val_loss: 0.4933 - val_accuracy: 0.8330\n",
            "Epoch 1786/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8496 - val_loss: 0.4926 - val_accuracy: 0.8330\n",
            "Epoch 1787/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8496 - val_loss: 0.5039 - val_accuracy: 0.8308\n",
            "Epoch 1788/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8496 - val_loss: 0.4933 - val_accuracy: 0.8330\n",
            "Epoch 1789/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3264 - accuracy: 0.8494 - val_loss: 0.4891 - val_accuracy: 0.8330\n",
            "Epoch 1790/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8510 - val_loss: 0.5046 - val_accuracy: 0.8319\n",
            "Epoch 1791/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8474 - val_loss: 0.4775 - val_accuracy: 0.8341\n",
            "Epoch 1792/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3277 - accuracy: 0.8497 - val_loss: 0.4964 - val_accuracy: 0.8330\n",
            "Epoch 1793/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8485 - val_loss: 0.4843 - val_accuracy: 0.8341\n",
            "Epoch 1794/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8497 - val_loss: 0.4941 - val_accuracy: 0.8330\n",
            "Epoch 1795/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8487 - val_loss: 0.4874 - val_accuracy: 0.8330\n",
            "Epoch 1796/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8499 - val_loss: 0.5021 - val_accuracy: 0.8319\n",
            "Epoch 1797/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8492 - val_loss: 0.4947 - val_accuracy: 0.8319\n",
            "Epoch 1798/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8481 - val_loss: 0.4857 - val_accuracy: 0.8330\n",
            "Epoch 1799/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8497 - val_loss: 0.4957 - val_accuracy: 0.8319\n",
            "Epoch 1800/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8479 - val_loss: 0.5006 - val_accuracy: 0.8319\n",
            "Epoch 1801/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8494 - val_loss: 0.5006 - val_accuracy: 0.8330\n",
            "Epoch 1802/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3267 - accuracy: 0.8496 - val_loss: 0.5042 - val_accuracy: 0.8308\n",
            "Epoch 1803/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8497 - val_loss: 0.5116 - val_accuracy: 0.8297\n",
            "Epoch 1804/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8479 - val_loss: 0.4834 - val_accuracy: 0.8330\n",
            "Epoch 1805/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3276 - accuracy: 0.8494 - val_loss: 0.4767 - val_accuracy: 0.8352\n",
            "Epoch 1806/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8494 - val_loss: 0.4837 - val_accuracy: 0.8330\n",
            "Epoch 1807/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8504 - val_loss: 0.5005 - val_accuracy: 0.8319\n",
            "Epoch 1808/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8492 - val_loss: 0.4952 - val_accuracy: 0.8330\n",
            "Epoch 1809/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8492 - val_loss: 0.4945 - val_accuracy: 0.8330\n",
            "Epoch 1810/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8501 - val_loss: 0.5135 - val_accuracy: 0.8308\n",
            "Epoch 1811/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8481 - val_loss: 0.5094 - val_accuracy: 0.8297\n",
            "Epoch 1812/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8479 - val_loss: 0.5027 - val_accuracy: 0.8319\n",
            "Epoch 1813/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8515 - val_loss: 0.5185 - val_accuracy: 0.8297\n",
            "Epoch 1814/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8476 - val_loss: 0.4908 - val_accuracy: 0.8330\n",
            "Epoch 1815/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8492 - val_loss: 0.4870 - val_accuracy: 0.8330\n",
            "Epoch 1816/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8490 - val_loss: 0.4914 - val_accuracy: 0.8330\n",
            "Epoch 1817/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8494 - val_loss: 0.4875 - val_accuracy: 0.8330\n",
            "Epoch 1818/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8485 - val_loss: 0.4827 - val_accuracy: 0.8341\n",
            "Epoch 1819/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8501 - val_loss: 0.5069 - val_accuracy: 0.8308\n",
            "Epoch 1820/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8490 - val_loss: 0.5061 - val_accuracy: 0.8319\n",
            "Epoch 1821/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3264 - accuracy: 0.8488 - val_loss: 0.4810 - val_accuracy: 0.8330\n",
            "Epoch 1822/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8481 - val_loss: 0.4752 - val_accuracy: 0.8352\n",
            "Epoch 1823/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8501 - val_loss: 0.5041 - val_accuracy: 0.8319\n",
            "Epoch 1824/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8506 - val_loss: 0.5136 - val_accuracy: 0.8297\n",
            "Epoch 1825/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8470 - val_loss: 0.4864 - val_accuracy: 0.8330\n",
            "Epoch 1826/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8499 - val_loss: 0.4815 - val_accuracy: 0.8330\n",
            "Epoch 1827/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3271 - accuracy: 0.8478 - val_loss: 0.4837 - val_accuracy: 0.8330\n",
            "Epoch 1828/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8503 - val_loss: 0.5039 - val_accuracy: 0.8319\n",
            "Epoch 1829/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8499 - val_loss: 0.5175 - val_accuracy: 0.8297\n",
            "Epoch 1830/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8494 - val_loss: 0.5006 - val_accuracy: 0.8319\n",
            "Epoch 1831/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8465 - val_loss: 0.4760 - val_accuracy: 0.8341\n",
            "Epoch 1832/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8479 - val_loss: 0.4816 - val_accuracy: 0.8330\n",
            "Epoch 1833/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8492 - val_loss: 0.4811 - val_accuracy: 0.8319\n",
            "Epoch 1834/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8481 - val_loss: 0.4726 - val_accuracy: 0.8363\n",
            "Epoch 1835/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3278 - accuracy: 0.8494 - val_loss: 0.4789 - val_accuracy: 0.8341\n",
            "Epoch 1836/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3279 - accuracy: 0.8497 - val_loss: 0.4788 - val_accuracy: 0.8319\n",
            "Epoch 1837/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8490 - val_loss: 0.5019 - val_accuracy: 0.8319\n",
            "Epoch 1838/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8487 - val_loss: 0.4938 - val_accuracy: 0.8330\n",
            "Epoch 1839/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8499 - val_loss: 0.4970 - val_accuracy: 0.8330\n",
            "Epoch 1840/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8490 - val_loss: 0.4964 - val_accuracy: 0.8330\n",
            "Epoch 1841/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8488 - val_loss: 0.4940 - val_accuracy: 0.8330\n",
            "Epoch 1842/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8494 - val_loss: 0.4825 - val_accuracy: 0.8330\n",
            "Epoch 1843/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3267 - accuracy: 0.8492 - val_loss: 0.4923 - val_accuracy: 0.8330\n",
            "Epoch 1844/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.8503 - val_loss: 0.4999 - val_accuracy: 0.8319\n",
            "Epoch 1845/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8490 - val_loss: 0.4935 - val_accuracy: 0.8330\n",
            "Epoch 1846/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8513 - val_loss: 0.5105 - val_accuracy: 0.8308\n",
            "Epoch 1847/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.8472 - val_loss: 0.4869 - val_accuracy: 0.8330\n",
            "Epoch 1848/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8499 - val_loss: 0.4849 - val_accuracy: 0.8341\n",
            "Epoch 1849/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8497 - val_loss: 0.4897 - val_accuracy: 0.8330\n",
            "Epoch 1850/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8488 - val_loss: 0.5096 - val_accuracy: 0.8319\n",
            "Epoch 1851/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8492 - val_loss: 0.4909 - val_accuracy: 0.8330\n",
            "Epoch 1852/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8487 - val_loss: 0.4881 - val_accuracy: 0.8330\n",
            "Epoch 1853/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8490 - val_loss: 0.4845 - val_accuracy: 0.8341\n",
            "Epoch 1854/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8488 - val_loss: 0.4949 - val_accuracy: 0.8319\n",
            "Epoch 1855/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8499 - val_loss: 0.4999 - val_accuracy: 0.8330\n",
            "Epoch 1856/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8496 - val_loss: 0.4998 - val_accuracy: 0.8319\n",
            "Epoch 1857/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8470 - val_loss: 0.4828 - val_accuracy: 0.8341\n",
            "Epoch 1858/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8483 - val_loss: 0.4959 - val_accuracy: 0.8319\n",
            "Epoch 1859/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8501 - val_loss: 0.4884 - val_accuracy: 0.8330\n",
            "Epoch 1860/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8490 - val_loss: 0.4887 - val_accuracy: 0.8330\n",
            "Epoch 1861/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8492 - val_loss: 0.4821 - val_accuracy: 0.8330\n",
            "Epoch 1862/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.8503 - val_loss: 0.4951 - val_accuracy: 0.8330\n",
            "Epoch 1863/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8496 - val_loss: 0.4851 - val_accuracy: 0.8341\n",
            "Epoch 1864/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8497 - val_loss: 0.5125 - val_accuracy: 0.8297\n",
            "Epoch 1865/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8494 - val_loss: 0.5147 - val_accuracy: 0.8297\n",
            "Epoch 1866/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8492 - val_loss: 0.4826 - val_accuracy: 0.8330\n",
            "Epoch 1867/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3269 - accuracy: 0.8497 - val_loss: 0.4978 - val_accuracy: 0.8330\n",
            "Epoch 1868/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8485 - val_loss: 0.4838 - val_accuracy: 0.8341\n",
            "Epoch 1869/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8508 - val_loss: 0.5087 - val_accuracy: 0.8308\n",
            "Epoch 1870/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8481 - val_loss: 0.5032 - val_accuracy: 0.8308\n",
            "Epoch 1871/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8492 - val_loss: 0.5077 - val_accuracy: 0.8308\n",
            "Epoch 1872/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8496 - val_loss: 0.5117 - val_accuracy: 0.8297\n",
            "Epoch 1873/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8481 - val_loss: 0.4955 - val_accuracy: 0.8330\n",
            "Epoch 1874/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8504 - val_loss: 0.4900 - val_accuracy: 0.8330\n",
            "Epoch 1875/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8494 - val_loss: 0.4959 - val_accuracy: 0.8330\n",
            "Epoch 1876/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8496 - val_loss: 0.4856 - val_accuracy: 0.8330\n",
            "Epoch 1877/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8487 - val_loss: 0.4922 - val_accuracy: 0.8330\n",
            "Epoch 1878/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8479 - val_loss: 0.4675 - val_accuracy: 0.8385\n",
            "Epoch 1879/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8503 - val_loss: 0.4896 - val_accuracy: 0.8341\n",
            "Epoch 1880/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8494 - val_loss: 0.5094 - val_accuracy: 0.8308\n",
            "Epoch 1881/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8496 - val_loss: 0.4979 - val_accuracy: 0.8319\n",
            "Epoch 1882/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8478 - val_loss: 0.4987 - val_accuracy: 0.8330\n",
            "Epoch 1883/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8496 - val_loss: 0.4822 - val_accuracy: 0.8330\n",
            "Epoch 1884/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8488 - val_loss: 0.4955 - val_accuracy: 0.8330\n",
            "Epoch 1885/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8496 - val_loss: 0.5033 - val_accuracy: 0.8319\n",
            "Epoch 1886/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8488 - val_loss: 0.4948 - val_accuracy: 0.8330\n",
            "Epoch 1887/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3264 - accuracy: 0.8494 - val_loss: 0.4906 - val_accuracy: 0.8330\n",
            "Epoch 1888/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8488 - val_loss: 0.4948 - val_accuracy: 0.8330\n",
            "Epoch 1889/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.8492 - val_loss: 0.4889 - val_accuracy: 0.8330\n",
            "Epoch 1890/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3263 - accuracy: 0.8497 - val_loss: 0.4968 - val_accuracy: 0.8330\n",
            "Epoch 1891/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3268 - accuracy: 0.8499 - val_loss: 0.4987 - val_accuracy: 0.8330\n",
            "Epoch 1892/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8499 - val_loss: 0.4877 - val_accuracy: 0.8330\n",
            "Epoch 1893/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3263 - accuracy: 0.8497 - val_loss: 0.4962 - val_accuracy: 0.8330\n",
            "Epoch 1894/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8490 - val_loss: 0.4959 - val_accuracy: 0.8330\n",
            "Epoch 1895/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8490 - val_loss: 0.4905 - val_accuracy: 0.8330\n",
            "Epoch 1896/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8485 - val_loss: 0.5034 - val_accuracy: 0.8319\n",
            "Epoch 1897/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8492 - val_loss: 0.4852 - val_accuracy: 0.8330\n",
            "Epoch 1898/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8494 - val_loss: 0.5002 - val_accuracy: 0.8319\n",
            "Epoch 1899/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3275 - accuracy: 0.8490 - val_loss: 0.5087 - val_accuracy: 0.8308\n",
            "Epoch 1900/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8492 - val_loss: 0.4947 - val_accuracy: 0.8330\n",
            "Epoch 1901/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8488 - val_loss: 0.5034 - val_accuracy: 0.8319\n",
            "Epoch 1902/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.8492 - val_loss: 0.5032 - val_accuracy: 0.8319\n",
            "Epoch 1903/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8497 - val_loss: 0.5011 - val_accuracy: 0.8319\n",
            "Epoch 1904/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8478 - val_loss: 0.4768 - val_accuracy: 0.8352\n",
            "Epoch 1905/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8515 - val_loss: 0.5122 - val_accuracy: 0.8308\n",
            "Epoch 1906/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8481 - val_loss: 0.4918 - val_accuracy: 0.8330\n",
            "Epoch 1907/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8492 - val_loss: 0.4865 - val_accuracy: 0.8330\n",
            "Epoch 1908/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8479 - val_loss: 0.4875 - val_accuracy: 0.8341\n",
            "Epoch 1909/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8501 - val_loss: 0.4851 - val_accuracy: 0.8341\n",
            "Epoch 1910/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3259 - accuracy: 0.8499 - val_loss: 0.5039 - val_accuracy: 0.8319\n",
            "Epoch 1911/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8497 - val_loss: 0.4986 - val_accuracy: 0.8330\n",
            "Epoch 1912/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8487 - val_loss: 0.4886 - val_accuracy: 0.8341\n",
            "Epoch 1913/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8492 - val_loss: 0.4977 - val_accuracy: 0.8330\n",
            "Epoch 1914/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8488 - val_loss: 0.4798 - val_accuracy: 0.8341\n",
            "Epoch 1915/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.8487 - val_loss: 0.4801 - val_accuracy: 0.8330\n",
            "Epoch 1916/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8503 - val_loss: 0.4912 - val_accuracy: 0.8341\n",
            "Epoch 1917/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8487 - val_loss: 0.4732 - val_accuracy: 0.8352\n",
            "Epoch 1918/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3274 - accuracy: 0.8490 - val_loss: 0.4748 - val_accuracy: 0.8352\n",
            "Epoch 1919/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8501 - val_loss: 0.5037 - val_accuracy: 0.8308\n",
            "Epoch 1920/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3264 - accuracy: 0.8488 - val_loss: 0.4863 - val_accuracy: 0.8341\n",
            "Epoch 1921/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3265 - accuracy: 0.8488 - val_loss: 0.4899 - val_accuracy: 0.8330\n",
            "Epoch 1922/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8494 - val_loss: 0.4967 - val_accuracy: 0.8330\n",
            "Epoch 1923/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8494 - val_loss: 0.5183 - val_accuracy: 0.8308\n",
            "Epoch 1924/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3276 - accuracy: 0.8503 - val_loss: 0.5048 - val_accuracy: 0.8319\n",
            "Epoch 1925/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8479 - val_loss: 0.5072 - val_accuracy: 0.8308\n",
            "Epoch 1926/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8478 - val_loss: 0.5074 - val_accuracy: 0.8308\n",
            "Epoch 1927/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8492 - val_loss: 0.5053 - val_accuracy: 0.8297\n",
            "Epoch 1928/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3263 - accuracy: 0.8479 - val_loss: 0.4914 - val_accuracy: 0.8341\n",
            "Epoch 1929/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8490 - val_loss: 0.4941 - val_accuracy: 0.8341\n",
            "Epoch 1930/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.8504 - val_loss: 0.5078 - val_accuracy: 0.8308\n",
            "Epoch 1931/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8487 - val_loss: 0.4815 - val_accuracy: 0.8341\n",
            "Epoch 1932/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.8503 - val_loss: 0.4858 - val_accuracy: 0.8341\n",
            "Epoch 1933/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.8490 - val_loss: 0.4863 - val_accuracy: 0.8341\n",
            "Epoch 1934/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3272 - accuracy: 0.8496 - val_loss: 0.4953 - val_accuracy: 0.8330\n",
            "Epoch 1935/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.8508 - val_loss: 0.5115 - val_accuracy: 0.8308\n",
            "Epoch 1936/2000\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.8494 - val_loss: 0.5046 - val_accuracy: 0.8308\n",
            "Epoch 1937/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8485 - val_loss: 0.4972 - val_accuracy: 0.8319\n",
            "Epoch 1938/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3267 - accuracy: 0.8490 - val_loss: 0.4803 - val_accuracy: 0.8341\n",
            "Epoch 1939/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8501 - val_loss: 0.4913 - val_accuracy: 0.8330\n",
            "Epoch 1940/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8494 - val_loss: 0.5003 - val_accuracy: 0.8319\n",
            "Epoch 1941/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8492 - val_loss: 0.5012 - val_accuracy: 0.8330\n",
            "Epoch 1942/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8492 - val_loss: 0.4944 - val_accuracy: 0.8330\n",
            "Epoch 1943/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8487 - val_loss: 0.4844 - val_accuracy: 0.8341\n",
            "Epoch 1944/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8497 - val_loss: 0.4800 - val_accuracy: 0.8330\n",
            "Epoch 1945/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8488 - val_loss: 0.4888 - val_accuracy: 0.8341\n",
            "Epoch 1946/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3259 - accuracy: 0.8504 - val_loss: 0.4918 - val_accuracy: 0.8341\n",
            "Epoch 1947/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8488 - val_loss: 0.4855 - val_accuracy: 0.8341\n",
            "Epoch 1948/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3268 - accuracy: 0.8506 - val_loss: 0.4906 - val_accuracy: 0.8341\n",
            "Epoch 1949/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8504 - val_loss: 0.5098 - val_accuracy: 0.8308\n",
            "Epoch 1950/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8478 - val_loss: 0.5002 - val_accuracy: 0.8330\n",
            "Epoch 1951/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8481 - val_loss: 0.4700 - val_accuracy: 0.8418\n",
            "Epoch 1952/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8487 - val_loss: 0.4775 - val_accuracy: 0.8330\n",
            "Epoch 1953/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8497 - val_loss: 0.4905 - val_accuracy: 0.8341\n",
            "Epoch 1954/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8492 - val_loss: 0.4878 - val_accuracy: 0.8330\n",
            "Epoch 1955/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8492 - val_loss: 0.4886 - val_accuracy: 0.8341\n",
            "Epoch 1956/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8496 - val_loss: 0.5077 - val_accuracy: 0.8308\n",
            "Epoch 1957/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8503 - val_loss: 0.5298 - val_accuracy: 0.8308\n",
            "Epoch 1958/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3280 - accuracy: 0.8483 - val_loss: 0.4960 - val_accuracy: 0.8330\n",
            "Epoch 1959/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8488 - val_loss: 0.4934 - val_accuracy: 0.8330\n",
            "Epoch 1960/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8485 - val_loss: 0.4906 - val_accuracy: 0.8330\n",
            "Epoch 1961/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8481 - val_loss: 0.4751 - val_accuracy: 0.8363\n",
            "Epoch 1962/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8494 - val_loss: 0.4850 - val_accuracy: 0.8352\n",
            "Epoch 1963/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8499 - val_loss: 0.4983 - val_accuracy: 0.8330\n",
            "Epoch 1964/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8504 - val_loss: 0.4971 - val_accuracy: 0.8319\n",
            "Epoch 1965/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8490 - val_loss: 0.5242 - val_accuracy: 0.8308\n",
            "Epoch 1966/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3273 - accuracy: 0.8481 - val_loss: 0.4942 - val_accuracy: 0.8341\n",
            "Epoch 1967/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8490 - val_loss: 0.4865 - val_accuracy: 0.8330\n",
            "Epoch 1968/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8508 - val_loss: 0.4882 - val_accuracy: 0.8341\n",
            "Epoch 1969/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3263 - accuracy: 0.8492 - val_loss: 0.5023 - val_accuracy: 0.8308\n",
            "Epoch 1970/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3265 - accuracy: 0.8487 - val_loss: 0.4752 - val_accuracy: 0.8374\n",
            "Epoch 1971/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3255 - accuracy: 0.8506 - val_loss: 0.5078 - val_accuracy: 0.8308\n",
            "Epoch 1972/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3271 - accuracy: 0.8490 - val_loss: 0.5083 - val_accuracy: 0.8308\n",
            "Epoch 1973/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.8494 - val_loss: 0.5148 - val_accuracy: 0.8297\n",
            "Epoch 1974/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8485 - val_loss: 0.4981 - val_accuracy: 0.8330\n",
            "Epoch 1975/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3266 - accuracy: 0.8481 - val_loss: 0.4929 - val_accuracy: 0.8341\n",
            "Epoch 1976/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8494 - val_loss: 0.4787 - val_accuracy: 0.8330\n",
            "Epoch 1977/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3289 - accuracy: 0.8488 - val_loss: 0.4688 - val_accuracy: 0.8385\n",
            "Epoch 1978/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3313 - accuracy: 0.8503 - val_loss: 0.5164 - val_accuracy: 0.8297\n",
            "Epoch 1979/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3268 - accuracy: 0.8488 - val_loss: 0.4991 - val_accuracy: 0.8319\n",
            "Epoch 1980/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8504 - val_loss: 0.5085 - val_accuracy: 0.8308\n",
            "Epoch 1981/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8490 - val_loss: 0.4892 - val_accuracy: 0.8330\n",
            "Epoch 1982/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8497 - val_loss: 0.4938 - val_accuracy: 0.8341\n",
            "Epoch 1983/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8496 - val_loss: 0.4984 - val_accuracy: 0.8319\n",
            "Epoch 1984/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8485 - val_loss: 0.4929 - val_accuracy: 0.8341\n",
            "Epoch 1985/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8469 - val_loss: 0.4716 - val_accuracy: 0.8385\n",
            "Epoch 1986/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8488 - val_loss: 0.4875 - val_accuracy: 0.8341\n",
            "Epoch 1987/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3261 - accuracy: 0.8506 - val_loss: 0.4998 - val_accuracy: 0.8330\n",
            "Epoch 1988/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3263 - accuracy: 0.8485 - val_loss: 0.4806 - val_accuracy: 0.8341\n",
            "Epoch 1989/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8492 - val_loss: 0.4834 - val_accuracy: 0.8341\n",
            "Epoch 1990/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3263 - accuracy: 0.8488 - val_loss: 0.4820 - val_accuracy: 0.8341\n",
            "Epoch 1991/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3261 - accuracy: 0.8481 - val_loss: 0.4958 - val_accuracy: 0.8330\n",
            "Epoch 1992/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8501 - val_loss: 0.4963 - val_accuracy: 0.8341\n",
            "Epoch 1993/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8497 - val_loss: 0.4936 - val_accuracy: 0.8341\n",
            "Epoch 1994/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3259 - accuracy: 0.8476 - val_loss: 0.4751 - val_accuracy: 0.8352\n",
            "Epoch 1995/2000\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3270 - accuracy: 0.8488 - val_loss: 0.4828 - val_accuracy: 0.8330\n",
            "Epoch 1996/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8512 - val_loss: 0.4941 - val_accuracy: 0.8330\n",
            "Epoch 1997/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8496 - val_loss: 0.5053 - val_accuracy: 0.8319\n",
            "Epoch 1998/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8469 - val_loss: 0.4831 - val_accuracy: 0.8319\n",
            "Epoch 1999/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3258 - accuracy: 0.8501 - val_loss: 0.5038 - val_accuracy: 0.8319\n",
            "Epoch 2000/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3260 - accuracy: 0.8479 - val_loss: 0.4751 - val_accuracy: 0.8341\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f562c91e150>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr7wlfCAgwIZ",
        "outputId": "acf6e4b6-7ce4-4ec6-bcbb-2fd77f5e5142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 14)                126       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 7)                 105       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 239\n",
            "Trainable params: 239\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Z7nI97l6gwKl",
        "outputId": "bf17fb9d-0740-480c-de96-aae21d03c02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   loss  accuracy  val_loss  val_accuracy\n",
              "0 1.065     0.796     0.570         0.796\n",
              "1 0.821     0.796     0.542         0.796\n",
              "2 0.638     0.796     0.564         0.796\n",
              "3 0.552     0.796     0.603         0.796\n",
              "4 0.522     0.796     0.633         0.796"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6ad73c4-e2e9-4d62-a02a-796503de7702\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.065</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.570</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.821</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.542</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.638</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.552</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.603</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.522</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.633</td>\n",
              "      <td>0.796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6ad73c4-e2e9-4d62-a02a-796503de7702')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6ad73c4-e2e9-4d62-a02a-796503de7702 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6ad73c4-e2e9-4d62-a02a-796503de7702');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "fP-QzqZ0gwM3",
        "outputId": "50dda0c1-3736-44d9-d8dd-1e8d94e9b389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upWySqtdgwPB",
        "outputId": "611c10fe-9921-42f2-8fa2-35c7411693a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.4255635142326355\n",
            "accuracy :  0.8454285860061646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_F6jJadgwR0",
        "outputId": "50f4ef68-81dc-4ab7-885a-0413961f20e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2763   24]\n",
            " [ 517  196]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.99      0.91      2787\n",
            "           1       0.89      0.27      0.42       713\n",
            "\n",
            "    accuracy                           0.85      3500\n",
            "   macro avg       0.87      0.63      0.67      3500\n",
            "weighted avg       0.85      0.85      0.81      3500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EarlyStopping"
      ],
      "metadata": {
        "id": "XcKtRRpc1HAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarida olusturdugumuz modeli aynen kurup ek olarak early_stop ekleyip model performansina bakacagiz :"
      ],
      "metadata": {
        "id": "qU4_ZGdh1Jfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "hGSfY2OU1Nwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(14, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(7, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "lSvCnBhF1PMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The patience is often set somewhere between 10 and 100 (10 or 25 is more common), \n",
        "#but it really depends on your dataset and network."
      ],
      "metadata": {
        "id": "_Mt4C5eI1Sj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bir degisken icine bir object olusturarak EarlyStop fonksiyonunu tanimladik. EarlyStop yapmasi icin hangi veriyi takip etmesi gerektigini __monitor__ parametresi icine tanimladik (val_loss dedik, val_accuracy de diyebilirdik. Onemli olan validation datasinin aldigi skorlari takip etmek)."
      ],
      "metadata": {
        "id": "HlHSREn41Jky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__patience=25 --->__ 25 satir boyunca skorlar degismezse dur."
      ],
      "metadata": {
        "id": "-QiGARvs1JpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"auto\", verbose = 1, patience = 25)"
      ],
      "metadata": {
        "id": "OHNsRu-L1et9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stop ile modelimizi calistirdik :"
      ],
      "metadata": {
        "id": "ZrjxWL1J1hBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.14, batch_size = 260, epochs = 2000, verbose = 1,\n",
        "          callbacks = [early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxsvfMDU1i0c",
        "outputId": "04ac8e47-189c-4b4d-e788-78f74c205a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.5964 - accuracy: 0.7959 - val_loss: 0.5709 - val_accuracy: 0.7956\n",
            "Epoch 2/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.7964 - val_loss: 0.5372 - val_accuracy: 0.7956\n",
            "Epoch 3/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7964 - val_loss: 0.5229 - val_accuracy: 0.7956\n",
            "Epoch 4/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5148 - accuracy: 0.7964 - val_loss: 0.5122 - val_accuracy: 0.7956\n",
            "Epoch 5/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7964 - val_loss: 0.5044 - val_accuracy: 0.7956\n",
            "Epoch 6/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.7964 - val_loss: 0.4981 - val_accuracy: 0.7956\n",
            "Epoch 7/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7964 - val_loss: 0.4932 - val_accuracy: 0.7956\n",
            "Epoch 8/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7964 - val_loss: 0.4893 - val_accuracy: 0.7956\n",
            "Epoch 9/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7964 - val_loss: 0.4857 - val_accuracy: 0.7956\n",
            "Epoch 10/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7964 - val_loss: 0.4819 - val_accuracy: 0.7956\n",
            "Epoch 11/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.7964 - val_loss: 0.4787 - val_accuracy: 0.7956\n",
            "Epoch 12/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7964 - val_loss: 0.4753 - val_accuracy: 0.7956\n",
            "Epoch 13/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7964 - val_loss: 0.4716 - val_accuracy: 0.7956\n",
            "Epoch 14/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7964 - val_loss: 0.4675 - val_accuracy: 0.7956\n",
            "Epoch 15/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7964 - val_loss: 0.4641 - val_accuracy: 0.7967\n",
            "Epoch 16/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7979 - val_loss: 0.4615 - val_accuracy: 0.7967\n",
            "Epoch 17/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7989 - val_loss: 0.4585 - val_accuracy: 0.7989\n",
            "Epoch 18/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.8038 - val_loss: 0.4565 - val_accuracy: 0.7989\n",
            "Epoch 19/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8050 - val_loss: 0.4541 - val_accuracy: 0.8011\n",
            "Epoch 20/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8059 - val_loss: 0.4530 - val_accuracy: 0.8022\n",
            "Epoch 21/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8061 - val_loss: 0.4511 - val_accuracy: 0.8044\n",
            "Epoch 22/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8091 - val_loss: 0.4491 - val_accuracy: 0.8066\n",
            "Epoch 23/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8091 - val_loss: 0.4477 - val_accuracy: 0.8099\n",
            "Epoch 24/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8104 - val_loss: 0.4454 - val_accuracy: 0.8055\n",
            "Epoch 25/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8102 - val_loss: 0.4443 - val_accuracy: 0.8055\n",
            "Epoch 26/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8109 - val_loss: 0.4421 - val_accuracy: 0.8011\n",
            "Epoch 27/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8154 - val_loss: 0.4414 - val_accuracy: 0.8022\n",
            "Epoch 28/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8148 - val_loss: 0.4380 - val_accuracy: 0.8055\n",
            "Epoch 29/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8166 - val_loss: 0.4354 - val_accuracy: 0.8055\n",
            "Epoch 30/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8188 - val_loss: 0.4361 - val_accuracy: 0.8066\n",
            "Epoch 31/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4138 - accuracy: 0.8191 - val_loss: 0.4325 - val_accuracy: 0.8099\n",
            "Epoch 32/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8218 - val_loss: 0.4334 - val_accuracy: 0.8110\n",
            "Epoch 33/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.8229 - val_loss: 0.4270 - val_accuracy: 0.8154\n",
            "Epoch 34/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8249 - val_loss: 0.4257 - val_accuracy: 0.8187\n",
            "Epoch 35/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8263 - val_loss: 0.4235 - val_accuracy: 0.8242\n",
            "Epoch 36/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8293 - val_loss: 0.4217 - val_accuracy: 0.8264\n",
            "Epoch 37/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8304 - val_loss: 0.4195 - val_accuracy: 0.8275\n",
            "Epoch 38/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8324 - val_loss: 0.4178 - val_accuracy: 0.8253\n",
            "Epoch 39/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3956 - accuracy: 0.8351 - val_loss: 0.4164 - val_accuracy: 0.8275\n",
            "Epoch 40/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.8367 - val_loss: 0.4148 - val_accuracy: 0.8264\n",
            "Epoch 41/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3923 - accuracy: 0.8381 - val_loss: 0.4139 - val_accuracy: 0.8275\n",
            "Epoch 42/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8376 - val_loss: 0.4126 - val_accuracy: 0.8286\n",
            "Epoch 43/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8397 - val_loss: 0.4099 - val_accuracy: 0.8275\n",
            "Epoch 44/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3861 - accuracy: 0.8413 - val_loss: 0.4107 - val_accuracy: 0.8297\n",
            "Epoch 45/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8408 - val_loss: 0.4098 - val_accuracy: 0.8275\n",
            "Epoch 46/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8408 - val_loss: 0.4063 - val_accuracy: 0.8330\n",
            "Epoch 47/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3823 - accuracy: 0.8438 - val_loss: 0.4057 - val_accuracy: 0.8341\n",
            "Epoch 48/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3810 - accuracy: 0.8440 - val_loss: 0.4049 - val_accuracy: 0.8319\n",
            "Epoch 49/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3793 - accuracy: 0.8469 - val_loss: 0.4061 - val_accuracy: 0.8275\n",
            "Epoch 50/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3779 - accuracy: 0.8463 - val_loss: 0.4026 - val_accuracy: 0.8374\n",
            "Epoch 51/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8492 - val_loss: 0.4031 - val_accuracy: 0.8308\n",
            "Epoch 52/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3761 - accuracy: 0.8453 - val_loss: 0.4040 - val_accuracy: 0.8253\n",
            "Epoch 53/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8487 - val_loss: 0.4000 - val_accuracy: 0.8352\n",
            "Epoch 54/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8524 - val_loss: 0.4021 - val_accuracy: 0.8297\n",
            "Epoch 55/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8535 - val_loss: 0.3975 - val_accuracy: 0.8363\n",
            "Epoch 56/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3733 - accuracy: 0.8526 - val_loss: 0.3973 - val_accuracy: 0.8363\n",
            "Epoch 57/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8508 - val_loss: 0.3961 - val_accuracy: 0.8363\n",
            "Epoch 58/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3700 - accuracy: 0.8537 - val_loss: 0.3965 - val_accuracy: 0.8363\n",
            "Epoch 59/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.8540 - val_loss: 0.3947 - val_accuracy: 0.8385\n",
            "Epoch 60/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8540 - val_loss: 0.3958 - val_accuracy: 0.8352\n",
            "Epoch 61/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.8540 - val_loss: 0.3957 - val_accuracy: 0.8341\n",
            "Epoch 62/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8546 - val_loss: 0.3936 - val_accuracy: 0.8396\n",
            "Epoch 63/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8558 - val_loss: 0.3946 - val_accuracy: 0.8330\n",
            "Epoch 64/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3662 - accuracy: 0.8544 - val_loss: 0.3937 - val_accuracy: 0.8352\n",
            "Epoch 65/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3659 - accuracy: 0.8546 - val_loss: 0.3965 - val_accuracy: 0.8363\n",
            "Epoch 66/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8542 - val_loss: 0.3913 - val_accuracy: 0.8363\n",
            "Epoch 67/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3650 - accuracy: 0.8558 - val_loss: 0.3912 - val_accuracy: 0.8407\n",
            "Epoch 68/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8560 - val_loss: 0.3906 - val_accuracy: 0.8363\n",
            "Epoch 69/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3637 - accuracy: 0.8565 - val_loss: 0.3905 - val_accuracy: 0.8396\n",
            "Epoch 70/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8544 - val_loss: 0.3907 - val_accuracy: 0.8385\n",
            "Epoch 71/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3625 - accuracy: 0.8572 - val_loss: 0.3911 - val_accuracy: 0.8396\n",
            "Epoch 72/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3619 - accuracy: 0.8560 - val_loss: 0.3916 - val_accuracy: 0.8385\n",
            "Epoch 73/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8569 - val_loss: 0.3905 - val_accuracy: 0.8407\n",
            "Epoch 74/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8564 - val_loss: 0.3899 - val_accuracy: 0.8385\n",
            "Epoch 75/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3612 - accuracy: 0.8558 - val_loss: 0.3892 - val_accuracy: 0.8407\n",
            "Epoch 76/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8565 - val_loss: 0.3905 - val_accuracy: 0.8407\n",
            "Epoch 77/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3604 - accuracy: 0.8571 - val_loss: 0.3908 - val_accuracy: 0.8418\n",
            "Epoch 78/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.8564 - val_loss: 0.3894 - val_accuracy: 0.8396\n",
            "Epoch 79/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3595 - accuracy: 0.8572 - val_loss: 0.3896 - val_accuracy: 0.8418\n",
            "Epoch 80/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3592 - accuracy: 0.8574 - val_loss: 0.3883 - val_accuracy: 0.8418\n",
            "Epoch 81/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8560 - val_loss: 0.3885 - val_accuracy: 0.8374\n",
            "Epoch 82/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8562 - val_loss: 0.3887 - val_accuracy: 0.8407\n",
            "Epoch 83/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3589 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8407\n",
            "Epoch 84/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8572 - val_loss: 0.3879 - val_accuracy: 0.8385\n",
            "Epoch 85/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8553 - val_loss: 0.3876 - val_accuracy: 0.8396\n",
            "Epoch 86/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3604 - accuracy: 0.8540 - val_loss: 0.3884 - val_accuracy: 0.8418\n",
            "Epoch 87/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3579 - accuracy: 0.8572 - val_loss: 0.3887 - val_accuracy: 0.8418\n",
            "Epoch 88/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8583 - val_loss: 0.3899 - val_accuracy: 0.8418\n",
            "Epoch 89/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3573 - accuracy: 0.8581 - val_loss: 0.3880 - val_accuracy: 0.8396\n",
            "Epoch 90/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8565 - val_loss: 0.3872 - val_accuracy: 0.8396\n",
            "Epoch 91/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3569 - accuracy: 0.8585 - val_loss: 0.3892 - val_accuracy: 0.8407\n",
            "Epoch 92/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3568 - accuracy: 0.8576 - val_loss: 0.3876 - val_accuracy: 0.8396\n",
            "Epoch 93/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3567 - accuracy: 0.8580 - val_loss: 0.3881 - val_accuracy: 0.8429\n",
            "Epoch 94/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8576 - val_loss: 0.3868 - val_accuracy: 0.8385\n",
            "Epoch 95/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8565 - val_loss: 0.3894 - val_accuracy: 0.8396\n",
            "Epoch 96/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8572 - val_loss: 0.3870 - val_accuracy: 0.8396\n",
            "Epoch 97/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3559 - accuracy: 0.8585 - val_loss: 0.3885 - val_accuracy: 0.8407\n",
            "Epoch 98/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8571 - val_loss: 0.3885 - val_accuracy: 0.8418\n",
            "Epoch 99/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8585 - val_loss: 0.3861 - val_accuracy: 0.8385\n",
            "Epoch 100/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3553 - accuracy: 0.8589 - val_loss: 0.3878 - val_accuracy: 0.8429\n",
            "Epoch 101/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3556 - accuracy: 0.8580 - val_loss: 0.3879 - val_accuracy: 0.8429\n",
            "Epoch 102/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8578 - val_loss: 0.3882 - val_accuracy: 0.8440\n",
            "Epoch 103/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8565 - val_loss: 0.3885 - val_accuracy: 0.8418\n",
            "Epoch 104/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8583 - val_loss: 0.3858 - val_accuracy: 0.8385\n",
            "Epoch 105/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8580 - val_loss: 0.3885 - val_accuracy: 0.8429\n",
            "Epoch 106/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3564 - accuracy: 0.8546 - val_loss: 0.3895 - val_accuracy: 0.8396\n",
            "Epoch 107/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3545 - accuracy: 0.8567 - val_loss: 0.3861 - val_accuracy: 0.8418\n",
            "Epoch 108/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3544 - accuracy: 0.8572 - val_loss: 0.3867 - val_accuracy: 0.8418\n",
            "Epoch 109/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3552 - accuracy: 0.8580 - val_loss: 0.3858 - val_accuracy: 0.8385\n",
            "Epoch 110/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3550 - accuracy: 0.8574 - val_loss: 0.3863 - val_accuracy: 0.8440\n",
            "Epoch 111/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8578 - val_loss: 0.3898 - val_accuracy: 0.8407\n",
            "Epoch 112/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8556 - val_loss: 0.3882 - val_accuracy: 0.8418\n",
            "Epoch 113/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3549 - accuracy: 0.8578 - val_loss: 0.3894 - val_accuracy: 0.8407\n",
            "Epoch 114/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8565 - val_loss: 0.3875 - val_accuracy: 0.8440\n",
            "Epoch 115/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8571 - val_loss: 0.3870 - val_accuracy: 0.8429\n",
            "Epoch 116/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.8569 - val_loss: 0.3884 - val_accuracy: 0.8418\n",
            "Epoch 117/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8578 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
            "Epoch 118/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8581 - val_loss: 0.3852 - val_accuracy: 0.8385\n",
            "Epoch 119/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8569 - val_loss: 0.3859 - val_accuracy: 0.8407\n",
            "Epoch 120/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8571 - val_loss: 0.3887 - val_accuracy: 0.8407\n",
            "Epoch 121/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8576 - val_loss: 0.3848 - val_accuracy: 0.8385\n",
            "Epoch 122/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3531 - accuracy: 0.8565 - val_loss: 0.3894 - val_accuracy: 0.8407\n",
            "Epoch 123/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3531 - accuracy: 0.8572 - val_loss: 0.3845 - val_accuracy: 0.8418\n",
            "Epoch 124/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8567 - val_loss: 0.3849 - val_accuracy: 0.8363\n",
            "Epoch 125/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8581 - val_loss: 0.3874 - val_accuracy: 0.8440\n",
            "Epoch 126/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8571 - val_loss: 0.3848 - val_accuracy: 0.8407\n",
            "Epoch 127/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3522 - accuracy: 0.8572 - val_loss: 0.3855 - val_accuracy: 0.8418\n",
            "Epoch 128/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8574 - val_loss: 0.3846 - val_accuracy: 0.8385\n",
            "Epoch 129/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8581 - val_loss: 0.3864 - val_accuracy: 0.8429\n",
            "Epoch 130/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8571 - val_loss: 0.3866 - val_accuracy: 0.8429\n",
            "Epoch 131/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8576 - val_loss: 0.3859 - val_accuracy: 0.8418\n",
            "Epoch 132/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8572 - val_loss: 0.3888 - val_accuracy: 0.8396\n",
            "Epoch 133/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3552 - accuracy: 0.8544 - val_loss: 0.3889 - val_accuracy: 0.8407\n",
            "Epoch 134/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.8562 - val_loss: 0.3847 - val_accuracy: 0.8385\n",
            "Epoch 135/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8578 - val_loss: 0.3855 - val_accuracy: 0.8418\n",
            "Epoch 136/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8580 - val_loss: 0.3844 - val_accuracy: 0.8407\n",
            "Epoch 137/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8560 - val_loss: 0.3842 - val_accuracy: 0.8374\n",
            "Epoch 138/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3516 - accuracy: 0.8583 - val_loss: 0.3842 - val_accuracy: 0.8396\n",
            "Epoch 139/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3528 - accuracy: 0.8564 - val_loss: 0.3841 - val_accuracy: 0.8374\n",
            "Epoch 140/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3520 - accuracy: 0.8578 - val_loss: 0.3857 - val_accuracy: 0.8440\n",
            "Epoch 141/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8574 - val_loss: 0.3839 - val_accuracy: 0.8385\n",
            "Epoch 142/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3518 - accuracy: 0.8567 - val_loss: 0.3851 - val_accuracy: 0.8418\n",
            "Epoch 143/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8572 - val_loss: 0.3868 - val_accuracy: 0.8418\n",
            "Epoch 144/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3514 - accuracy: 0.8581 - val_loss: 0.3837 - val_accuracy: 0.8385\n",
            "Epoch 145/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8580 - val_loss: 0.3837 - val_accuracy: 0.8396\n",
            "Epoch 146/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8569 - val_loss: 0.3844 - val_accuracy: 0.8407\n",
            "Epoch 147/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3506 - accuracy: 0.8576 - val_loss: 0.3858 - val_accuracy: 0.8429\n",
            "Epoch 148/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8571 - val_loss: 0.3851 - val_accuracy: 0.8429\n",
            "Epoch 149/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8572 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 150/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3508 - accuracy: 0.8581 - val_loss: 0.3834 - val_accuracy: 0.8374\n",
            "Epoch 151/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8578 - val_loss: 0.3839 - val_accuracy: 0.8385\n",
            "Epoch 152/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8574 - val_loss: 0.3846 - val_accuracy: 0.8440\n",
            "Epoch 153/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.8569 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 154/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8574 - val_loss: 0.3847 - val_accuracy: 0.8440\n",
            "Epoch 155/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8572 - val_loss: 0.3849 - val_accuracy: 0.8440\n",
            "Epoch 156/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3505 - accuracy: 0.8572 - val_loss: 0.3852 - val_accuracy: 0.8440\n",
            "Epoch 157/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8574 - val_loss: 0.3849 - val_accuracy: 0.8429\n",
            "Epoch 158/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8574 - val_loss: 0.3861 - val_accuracy: 0.8396\n",
            "Epoch 159/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.8565 - val_loss: 0.3861 - val_accuracy: 0.8407\n",
            "Epoch 160/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8574 - val_loss: 0.3836 - val_accuracy: 0.8407\n",
            "Epoch 161/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3497 - accuracy: 0.8574 - val_loss: 0.3832 - val_accuracy: 0.8396\n",
            "Epoch 162/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8567 - val_loss: 0.3846 - val_accuracy: 0.8418\n",
            "Epoch 163/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3499 - accuracy: 0.8565 - val_loss: 0.3870 - val_accuracy: 0.8407\n",
            "Epoch 164/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8572 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 165/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8578 - val_loss: 0.3837 - val_accuracy: 0.8418\n",
            "Epoch 166/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3493 - accuracy: 0.8581 - val_loss: 0.3851 - val_accuracy: 0.8418\n",
            "Epoch 167/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3499 - accuracy: 0.8587 - val_loss: 0.3878 - val_accuracy: 0.8418\n",
            "Epoch 168/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8572 - val_loss: 0.3839 - val_accuracy: 0.8407\n",
            "Epoch 169/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8578 - val_loss: 0.3827 - val_accuracy: 0.8374\n",
            "Epoch 170/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8567 - val_loss: 0.3835 - val_accuracy: 0.8418\n",
            "Epoch 171/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8572 - val_loss: 0.3839 - val_accuracy: 0.8396\n",
            "Epoch 172/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8572 - val_loss: 0.3831 - val_accuracy: 0.8374\n",
            "Epoch 173/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3493 - accuracy: 0.8567 - val_loss: 0.3828 - val_accuracy: 0.8385\n",
            "Epoch 174/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3486 - accuracy: 0.8571 - val_loss: 0.3837 - val_accuracy: 0.8407\n",
            "Epoch 175/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8583 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
            "Epoch 176/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8572 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 177/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3492 - accuracy: 0.8576 - val_loss: 0.3829 - val_accuracy: 0.8385\n",
            "Epoch 178/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8580 - val_loss: 0.3827 - val_accuracy: 0.8385\n",
            "Epoch 179/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8572 - val_loss: 0.3850 - val_accuracy: 0.8418\n",
            "Epoch 180/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8583 - val_loss: 0.3847 - val_accuracy: 0.8418\n",
            "Epoch 181/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8576 - val_loss: 0.3831 - val_accuracy: 0.8385\n",
            "Epoch 182/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8581 - val_loss: 0.3824 - val_accuracy: 0.8374\n",
            "Epoch 183/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8569 - val_loss: 0.3825 - val_accuracy: 0.8396\n",
            "Epoch 184/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8589 - val_loss: 0.3895 - val_accuracy: 0.8385\n",
            "Epoch 185/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8583 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 186/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3484 - accuracy: 0.8549 - val_loss: 0.3824 - val_accuracy: 0.8396\n",
            "Epoch 187/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8574 - val_loss: 0.3820 - val_accuracy: 0.8385\n",
            "Epoch 188/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8585 - val_loss: 0.3826 - val_accuracy: 0.8374\n",
            "Epoch 189/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8571 - val_loss: 0.3843 - val_accuracy: 0.8396\n",
            "Epoch 190/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3487 - accuracy: 0.8576 - val_loss: 0.3874 - val_accuracy: 0.8407\n",
            "Epoch 191/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8572 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 192/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3488 - accuracy: 0.8564 - val_loss: 0.3817 - val_accuracy: 0.8385\n",
            "Epoch 193/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8574 - val_loss: 0.3835 - val_accuracy: 0.8396\n",
            "Epoch 194/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8572 - val_loss: 0.3831 - val_accuracy: 0.8407\n",
            "Epoch 195/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8578 - val_loss: 0.3833 - val_accuracy: 0.8407\n",
            "Epoch 196/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8576 - val_loss: 0.3832 - val_accuracy: 0.8385\n",
            "Epoch 197/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8562 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 198/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8556 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 199/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8576 - val_loss: 0.3832 - val_accuracy: 0.8374\n",
            "Epoch 200/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8574 - val_loss: 0.3844 - val_accuracy: 0.8418\n",
            "Epoch 201/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3476 - accuracy: 0.8572 - val_loss: 0.3815 - val_accuracy: 0.8374\n",
            "Epoch 202/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8572 - val_loss: 0.3832 - val_accuracy: 0.8385\n",
            "Epoch 203/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8560 - val_loss: 0.3848 - val_accuracy: 0.8396\n",
            "Epoch 204/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3471 - accuracy: 0.8569 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 205/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8385\n",
            "Epoch 206/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8572 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 207/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8574 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 208/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 209/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8574 - val_loss: 0.3817 - val_accuracy: 0.8374\n",
            "Epoch 210/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8569 - val_loss: 0.3840 - val_accuracy: 0.8407\n",
            "Epoch 211/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8572 - val_loss: 0.3849 - val_accuracy: 0.8396\n",
            "Epoch 212/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.8580 - val_loss: 0.3824 - val_accuracy: 0.8407\n",
            "Epoch 213/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8585 - val_loss: 0.3845 - val_accuracy: 0.8396\n",
            "Epoch 214/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8567 - val_loss: 0.3831 - val_accuracy: 0.8385\n",
            "Epoch 215/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8580 - val_loss: 0.3816 - val_accuracy: 0.8396\n",
            "Epoch 216/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8578 - val_loss: 0.3814 - val_accuracy: 0.8374\n",
            "Epoch 217/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8583 - val_loss: 0.3817 - val_accuracy: 0.8407\n",
            "Epoch 218/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8576 - val_loss: 0.3886 - val_accuracy: 0.8396\n",
            "Epoch 219/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8567 - val_loss: 0.3820 - val_accuracy: 0.8396\n",
            "Epoch 220/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8578 - val_loss: 0.3810 - val_accuracy: 0.8374\n",
            "Epoch 221/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8589 - val_loss: 0.3821 - val_accuracy: 0.8396\n",
            "Epoch 222/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.8571 - val_loss: 0.3826 - val_accuracy: 0.8396\n",
            "Epoch 223/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8565 - val_loss: 0.3834 - val_accuracy: 0.8407\n",
            "Epoch 224/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3464 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 225/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3466 - accuracy: 0.8578 - val_loss: 0.3812 - val_accuracy: 0.8396\n",
            "Epoch 226/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3462 - accuracy: 0.8592 - val_loss: 0.3826 - val_accuracy: 0.8429\n",
            "Epoch 227/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8581 - val_loss: 0.3865 - val_accuracy: 0.8396\n",
            "Epoch 228/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8580 - val_loss: 0.3834 - val_accuracy: 0.8418\n",
            "Epoch 229/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3463 - accuracy: 0.8587 - val_loss: 0.3820 - val_accuracy: 0.8407\n",
            "Epoch 230/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3459 - accuracy: 0.8592 - val_loss: 0.3821 - val_accuracy: 0.8396\n",
            "Epoch 231/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8583 - val_loss: 0.3842 - val_accuracy: 0.8407\n",
            "Epoch 232/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3461 - accuracy: 0.8581 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 233/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8587 - val_loss: 0.3809 - val_accuracy: 0.8374\n",
            "Epoch 234/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8578 - val_loss: 0.3829 - val_accuracy: 0.8407\n",
            "Epoch 235/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8587 - val_loss: 0.3825 - val_accuracy: 0.8396\n",
            "Epoch 236/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3455 - accuracy: 0.8578 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 237/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8587 - val_loss: 0.3827 - val_accuracy: 0.8418\n",
            "Epoch 238/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8590 - val_loss: 0.3832 - val_accuracy: 0.8418\n",
            "Epoch 239/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3455 - accuracy: 0.8585 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 240/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8587 - val_loss: 0.3854 - val_accuracy: 0.8407\n",
            "Epoch 241/2000\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.3458 - accuracy: 0.8587 - val_loss: 0.3842 - val_accuracy: 0.8418\n",
            "Epoch 242/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3461 - accuracy: 0.8574 - val_loss: 0.3871 - val_accuracy: 0.8407\n",
            "Epoch 243/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8576 - val_loss: 0.3848 - val_accuracy: 0.8385\n",
            "Epoch 244/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8589 - val_loss: 0.3810 - val_accuracy: 0.8396\n",
            "Epoch 245/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8590 - val_loss: 0.3809 - val_accuracy: 0.8374\n",
            "Epoch 246/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8594 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 247/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8594 - val_loss: 0.3815 - val_accuracy: 0.8385\n",
            "Epoch 248/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3453 - accuracy: 0.8590 - val_loss: 0.3832 - val_accuracy: 0.8407\n",
            "Epoch 249/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8576 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 250/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8587 - val_loss: 0.3841 - val_accuracy: 0.8407\n",
            "Epoch 251/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8581 - val_loss: 0.3821 - val_accuracy: 0.8385\n",
            "Epoch 252/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8592 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 253/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8581 - val_loss: 0.3812 - val_accuracy: 0.8407\n",
            "Epoch 254/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8589 - val_loss: 0.3847 - val_accuracy: 0.8385\n",
            "Epoch 255/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3452 - accuracy: 0.8587 - val_loss: 0.3812 - val_accuracy: 0.8385\n",
            "Epoch 256/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3449 - accuracy: 0.8592 - val_loss: 0.3837 - val_accuracy: 0.8396\n",
            "Epoch 257/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8603 - val_loss: 0.3857 - val_accuracy: 0.8396\n",
            "Epoch 258/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8587 - val_loss: 0.3828 - val_accuracy: 0.8407\n",
            "Epoch 258: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f562c7e5250>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukaridaki modeldeki gorselde x eksenindeki deger 2000' e kadar gitmisti yani 2000 epoch boyunca calismisti. Early stop ile tanimladigimiz bu modelde ise epoch degeri 250 civarlarinda iken egitim tamamlandi :"
      ],
      "metadata": {
        "id": "PuiiRdGg1q0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV0mk_at1sPu",
        "outputId": "f9c61da8-afce-4edb-d5a2-6bc02b3c60fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stop kullanarak aldigimiz skorlar oncesine gore yukseldi. Cunku modelimiz overfit'e gitmisti, earl stop ile bunu engelledik :"
      ],
      "metadata": {
        "id": "IVR9qX1f15gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N1i_Aoc17LO",
        "outputId": "8b014ce7-e6b9-4de6-c91f-7a38c4545b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.3552604615688324\n",
            "accuracy :  0.8585714101791382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__weighted_avg__ ile sayisi fazla olan class' a ait skorlar agirlikli olarak temsil edilir. Eger sayisi fazla olan class degerleri bizim icin onemliyse bu skoru baz almak gerekir. Sayisi az olan class' i on plana cikarmak istiyorsak ise __macro__ skoruna bakmaliyiz."
      ],
      "metadata": {
        "id": "EzfdWEzh18yj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEGrVtmS1-JE",
        "outputId": "b76f677e-1f4b-4f97-d8cc-809a615733f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2698   89]\n",
            " [ 406  307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.97      0.92      2787\n",
            "           1       0.78      0.43      0.55       713\n",
            "\n",
            "    accuracy                           0.86      3500\n",
            "   macro avg       0.82      0.70      0.73      3500\n",
            "weighted avg       0.85      0.86      0.84      3500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### learning_rate"
      ],
      "metadata": {
        "id": "xWDo3xXN5Are"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarida early stop ile olusturdugumuz modele learning_rate parametresini ekleyerek skorlarimizdaki degisimleri gozlemleyecegiz :"
      ],
      "metadata": {
        "id": "khGfmRFs5Lnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "8vMyUSc055f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam' in icine learning rate tanimlayacagimiz icin Adam' i import ettik. (compile icine tanimlarken import etmeye gerek yok)"
      ],
      "metadata": {
        "id": "uCn2_MFU5Lt3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukaridaki model ile ayni islemleri yaptik. Sadece default degeri 0.001 olan learning_rate' i 0.005 yaparak atacagimiz adimlarin buyukluklerini 5 kat artirdik ve bunu bir degiskene atadik. optimizer icine ise bu degiskeni verdik. __(learning_rate ile adimlar buyudugu icin global min' e daha hizli ulasma ihtimali artar, tasarruf saglanir)__ : "
      ],
      "metadata": {
        "id": "kcu6luET5Lz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(30, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(15, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "opt = Adam(lr = 0.006)\n",
        "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "InKC8HWk49NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"auto\", verbose = 1, patience = 25)"
      ],
      "metadata": {
        "id": "WA_9d9815SxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "early_stop sayesinde egitimimiz 71. epoch' ta tamamlandi :"
      ],
      "metadata": {
        "id": "yEvO5HHl5S44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split = 0.14, batch_size = 260, epochs = 2000, verbose = 1,\n",
        "          callbacks = [early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdNJ_IJK5TJR",
        "outputId": "be03fb83-54ba-4dee-e38a-92335551f2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.5225 - accuracy: 0.7961 - val_loss: 0.4981 - val_accuracy: 0.7956\n",
            "Epoch 2/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7964 - val_loss: 0.4764 - val_accuracy: 0.7956\n",
            "Epoch 3/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7977 - val_loss: 0.4600 - val_accuracy: 0.7956\n",
            "Epoch 4/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.8075 - val_loss: 0.4373 - val_accuracy: 0.8198\n",
            "Epoch 5/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8277 - val_loss: 0.4160 - val_accuracy: 0.8319\n",
            "Epoch 6/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.8428 - val_loss: 0.4073 - val_accuracy: 0.8308\n",
            "Epoch 7/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3766 - accuracy: 0.8519 - val_loss: 0.3985 - val_accuracy: 0.8374\n",
            "Epoch 8/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3691 - accuracy: 0.8537 - val_loss: 0.4029 - val_accuracy: 0.8396\n",
            "Epoch 9/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3668 - accuracy: 0.8546 - val_loss: 0.3948 - val_accuracy: 0.8374\n",
            "Epoch 10/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8542 - val_loss: 0.3911 - val_accuracy: 0.8407\n",
            "Epoch 11/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.8544 - val_loss: 0.3900 - val_accuracy: 0.8451\n",
            "Epoch 12/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8555 - val_loss: 0.3929 - val_accuracy: 0.8440\n",
            "Epoch 13/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3598 - accuracy: 0.8581 - val_loss: 0.3894 - val_accuracy: 0.8396\n",
            "Epoch 14/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3593 - accuracy: 0.8578 - val_loss: 0.3845 - val_accuracy: 0.8429\n",
            "Epoch 15/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3595 - accuracy: 0.8544 - val_loss: 0.3886 - val_accuracy: 0.8473\n",
            "Epoch 16/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.8531 - val_loss: 0.4061 - val_accuracy: 0.8429\n",
            "Epoch 17/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8585 - val_loss: 0.3868 - val_accuracy: 0.8396\n",
            "Epoch 18/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3576 - accuracy: 0.8547 - val_loss: 0.3866 - val_accuracy: 0.8429\n",
            "Epoch 19/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8551 - val_loss: 0.3881 - val_accuracy: 0.8407\n",
            "Epoch 20/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3533 - accuracy: 0.8574 - val_loss: 0.3897 - val_accuracy: 0.8418\n",
            "Epoch 21/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.8569 - val_loss: 0.3849 - val_accuracy: 0.8385\n",
            "Epoch 22/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3542 - accuracy: 0.8538 - val_loss: 0.3858 - val_accuracy: 0.8418\n",
            "Epoch 23/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3537 - accuracy: 0.8581 - val_loss: 0.3861 - val_accuracy: 0.8440\n",
            "Epoch 24/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3519 - accuracy: 0.8590 - val_loss: 0.3849 - val_accuracy: 0.8418\n",
            "Epoch 25/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8572 - val_loss: 0.4082 - val_accuracy: 0.8440\n",
            "Epoch 26/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8546 - val_loss: 0.3846 - val_accuracy: 0.8407\n",
            "Epoch 27/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8578 - val_loss: 0.3848 - val_accuracy: 0.8407\n",
            "Epoch 28/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8533 - val_loss: 0.3947 - val_accuracy: 0.8396\n",
            "Epoch 29/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3566 - accuracy: 0.8547 - val_loss: 0.3852 - val_accuracy: 0.8374\n",
            "Epoch 30/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8605 - val_loss: 0.3880 - val_accuracy: 0.8385\n",
            "Epoch 31/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8567 - val_loss: 0.3839 - val_accuracy: 0.8363\n",
            "Epoch 32/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8569 - val_loss: 0.3867 - val_accuracy: 0.8396\n",
            "Epoch 33/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3488 - accuracy: 0.8583 - val_loss: 0.3854 - val_accuracy: 0.8396\n",
            "Epoch 34/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8569 - val_loss: 0.3833 - val_accuracy: 0.8374\n",
            "Epoch 35/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8583 - val_loss: 0.3900 - val_accuracy: 0.8407\n",
            "Epoch 36/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8572 - val_loss: 0.3825 - val_accuracy: 0.8407\n",
            "Epoch 37/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3487 - accuracy: 0.8583 - val_loss: 0.3831 - val_accuracy: 0.8429\n",
            "Epoch 38/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3476 - accuracy: 0.8585 - val_loss: 0.3857 - val_accuracy: 0.8418\n",
            "Epoch 39/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3448 - accuracy: 0.8590 - val_loss: 0.3821 - val_accuracy: 0.8451\n",
            "Epoch 40/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8567 - val_loss: 0.3830 - val_accuracy: 0.8418\n",
            "Epoch 41/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.8585 - val_loss: 0.3863 - val_accuracy: 0.8407\n",
            "Epoch 42/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3464 - accuracy: 0.8571 - val_loss: 0.3825 - val_accuracy: 0.8440\n",
            "Epoch 43/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3470 - accuracy: 0.8553 - val_loss: 0.3888 - val_accuracy: 0.8407\n",
            "Epoch 44/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3452 - accuracy: 0.8583 - val_loss: 0.3902 - val_accuracy: 0.8418\n",
            "Epoch 45/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3452 - accuracy: 0.8580 - val_loss: 0.3807 - val_accuracy: 0.8429\n",
            "Epoch 46/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8553 - val_loss: 0.3793 - val_accuracy: 0.8440\n",
            "Epoch 47/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3432 - accuracy: 0.8605 - val_loss: 0.3806 - val_accuracy: 0.8418\n",
            "Epoch 48/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8606 - val_loss: 0.3830 - val_accuracy: 0.8429\n",
            "Epoch 49/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8601 - val_loss: 0.3862 - val_accuracy: 0.8418\n",
            "Epoch 50/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3441 - accuracy: 0.8590 - val_loss: 0.3826 - val_accuracy: 0.8385\n",
            "Epoch 51/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3420 - accuracy: 0.8599 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 52/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8587 - val_loss: 0.3907 - val_accuracy: 0.8396\n",
            "Epoch 53/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3427 - accuracy: 0.8580 - val_loss: 0.3819 - val_accuracy: 0.8418\n",
            "Epoch 54/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8590 - val_loss: 0.3802 - val_accuracy: 0.8429\n",
            "Epoch 55/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3402 - accuracy: 0.8630 - val_loss: 0.3833 - val_accuracy: 0.8440\n",
            "Epoch 56/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8590 - val_loss: 0.3903 - val_accuracy: 0.8418\n",
            "Epoch 57/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8623 - val_loss: 0.3834 - val_accuracy: 0.8451\n",
            "Epoch 58/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.8606 - val_loss: 0.3804 - val_accuracy: 0.8440\n",
            "Epoch 59/2000\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.3408 - accuracy: 0.8583 - val_loss: 0.3810 - val_accuracy: 0.8462\n",
            "Epoch 60/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8608 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
            "Epoch 61/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3389 - accuracy: 0.8597 - val_loss: 0.3906 - val_accuracy: 0.8418\n",
            "Epoch 62/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3400 - accuracy: 0.8601 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
            "Epoch 63/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3385 - accuracy: 0.8617 - val_loss: 0.3866 - val_accuracy: 0.8429\n",
            "Epoch 64/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8574 - val_loss: 0.3844 - val_accuracy: 0.8385\n",
            "Epoch 65/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8574 - val_loss: 0.3811 - val_accuracy: 0.8451\n",
            "Epoch 66/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8612 - val_loss: 0.3827 - val_accuracy: 0.8363\n",
            "Epoch 67/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8617 - val_loss: 0.3857 - val_accuracy: 0.8418\n",
            "Epoch 68/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8608 - val_loss: 0.3839 - val_accuracy: 0.8385\n",
            "Epoch 69/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3358 - accuracy: 0.8615 - val_loss: 0.3818 - val_accuracy: 0.8418\n",
            "Epoch 70/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3360 - accuracy: 0.8606 - val_loss: 0.3810 - val_accuracy: 0.8495\n",
            "Epoch 71/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8587 - val_loss: 0.3868 - val_accuracy: 0.8352\n",
            "Epoch 71: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f562c82b810>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Onceki derste kurdugumuz regression modelindeki gibi eger 1000 epoch boyunca herhangi bir overfit durumu yoksa early stop' tan once learning rate parametresi ile oynamak mantikli olur; overfit tehlikesi olmadigi icin adimlarimizi buyuterek modeli iyilestirme yoluna gidebiliriz. Fakat burda kurdugumuz modelde overfit tehlikesi oldugu icin oncelikle early stop parametresi ile oynamak daha mantikli olur. Bu yuzden onceki datasetinde ilk olarak learning rate' i, sonra early stop' u degistirdik; bu datasetinde ise once early stop' u degistirerek overfit tehlikesini ortadan kaldirdik, sonrasinda learning rate ile iyilestirme yoluna gittik :"
      ],
      "metadata": {
        "id": "KBwxji4t5bK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eSyNEab-5cJn",
        "outputId": "e1c73cfb-5109-4f02-8aa1-7d84a2ff4b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2V9SExd5edN",
        "outputId": "18349b1c-a89f-4f82-f581-99849acd0d44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.36507415771484375\n",
            "accuracy :  0.8485714197158813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning_rate artirildigi icin egitim daha hizli yapildi. Skorlarimiz learning_rate=0.001' e gore biraz dustu. Yukaridaki model daha az hata yapmisti, buradaki model ise daha ok hata yapti (Boyle bir model icin learning_rate parametresi ile oynamaya gerek yok) :"
      ],
      "metadata": {
        "id": "4JNNh58K5e0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgoZ5irB5geh",
        "outputId": "83aedf07-334d-4ea4-f8e9-6ef4224e489c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2606  181]\n",
            " [ 349  364]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.94      0.91      2787\n",
            "           1       0.67      0.51      0.58       713\n",
            "\n",
            "    accuracy                           0.85      3500\n",
            "   macro avg       0.77      0.72      0.74      3500\n",
            "weighted avg       0.84      0.85      0.84      3500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GridSearchCV\n",
        "\n",
        "https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/"
      ],
      "metadata": {
        "id": "z1nMLMicKP1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop, Nadam\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "metadata": {
        "id": "yK8cl3Q6KVny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML' deki SVM modellerde hyperparametreler ile oynamak (GridSearch) onemliydi cunku kerneli degistiriyorduk, model kernel' e gore farkli sonuclar veriyordu. Burada da ayni SVM gibi model skorunu etkileyebilecek cok fazla degisken var. Bu yuzden DL modellerinde de GridSearch cok onemli."
      ],
      "metadata": {
        "id": "vk0AXy2_oSSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__--__ random.set_seed uygulansa bile GridSearch islemlerinde farkli skorlar alinabilir. Bu yuzden birkac kere model calistirilip en iyi skoru veren model secilebilir.  __--__"
      ],
      "metadata": {
        "id": "9GW37vYgoUb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def fonksiyonu icine optimizer ve learn_rate' i degisken olarak tanimladik; compile icinde de optimizer icine learning rate' i verdik (def fonksiyonu icinde nron sayilari da tanimlanarak makine gcne gre farkli nron sayilari denenebilir.Yukaridaki makalede rnekleri var) :"
      ],
      "metadata": {
        "id": "WfoGC_2eoV_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(optimizer, learn_rate):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 14, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 7, activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = optimizer(learn_rate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier"
      ],
      "metadata": {
        "id": "ACnP_5iJiVOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch' te EarlyStop kullanilip kullanilmamasi durumu tartismali bir konudur. Bazi makalelerde kullanilmamasi nerilir. Bizim modelimizde yaptigimiz gibi eger epoch sayisi sabitlendiyse (biz 2000 epoch olarak sabitledik) ve bu sayi GridSearch isleminde degistirilmeyecekse early stop kullanilabilir. Eger early stop kullanmazsak model overfite gidebilir ve skorlar dusebilir."
      ],
      "metadata": {
        "id": "hGFMxvYNoZDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_accuracy\", mode = \"auto\", verbose = 1, patience = 25)"
      ],
      "metadata": {
        "id": "sA36aDkyiVRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early stop kullandigimiz icin validation_split de vermemiz gerekti (validation split' e gore 15 adim boyunca skorlar duzelmezse egitimi durduracak)"
      ],
      "metadata": {
        "id": "FUPqIcxqobvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "classifier_model = KerasClassifier(build_fn = build_classifier,validation_split = 0.14, epochs = 2000)\n",
        "\n",
        "parameters = {'batch_size': [260, 520],\n",
        "              'optimizer': [Adam, RMSprop, Adadelta, Nadam],\n",
        "              'learn_rate': [0.001, 0.003, 0.005]}\n",
        "\n",
        "grid_model = GridSearchCV(estimator = classifier_model,\n",
        "                          param_grid = parameters,\n",
        "                          scoring = 'accuracy',\n",
        "                          cv = 10,\n",
        "                          n_jobs = -1,\n",
        "                          verbose = 1)\n",
        "\n",
        "grid_model.fit(X_train, y_train, callbacks = [early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAlJo71BiVS3",
        "outputId": "2ccaf1c6-56a8-4b68-93e9-2422affea0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
            "Epoch 1/2000\n",
            "22/22 [==============================] - 1s 11ms/step - loss: 0.5467 - accuracy: 0.7962 - val_loss: 0.5098 - val_accuracy: 0.7956\n",
            "Epoch 2/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7964 - val_loss: 0.4847 - val_accuracy: 0.7956\n",
            "Epoch 3/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7964 - val_loss: 0.4712 - val_accuracy: 0.7956\n",
            "Epoch 4/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7991 - val_loss: 0.4564 - val_accuracy: 0.8000\n",
            "Epoch 5/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8066 - val_loss: 0.4510 - val_accuracy: 0.8033\n",
            "Epoch 6/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8113 - val_loss: 0.4410 - val_accuracy: 0.8110\n",
            "Epoch 7/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8152 - val_loss: 0.4340 - val_accuracy: 0.8198\n",
            "Epoch 8/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8272 - val_loss: 0.4337 - val_accuracy: 0.8165\n",
            "Epoch 9/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.4030 - accuracy: 0.8301 - val_loss: 0.4203 - val_accuracy: 0.8242\n",
            "Epoch 10/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3950 - accuracy: 0.8358 - val_loss: 0.4137 - val_accuracy: 0.8286\n",
            "Epoch 11/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8401 - val_loss: 0.4115 - val_accuracy: 0.8374\n",
            "Epoch 12/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3817 - accuracy: 0.8460 - val_loss: 0.4057 - val_accuracy: 0.8308\n",
            "Epoch 13/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3782 - accuracy: 0.8472 - val_loss: 0.4016 - val_accuracy: 0.8330\n",
            "Epoch 14/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3767 - accuracy: 0.8496 - val_loss: 0.3999 - val_accuracy: 0.8319\n",
            "Epoch 15/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3717 - accuracy: 0.8519 - val_loss: 0.3955 - val_accuracy: 0.8374\n",
            "Epoch 16/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.8533 - val_loss: 0.3943 - val_accuracy: 0.8363\n",
            "Epoch 17/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8530 - val_loss: 0.3970 - val_accuracy: 0.8363\n",
            "Epoch 18/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3656 - accuracy: 0.8528 - val_loss: 0.3907 - val_accuracy: 0.8407\n",
            "Epoch 19/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8560 - val_loss: 0.4095 - val_accuracy: 0.8308\n",
            "Epoch 20/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8528 - val_loss: 0.3915 - val_accuracy: 0.8440\n",
            "Epoch 21/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3646 - accuracy: 0.8515 - val_loss: 0.3883 - val_accuracy: 0.8385\n",
            "Epoch 22/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.8549 - val_loss: 0.4035 - val_accuracy: 0.8363\n",
            "Epoch 23/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3588 - accuracy: 0.8580 - val_loss: 0.3925 - val_accuracy: 0.8396\n",
            "Epoch 24/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8571 - val_loss: 0.3908 - val_accuracy: 0.8407\n",
            "Epoch 25/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3615 - accuracy: 0.8533 - val_loss: 0.4006 - val_accuracy: 0.8363\n",
            "Epoch 26/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3574 - accuracy: 0.8564 - val_loss: 0.3870 - val_accuracy: 0.8385\n",
            "Epoch 27/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.8556 - val_loss: 0.3889 - val_accuracy: 0.8374\n",
            "Epoch 28/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8553 - val_loss: 0.3890 - val_accuracy: 0.8385\n",
            "Epoch 29/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8553 - val_loss: 0.3870 - val_accuracy: 0.8385\n",
            "Epoch 30/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8569 - val_loss: 0.3895 - val_accuracy: 0.8385\n",
            "Epoch 31/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8565 - val_loss: 0.3924 - val_accuracy: 0.8440\n",
            "Epoch 32/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8555 - val_loss: 0.4022 - val_accuracy: 0.8374\n",
            "Epoch 33/2000\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.3579 - accuracy: 0.8553 - val_loss: 0.4028 - val_accuracy: 0.8352\n",
            "Epoch 34/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8572 - val_loss: 0.3904 - val_accuracy: 0.8374\n",
            "Epoch 35/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8567 - val_loss: 0.3858 - val_accuracy: 0.8396\n",
            "Epoch 36/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8558 - val_loss: 0.3945 - val_accuracy: 0.8363\n",
            "Epoch 37/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8551 - val_loss: 0.3859 - val_accuracy: 0.8418\n",
            "Epoch 38/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8565 - val_loss: 0.3861 - val_accuracy: 0.8407\n",
            "Epoch 39/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8578 - val_loss: 0.3868 - val_accuracy: 0.8396\n",
            "Epoch 40/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8572 - val_loss: 0.3928 - val_accuracy: 0.8374\n",
            "Epoch 41/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3520 - accuracy: 0.8555 - val_loss: 0.3860 - val_accuracy: 0.8396\n",
            "Epoch 42/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8569 - val_loss: 0.3874 - val_accuracy: 0.8429\n",
            "Epoch 43/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8555 - val_loss: 0.3900 - val_accuracy: 0.8407\n",
            "Epoch 44/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8571 - val_loss: 0.3904 - val_accuracy: 0.8363\n",
            "Epoch 45/2000\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8553 - val_loss: 0.3880 - val_accuracy: 0.8385\n",
            "Epoch 45: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=10,\n",
              "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7f562b4c1e90>,\n",
              "             n_jobs=-1,\n",
              "             param_grid={'batch_size': [260, 520],\n",
              "                         'learn_rate': [0.001, 0.003, 0.005],\n",
              "                         'optimizer': [<class 'keras.optimizer_v2.adam.Adam'>,\n",
              "                                       <class 'keras.optimizer_v2.rmsprop.RMSprop'>,\n",
              "                                       <class 'keras.optimizer_v2.adadelta.Adadelta'>,\n",
              "                                       <class 'keras.optimizer_v2.nadam.Nadam'>]},\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML modellerindeki gibi best score ve best parametrelere bakabiliyoruz :"
      ],
      "metadata": {
        "id": "kL9GTNYOogMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbXjKAGwiVUv",
        "outputId": "b149b230-437d-4344-b7aa-e3773f117ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8546153846153846"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_model.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIz4ghYBiVWt",
        "outputId": "10ddb7fe-06dc-49a6-8593-2d5bc1a3ac68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 260,\n",
              " 'learn_rate': 0.005,\n",
              " 'optimizer': keras.optimizer_v2.nadam.Nadam}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#grid_model.cv_results_   \n",
        "\n",
        "#Tum sonuclari verir, okumasi kolay degil. Bu yuzden asagida DataFrame' e cevirdik."
      ],
      "metadata": {
        "id": "szIfxxdiiVYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alinan skorlar arasinda \"ort. test skor, ort. std, en iyi skoru kacinci derecede aldigi, hangi parametreleri secmis\" bilgilerine DataFrame ile  baktik :"
      ],
      "metadata": {
        "id": "aCagj1W-omch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = pd.DataFrame(grid_model.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"params\"]]\n",
        "grid_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "d6lEFiffiVbF",
        "outputId": "7d277e6c-cd3e-425f-ca17-1c3d35e0d74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_test_score  std_test_score  rank_test_score  \\\n",
              "0             0.837           0.029               14   \n",
              "1             0.828           0.025               15   \n",
              "2             0.675           0.237               21   \n",
              "3             0.845           0.022               11   \n",
              "4             0.854           0.022                2   \n",
              "5             0.851           0.020                5   \n",
              "6             0.797           0.017               18   \n",
              "7             0.853           0.019                4   \n",
              "8             0.851           0.024                6   \n",
              "9             0.844           0.017               12   \n",
              "10            0.796           0.016               19   \n",
              "11            0.855           0.019                1   \n",
              "12            0.796           0.016               20   \n",
              "13            0.800           0.020               17   \n",
              "14            0.559           0.271               24   \n",
              "15            0.814           0.029               16   \n",
              "16            0.842           0.028               13   \n",
              "17            0.850           0.023                7   \n",
              "18            0.673           0.238               22   \n",
              "19            0.853           0.021                3   \n",
              "20            0.848           0.027                9   \n",
              "21            0.849           0.015                8   \n",
              "22            0.620           0.272               23   \n",
              "23            0.847           0.025               10   \n",
              "\n",
              "                                               params  \n",
              "0   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "1   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "2   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "3   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "4   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "5   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "6   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "7   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "8   {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "9   {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "10  {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "11  {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "12  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "13  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "14  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "15  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "16  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "17  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "18  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "19  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "20  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "21  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "22  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "23  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59765373-5384-4658-8e0e-22b4062292ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.837</td>\n",
              "      <td>0.029</td>\n",
              "      <td>14</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.828</td>\n",
              "      <td>0.025</td>\n",
              "      <td>15</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.675</td>\n",
              "      <td>0.237</td>\n",
              "      <td>21</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.845</td>\n",
              "      <td>0.022</td>\n",
              "      <td>11</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.854</td>\n",
              "      <td>0.022</td>\n",
              "      <td>2</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.851</td>\n",
              "      <td>0.020</td>\n",
              "      <td>5</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.797</td>\n",
              "      <td>0.017</td>\n",
              "      <td>18</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.019</td>\n",
              "      <td>4</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.851</td>\n",
              "      <td>0.024</td>\n",
              "      <td>6</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.844</td>\n",
              "      <td>0.017</td>\n",
              "      <td>12</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.796</td>\n",
              "      <td>0.016</td>\n",
              "      <td>19</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.855</td>\n",
              "      <td>0.019</td>\n",
              "      <td>1</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.796</td>\n",
              "      <td>0.016</td>\n",
              "      <td>20</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.020</td>\n",
              "      <td>17</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.559</td>\n",
              "      <td>0.271</td>\n",
              "      <td>24</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.814</td>\n",
              "      <td>0.029</td>\n",
              "      <td>16</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.842</td>\n",
              "      <td>0.028</td>\n",
              "      <td>13</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.850</td>\n",
              "      <td>0.023</td>\n",
              "      <td>7</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.673</td>\n",
              "      <td>0.238</td>\n",
              "      <td>22</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.021</td>\n",
              "      <td>3</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.848</td>\n",
              "      <td>0.027</td>\n",
              "      <td>9</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.849</td>\n",
              "      <td>0.015</td>\n",
              "      <td>8</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.620</td>\n",
              "      <td>0.272</td>\n",
              "      <td>23</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.847</td>\n",
              "      <td>0.025</td>\n",
              "      <td>10</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59765373-5384-4658-8e0e-22b4062292ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59765373-5384-4658-8e0e-22b4062292ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59765373-5384-4658-8e0e-22b4062292ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukaridaki sonuclarin rank_test_score' a gore siralanmasini istedik :"
      ],
      "metadata": {
        "id": "T0p1Dmuwop48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_result = pd.DataFrame(grid_model.cv_results_)[[\"mean_test_score\", \"std_test_score\", \"rank_test_score\", \"params\"]].sort_values('rank_test_score')\n",
        "grid_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "XFPe2r0wiVdZ",
        "outputId": "3f7dbfe9-e076-40b0-a4db-0b0f7421d430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_test_score  std_test_score  rank_test_score  \\\n",
              "11            0.855           0.019                1   \n",
              "4             0.854           0.022                2   \n",
              "19            0.853           0.021                3   \n",
              "7             0.853           0.019                4   \n",
              "5             0.851           0.020                5   \n",
              "8             0.851           0.024                6   \n",
              "17            0.850           0.023                7   \n",
              "21            0.849           0.015                8   \n",
              "20            0.848           0.027                9   \n",
              "23            0.847           0.025               10   \n",
              "3             0.845           0.022               11   \n",
              "9             0.844           0.017               12   \n",
              "16            0.842           0.028               13   \n",
              "0             0.837           0.029               14   \n",
              "1             0.828           0.025               15   \n",
              "15            0.814           0.029               16   \n",
              "13            0.800           0.020               17   \n",
              "6             0.797           0.017               18   \n",
              "10            0.796           0.016               19   \n",
              "12            0.796           0.016               20   \n",
              "2             0.675           0.237               21   \n",
              "18            0.673           0.238               22   \n",
              "22            0.620           0.272               23   \n",
              "14            0.559           0.271               24   \n",
              "\n",
              "                                               params  \n",
              "11  {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "4   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "19  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "7   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "5   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "8   {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "17  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "21  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "20  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "23  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "3   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "9   {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "16  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "0   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "1   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "15  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "13  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "6   {'batch_size': 260, 'learn_rate': 0.003, 'opti...  \n",
              "10  {'batch_size': 260, 'learn_rate': 0.005, 'opti...  \n",
              "12  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  \n",
              "2   {'batch_size': 260, 'learn_rate': 0.001, 'opti...  \n",
              "18  {'batch_size': 520, 'learn_rate': 0.003, 'opti...  \n",
              "22  {'batch_size': 520, 'learn_rate': 0.005, 'opti...  \n",
              "14  {'batch_size': 520, 'learn_rate': 0.001, 'opti...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-13f499af-a03b-4165-a995-ea94a72504ac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.855</td>\n",
              "      <td>0.019</td>\n",
              "      <td>1</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.854</td>\n",
              "      <td>0.022</td>\n",
              "      <td>2</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.021</td>\n",
              "      <td>3</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.853</td>\n",
              "      <td>0.019</td>\n",
              "      <td>4</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.851</td>\n",
              "      <td>0.020</td>\n",
              "      <td>5</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.851</td>\n",
              "      <td>0.024</td>\n",
              "      <td>6</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.850</td>\n",
              "      <td>0.023</td>\n",
              "      <td>7</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.849</td>\n",
              "      <td>0.015</td>\n",
              "      <td>8</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.848</td>\n",
              "      <td>0.027</td>\n",
              "      <td>9</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.847</td>\n",
              "      <td>0.025</td>\n",
              "      <td>10</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.845</td>\n",
              "      <td>0.022</td>\n",
              "      <td>11</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.844</td>\n",
              "      <td>0.017</td>\n",
              "      <td>12</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.842</td>\n",
              "      <td>0.028</td>\n",
              "      <td>13</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.837</td>\n",
              "      <td>0.029</td>\n",
              "      <td>14</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.828</td>\n",
              "      <td>0.025</td>\n",
              "      <td>15</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.814</td>\n",
              "      <td>0.029</td>\n",
              "      <td>16</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.020</td>\n",
              "      <td>17</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.797</td>\n",
              "      <td>0.017</td>\n",
              "      <td>18</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.796</td>\n",
              "      <td>0.016</td>\n",
              "      <td>19</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.796</td>\n",
              "      <td>0.016</td>\n",
              "      <td>20</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.675</td>\n",
              "      <td>0.237</td>\n",
              "      <td>21</td>\n",
              "      <td>{'batch_size': 260, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.673</td>\n",
              "      <td>0.238</td>\n",
              "      <td>22</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.003, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.620</td>\n",
              "      <td>0.272</td>\n",
              "      <td>23</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.005, 'opti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.559</td>\n",
              "      <td>0.271</td>\n",
              "      <td>24</td>\n",
              "      <td>{'batch_size': 520, 'learn_rate': 0.001, 'opti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13f499af-a03b-4165-a995-ea94a72504ac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13f499af-a03b-4165-a995-ea94a72504ac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13f499af-a03b-4165-a995-ea94a72504ac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome."
      ],
      "metadata": {
        "id": "sPUUoW01otI1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b64s5gNOXsAX"
      },
      "source": [
        "## Final Model and Model Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yine X_train ve y_train' i kullanacagimiz icin final modelde de yukarida olusturdugumuz scaler' i pickle ile dump ettik :"
      ],
      "metadata": {
        "id": "HgOzF4Xq3r3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(scaler, open(\"scaler_Exited\", 'wb'))"
      ],
      "metadata": {
        "id": "ovyD4jm-3ZSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yukarida aldigimiz en iyi degerler ile final modelimizi kurduk :"
      ],
      "metadata": {
        "id": "m85-O4QM3vOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(seed)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(14, activation = \"relu\", input_dim = X_train.shape[1]))\n",
        "model.add(Dense(7, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "\n",
        "opt = Adam(lr = 0.005)\n",
        "model.compile(optimizer = opt, loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "oFwW03ZR3ZZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"auto\", verbose = 1, patience = 25)"
      ],
      "metadata": {
        "id": "ywWMgyqU3ZcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final modelde yukaridaki modellerden farkli olarak __validation_split__ yerine __validation_data__ kullandik. validation_data' da X_train ve y_train' in son kismindan belirtilen miktar kadarini validation' a ayirir; validation_datada ise X_test ve y_test validation datasi olarak kullanilir."
      ],
      "metadata": {
        "id": "tpS1TQYB3ymk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x = X_train, y = y_train, validation_data = (X_test, y_test), batch_size = 260, epochs = 2000, verbose = 1,\n",
        "          callbacks = [early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8X6ZJuw3ZeZ",
        "outputId": "754c5129-4e06-4e20-a206-0463a2afd9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "25/25 [==============================] - 1s 11ms/step - loss: 0.5378 - accuracy: 0.7960 - val_loss: 0.5010 - val_accuracy: 0.7963\n",
            "Epoch 2/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4923 - accuracy: 0.7963 - val_loss: 0.4808 - val_accuracy: 0.7963\n",
            "Epoch 3/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7963 - val_loss: 0.4642 - val_accuracy: 0.7963\n",
            "Epoch 4/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7968 - val_loss: 0.4510 - val_accuracy: 0.8020\n",
            "Epoch 5/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8008 - val_loss: 0.4358 - val_accuracy: 0.8160\n",
            "Epoch 6/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.8069 - val_loss: 0.4188 - val_accuracy: 0.8143\n",
            "Epoch 7/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8125 - val_loss: 0.4076 - val_accuracy: 0.8257\n",
            "Epoch 8/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8254 - val_loss: 0.4006 - val_accuracy: 0.8266\n",
            "Epoch 9/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8298 - val_loss: 0.3898 - val_accuracy: 0.8449\n",
            "Epoch 10/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8374 - val_loss: 0.3827 - val_accuracy: 0.8451\n",
            "Epoch 11/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8425 - val_loss: 0.3780 - val_accuracy: 0.8497\n",
            "Epoch 12/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8468 - val_loss: 0.3733 - val_accuracy: 0.8494\n",
            "Epoch 13/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3757 - accuracy: 0.8472 - val_loss: 0.3748 - val_accuracy: 0.8480\n",
            "Epoch 14/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8495 - val_loss: 0.3768 - val_accuracy: 0.8400\n",
            "Epoch 15/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8511 - val_loss: 0.3700 - val_accuracy: 0.8537\n",
            "Epoch 16/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8509 - val_loss: 0.3694 - val_accuracy: 0.8540\n",
            "Epoch 17/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3698 - accuracy: 0.8474 - val_loss: 0.3753 - val_accuracy: 0.8511\n",
            "Epoch 18/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8520 - val_loss: 0.3637 - val_accuracy: 0.8549\n",
            "Epoch 19/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3642 - accuracy: 0.8545 - val_loss: 0.3638 - val_accuracy: 0.8529\n",
            "Epoch 20/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8526 - val_loss: 0.3677 - val_accuracy: 0.8517\n",
            "Epoch 21/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3620 - accuracy: 0.8538 - val_loss: 0.3637 - val_accuracy: 0.8580\n",
            "Epoch 22/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8558 - val_loss: 0.3631 - val_accuracy: 0.8563\n",
            "Epoch 23/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3623 - accuracy: 0.8552 - val_loss: 0.3628 - val_accuracy: 0.8563\n",
            "Epoch 24/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8554 - val_loss: 0.3650 - val_accuracy: 0.8543\n",
            "Epoch 25/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8537 - val_loss: 0.3630 - val_accuracy: 0.8537\n",
            "Epoch 26/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3597 - accuracy: 0.8532 - val_loss: 0.3702 - val_accuracy: 0.8517\n",
            "Epoch 27/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3645 - accuracy: 0.8531 - val_loss: 0.3627 - val_accuracy: 0.8543\n",
            "Epoch 28/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3585 - accuracy: 0.8555 - val_loss: 0.3616 - val_accuracy: 0.8540\n",
            "Epoch 29/2000\n",
            "25/25 [==============================] - 0s 11ms/step - loss: 0.3591 - accuracy: 0.8537 - val_loss: 0.3643 - val_accuracy: 0.8531\n",
            "Epoch 30/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8534 - val_loss: 0.3654 - val_accuracy: 0.8517\n",
            "Epoch 31/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8540 - val_loss: 0.3629 - val_accuracy: 0.8569\n",
            "Epoch 32/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8534 - val_loss: 0.3620 - val_accuracy: 0.8543\n",
            "Epoch 33/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8554 - val_loss: 0.3605 - val_accuracy: 0.8566\n",
            "Epoch 34/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8558 - val_loss: 0.3603 - val_accuracy: 0.8569\n",
            "Epoch 35/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8538 - val_loss: 0.3660 - val_accuracy: 0.8506\n",
            "Epoch 36/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3588 - accuracy: 0.8518 - val_loss: 0.3595 - val_accuracy: 0.8589\n",
            "Epoch 37/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3566 - accuracy: 0.8537 - val_loss: 0.3589 - val_accuracy: 0.8574\n",
            "Epoch 38/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.3568 - accuracy: 0.8555 - val_loss: 0.3594 - val_accuracy: 0.8577\n",
            "Epoch 39/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3551 - accuracy: 0.8551 - val_loss: 0.3591 - val_accuracy: 0.8569\n",
            "Epoch 40/2000\n",
            "25/25 [==============================] - 0s 12ms/step - loss: 0.3588 - accuracy: 0.8548 - val_loss: 0.3645 - val_accuracy: 0.8557\n",
            "Epoch 41/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3595 - accuracy: 0.8548 - val_loss: 0.3734 - val_accuracy: 0.8434\n",
            "Epoch 42/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3565 - accuracy: 0.8562 - val_loss: 0.3651 - val_accuracy: 0.8534\n",
            "Epoch 43/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8563 - val_loss: 0.3578 - val_accuracy: 0.8574\n",
            "Epoch 44/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3579 - accuracy: 0.8542 - val_loss: 0.3600 - val_accuracy: 0.8577\n",
            "Epoch 45/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8518 - val_loss: 0.3613 - val_accuracy: 0.8546\n",
            "Epoch 46/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8542 - val_loss: 0.3577 - val_accuracy: 0.8540\n",
            "Epoch 47/2000\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3535 - accuracy: 0.8548 - val_loss: 0.3599 - val_accuracy: 0.8537\n",
            "Epoch 48/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8557 - val_loss: 0.3578 - val_accuracy: 0.8583\n",
            "Epoch 49/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8560 - val_loss: 0.3569 - val_accuracy: 0.8554\n",
            "Epoch 50/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.8532 - val_loss: 0.3584 - val_accuracy: 0.8551\n",
            "Epoch 51/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.8568 - val_loss: 0.3576 - val_accuracy: 0.8537\n",
            "Epoch 52/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3524 - accuracy: 0.8532 - val_loss: 0.3582 - val_accuracy: 0.8589\n",
            "Epoch 53/2000\n",
            "25/25 [==============================] - 0s 14ms/step - loss: 0.3528 - accuracy: 0.8560 - val_loss: 0.3599 - val_accuracy: 0.8517\n",
            "Epoch 54/2000\n",
            "25/25 [==============================] - 0s 13ms/step - loss: 0.3522 - accuracy: 0.8569 - val_loss: 0.3571 - val_accuracy: 0.8577\n",
            "Epoch 55/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8563 - val_loss: 0.3574 - val_accuracy: 0.8580\n",
            "Epoch 56/2000\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.3517 - accuracy: 0.8563 - val_loss: 0.3561 - val_accuracy: 0.8577\n",
            "Epoch 57/2000\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.8557 - val_loss: 0.3594 - val_accuracy: 0.8540\n",
            "Epoch 58/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3513 - accuracy: 0.8569 - val_loss: 0.3581 - val_accuracy: 0.8517\n",
            "Epoch 59/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3538 - accuracy: 0.8538 - val_loss: 0.3584 - val_accuracy: 0.8583\n",
            "Epoch 60/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8566 - val_loss: 0.3581 - val_accuracy: 0.8540\n",
            "Epoch 61/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3521 - accuracy: 0.8566 - val_loss: 0.3575 - val_accuracy: 0.8531\n",
            "Epoch 62/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3512 - accuracy: 0.8589 - val_loss: 0.3570 - val_accuracy: 0.8591\n",
            "Epoch 63/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8571 - val_loss: 0.3555 - val_accuracy: 0.8571\n",
            "Epoch 64/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.8558 - val_loss: 0.3565 - val_accuracy: 0.8577\n",
            "Epoch 65/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8551 - val_loss: 0.3558 - val_accuracy: 0.8566\n",
            "Epoch 66/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8555 - val_loss: 0.3584 - val_accuracy: 0.8571\n",
            "Epoch 67/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8560 - val_loss: 0.3559 - val_accuracy: 0.8566\n",
            "Epoch 68/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3501 - accuracy: 0.8566 - val_loss: 0.3552 - val_accuracy: 0.8571\n",
            "Epoch 69/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8548 - val_loss: 0.3566 - val_accuracy: 0.8583\n",
            "Epoch 70/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8543 - val_loss: 0.3566 - val_accuracy: 0.8534\n",
            "Epoch 71/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8557 - val_loss: 0.3585 - val_accuracy: 0.8551\n",
            "Epoch 72/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3510 - accuracy: 0.8575 - val_loss: 0.3551 - val_accuracy: 0.8560\n",
            "Epoch 73/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3510 - accuracy: 0.8554 - val_loss: 0.3582 - val_accuracy: 0.8560\n",
            "Epoch 74/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3500 - accuracy: 0.8560 - val_loss: 0.3576 - val_accuracy: 0.8563\n",
            "Epoch 75/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3494 - accuracy: 0.8552 - val_loss: 0.3659 - val_accuracy: 0.8514\n",
            "Epoch 76/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8546 - val_loss: 0.3564 - val_accuracy: 0.8586\n",
            "Epoch 77/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8577 - val_loss: 0.3586 - val_accuracy: 0.8563\n",
            "Epoch 78/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8565 - val_loss: 0.3569 - val_accuracy: 0.8526\n",
            "Epoch 79/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8534 - val_loss: 0.3585 - val_accuracy: 0.8591\n",
            "Epoch 80/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8560 - val_loss: 0.3570 - val_accuracy: 0.8554\n",
            "Epoch 81/2000\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8569 - val_loss: 0.3601 - val_accuracy: 0.8514\n",
            "Epoch 82/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3501 - accuracy: 0.8569 - val_loss: 0.3565 - val_accuracy: 0.8569\n",
            "Epoch 83/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8569 - val_loss: 0.3609 - val_accuracy: 0.8571\n",
            "Epoch 84/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3502 - accuracy: 0.8565 - val_loss: 0.3570 - val_accuracy: 0.8574\n",
            "Epoch 85/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8572 - val_loss: 0.3576 - val_accuracy: 0.8543\n",
            "Epoch 86/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8549 - val_loss: 0.3729 - val_accuracy: 0.8431\n",
            "Epoch 87/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3521 - accuracy: 0.8565 - val_loss: 0.3577 - val_accuracy: 0.8577\n",
            "Epoch 88/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3482 - accuracy: 0.8578 - val_loss: 0.3573 - val_accuracy: 0.8551\n",
            "Epoch 89/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8583 - val_loss: 0.3601 - val_accuracy: 0.8534\n",
            "Epoch 90/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3481 - accuracy: 0.8562 - val_loss: 0.3600 - val_accuracy: 0.8557\n",
            "Epoch 91/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3524 - accuracy: 0.8546 - val_loss: 0.3640 - val_accuracy: 0.8529\n",
            "Epoch 92/2000\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3491 - accuracy: 0.8546 - val_loss: 0.3600 - val_accuracy: 0.8551\n",
            "Epoch 93/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8575 - val_loss: 0.3596 - val_accuracy: 0.8569\n",
            "Epoch 94/2000\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8574 - val_loss: 0.3576 - val_accuracy: 0.8571\n",
            "Epoch 95/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8572 - val_loss: 0.3598 - val_accuracy: 0.8529\n",
            "Epoch 96/2000\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3479 - accuracy: 0.8563 - val_loss: 0.3589 - val_accuracy: 0.8554\n",
            "Epoch 97/2000\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.3501 - accuracy: 0.8534 - val_loss: 0.3571 - val_accuracy: 0.8551\n",
            "Epoch 97: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f562bb22d90>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_df = pd.DataFrame(model.history.history)\n",
        "loss_df.plot();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8c6jz6cz33vs",
        "outputId": "26b2a0b4-19fb-4d47-c4d3-d0dcac57db9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"loss : \", loss)\n",
        "print(\"accuracy : \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkDsuVrP33x7",
        "outputId": "0875c1ac-712e-4c91-a764-ef50c4631d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss :  0.35712695121765137\n",
            "accuracy :  0.8551428318023682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOyaoo5e330I",
        "outputId": "57ca2126-434c-484d-f4e5-0311a257a06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2686  101]\n",
            " [ 406  307]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.96      0.91      2787\n",
            "           1       0.75      0.43      0.55       713\n",
            "\n",
            "    accuracy                           0.86      3500\n",
            "   macro avg       0.81      0.70      0.73      3500\n",
            "weighted avg       0.85      0.86      0.84      3500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model_Exited.h5')"
      ],
      "metadata": {
        "id": "3lE5AnWc334D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Model and Scaler"
      ],
      "metadata": {
        "id": "hiFq7adJD9LM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "MIC-SokyEApH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaydettigimiz model ve scaler' i prediction almak uzere tekrar load ettik."
      ],
      "metadata": {
        "id": "LCyxSI28EAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_Exited = load_model('model_Exited.h5')\n",
        "scaler_Exited = pickle.load(open(\"scaler_Exited\", \"rb\"))"
      ],
      "metadata": {
        "id": "xTYkTmzJEBDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq10ovAX6daY"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target label olan Cancer stununu datadan atarak datadaki ilk satiri prediction' da kullanmak uzere cektik ve bunu modele vermeden nce transform ile scale islemini uyguladik :"
      ],
      "metadata": {
        "id": "apDBm3RDERNU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Exited_cust = df.drop('Exited', axis = 1).iloc[50:60, :]\n",
        "Exited_cust"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "rq04OuChER0z",
        "outputId": "0b35f1c2-838b-4c67-dca0-a2f161c47085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "50          698   44      10 116363.370              2          1   \n",
              "51          585   36       5 146050.970              2          0   \n",
              "52          788   33       5      0.000              2          0   \n",
              "53          655   41       8 125561.970              1          0   \n",
              "54          601   42       1  98495.720              1          1   \n",
              "55          619   43       1 125211.920              1          1   \n",
              "56          656   45       5 127864.400              1          1   \n",
              "57          725   19       0  75888.200              1          0   \n",
              "58          511   66       4      0.000              1          1   \n",
              "59          614   51       4  40685.920              1          1   \n",
              "\n",
              "    IsActiveMember  EstimatedSalary  \n",
              "50               0       198059.160  \n",
              "51               0        86424.570  \n",
              "52               0       116978.190  \n",
              "53               0       164040.940  \n",
              "54               0        40014.760  \n",
              "55               1       113410.490  \n",
              "56               0        87107.570  \n",
              "57               0        45613.750  \n",
              "58               0         1643.110  \n",
              "59               1        46775.280  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85e51731-23ee-4cc1-9ae5-05bd5ac66cb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>698</td>\n",
              "      <td>44</td>\n",
              "      <td>10</td>\n",
              "      <td>116363.370</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>198059.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>585</td>\n",
              "      <td>36</td>\n",
              "      <td>5</td>\n",
              "      <td>146050.970</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86424.570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>788</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>116978.190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>655</td>\n",
              "      <td>41</td>\n",
              "      <td>8</td>\n",
              "      <td>125561.970</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>164040.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>601</td>\n",
              "      <td>42</td>\n",
              "      <td>1</td>\n",
              "      <td>98495.720</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>40014.760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>619</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>125211.920</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>113410.490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>656</td>\n",
              "      <td>45</td>\n",
              "      <td>5</td>\n",
              "      <td>127864.400</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>87107.570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>725</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>75888.200</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45613.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>511</td>\n",
              "      <td>66</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1643.110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>614</td>\n",
              "      <td>51</td>\n",
              "      <td>4</td>\n",
              "      <td>40685.920</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>46775.280</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85e51731-23ee-4cc1-9ae5-05bd5ac66cb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85e51731-23ee-4cc1-9ae5-05bd5ac66cb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85e51731-23ee-4cc1-9ae5-05bd5ac66cb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DL modelleri scale edilmis array seklindeki data ile calisir :"
      ],
      "metadata": {
        "id": "fG5zFTRJER-k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq6UQu-QXsAY",
        "outputId": "3f54a98e-ce79-4ee1-a28b-ff07b5b10efc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.696     , 0.35135135, 1.        , 0.52526475, 0.33333333,\n",
              "        1.        , 0.        , 0.99033248],\n",
              "       [0.47      , 0.24324324, 0.5       , 0.6592747 , 0.33333333,\n",
              "        0.        , 0.        , 0.43210622],\n",
              "       [0.876     , 0.2027027 , 0.5       , 0.        , 0.33333333,\n",
              "        0.        , 0.        , 0.58488891],\n",
              "       [0.61      , 0.31081081, 0.8       , 0.56678727, 0.        ,\n",
              "        0.        , 0.        , 0.82022513],\n",
              "       [0.502     , 0.32432432, 0.1       , 0.4446101 , 0.        ,\n",
              "        1.        , 0.        , 0.200035  ],\n",
              "       [0.538     , 0.33783784, 0.1       , 0.56520714, 0.        ,\n",
              "        1.        , 1.        , 0.5670487 ],\n",
              "       [0.612     , 0.36486486, 0.5       , 0.57718044, 0.        ,\n",
              "        1.        , 0.        , 0.43552154],\n",
              "       [0.75      , 0.01351351, 0.        , 0.34255966, 0.        ,\n",
              "        0.        , 0.        , 0.22803263],\n",
              "       [0.322     , 0.64864865, 0.4       , 0.        , 0.        ,\n",
              "        1.        , 0.        , 0.00815843],\n",
              "       [0.528     , 0.44594595, 0.4       , 0.18365642, 0.        ,\n",
              "        1.        , 1.        , 0.23384083]])"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "Exited_cust = scaler_Exited.transform(Exited_cust)\n",
        "Exited_cust"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction asamasinda yine >0.5' i belirtiyoruz. 0.5' in uzerinde bir deger cikarsa 1 class' ina; cikmazsa 0 class' ina atama yapacak :"
      ],
      "metadata": {
        "id": "inznOA6zEYat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_sample = pd.DataFrame(model_Exited.predict(Exited_cust) > 0.5).astype(\"int32\").rename({0: 'Predicted Sample'}, axis=1)\n",
        "predicted_sample\n",
        "#model_Exited.predict_classes(Exited_cust)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "0A1SXkj-EY1q",
        "outputId": "96b66947-4f38-4750-8493-5c04c17335ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Predicted Sample\n",
              "0                 0\n",
              "1                 0\n",
              "2                 0\n",
              "3                 0\n",
              "4                 0\n",
              "5                 0\n",
              "6                 1\n",
              "7                 0\n",
              "8                 1\n",
              "9                 0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a54db4b-637a-41ab-9c48-92a958a12eeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted Sample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a54db4b-637a-41ab-9c48-92a958a12eeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a54db4b-637a-41ab-9c48-92a958a12eeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a54db4b-637a-41ab-9c48-92a958a12eeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction ile gercek degeri kiyasladik, ayni sonuc cikti. Roc/Auc' da aldigimiz yuksek skorlar bize 1 ve 0 class' inin ayriminin iyi yapildigi inside' ini vermisti:"
      ],
      "metadata": {
        "id": "XTFn4O3ZEY9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual_sample = pd.DataFrame(df[\"Exited\"].iloc[50:60]).rename({'Exited': 'Actual Sample'}, axis=1)\n",
        "actual_sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "S00PdcVdEZE2",
        "outputId": "b0b5bc7d-11ef-429e-cd6c-8b2786cbf5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Actual Sample\n",
              "50              0\n",
              "51              0\n",
              "52              0\n",
              "53              1\n",
              "54              1\n",
              "55              0\n",
              "56              0\n",
              "57              0\n",
              "58              1\n",
              "59              0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5896b616-d681-477c-96bb-02e5604f1a59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual Sample</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5896b616-d681-477c-96bb-02e5604f1a59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5896b616-d681-477c-96bb-02e5604f1a59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5896b616-d681-477c-96bb-02e5604f1a59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df['Prediction Accuracy'] = pred_df.apply(lambda x: \"Correct Pred\" if int(x['Actual Sample'] == x['Predicted Sample']) else \"Wrong Pred\", axis=1)\n",
        "\n",
        "def color_positive_green(val):\n",
        "    if val == 'Correct Pred':\n",
        "        color = 'green'\n",
        "    elif val == 'Wrong Pred':\n",
        "        color = 'red'\n",
        "    else:\n",
        "        color = 'black'\n",
        "    return 'color: %s' % color\n",
        " \n",
        "pred_df.style.applymap(color_positive_green)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "zl1KRl81HOWv",
        "outputId": "c506d6f3-5988-4388-a0a6-d73fb11f1157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f56284e9810>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_134a2_row0_col0, #T_134a2_row0_col1, #T_134a2_row1_col0, #T_134a2_row1_col1, #T_134a2_row2_col0, #T_134a2_row2_col1, #T_134a2_row3_col0, #T_134a2_row3_col1, #T_134a2_row4_col0, #T_134a2_row4_col1, #T_134a2_row5_col0, #T_134a2_row5_col1, #T_134a2_row6_col0, #T_134a2_row6_col1, #T_134a2_row7_col0, #T_134a2_row7_col1, #T_134a2_row8_col0, #T_134a2_row8_col1, #T_134a2_row9_col0, #T_134a2_row9_col1 {\n",
              "  color: black;\n",
              "}\n",
              "#T_134a2_row0_col2, #T_134a2_row1_col2, #T_134a2_row2_col2, #T_134a2_row5_col2, #T_134a2_row7_col2, #T_134a2_row8_col2, #T_134a2_row9_col2 {\n",
              "  color: green;\n",
              "}\n",
              "#T_134a2_row3_col2, #T_134a2_row4_col2, #T_134a2_row6_col2 {\n",
              "  color: red;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_134a2_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >Actual Sample</th>\n",
              "      <th class=\"col_heading level0 col1\" >Predicted Sample</th>\n",
              "      <th class=\"col_heading level0 col2\" >Prediction Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row0\" class=\"row_heading level0 row0\" >50</th>\n",
              "      <td id=\"T_134a2_row0_col0\" class=\"data row0 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row0_col2\" class=\"data row0 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row1\" class=\"row_heading level0 row1\" >51</th>\n",
              "      <td id=\"T_134a2_row1_col0\" class=\"data row1 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row1_col2\" class=\"data row1 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row2\" class=\"row_heading level0 row2\" >52</th>\n",
              "      <td id=\"T_134a2_row2_col0\" class=\"data row2 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row2_col1\" class=\"data row2 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row2_col2\" class=\"data row2 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row3\" class=\"row_heading level0 row3\" >53</th>\n",
              "      <td id=\"T_134a2_row3_col0\" class=\"data row3 col0\" >1</td>\n",
              "      <td id=\"T_134a2_row3_col1\" class=\"data row3 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row3_col2\" class=\"data row3 col2\" >Wrong Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row4\" class=\"row_heading level0 row4\" >54</th>\n",
              "      <td id=\"T_134a2_row4_col0\" class=\"data row4 col0\" >1</td>\n",
              "      <td id=\"T_134a2_row4_col1\" class=\"data row4 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row4_col2\" class=\"data row4 col2\" >Wrong Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row5\" class=\"row_heading level0 row5\" >55</th>\n",
              "      <td id=\"T_134a2_row5_col0\" class=\"data row5 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row5_col1\" class=\"data row5 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row5_col2\" class=\"data row5 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row6\" class=\"row_heading level0 row6\" >56</th>\n",
              "      <td id=\"T_134a2_row6_col0\" class=\"data row6 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row6_col1\" class=\"data row6 col1\" >1</td>\n",
              "      <td id=\"T_134a2_row6_col2\" class=\"data row6 col2\" >Wrong Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row7\" class=\"row_heading level0 row7\" >57</th>\n",
              "      <td id=\"T_134a2_row7_col0\" class=\"data row7 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row7_col1\" class=\"data row7 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row7_col2\" class=\"data row7 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row8\" class=\"row_heading level0 row8\" >58</th>\n",
              "      <td id=\"T_134a2_row8_col0\" class=\"data row8 col0\" >1</td>\n",
              "      <td id=\"T_134a2_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "      <td id=\"T_134a2_row8_col2\" class=\"data row8 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_134a2_level0_row9\" class=\"row_heading level0 row9\" >59</th>\n",
              "      <td id=\"T_134a2_row9_col0\" class=\"data row9 col0\" >0</td>\n",
              "      <td id=\"T_134a2_row9_col1\" class=\"data row9 col1\" >0</td>\n",
              "      <td id=\"T_134a2_row9_col2\" class=\"data row9 col2\" >Correct Pred</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PBBPmGWXsAY"
      },
      "source": [
        "___\n",
        "\n",
        "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" alt=\"CLRSWY\"></p>\n",
        "\n",
        "___"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "XcKtRRpc1HAE"
      ],
      "name": "DL-Assignment-1 (Classification with ANN-Churn Prediction)-Student.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}